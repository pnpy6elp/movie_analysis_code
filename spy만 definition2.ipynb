{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "764716cf",
   "metadata": {},
   "source": [
    "# 첫번째"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6390e19f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.text import Tokenizer\n",
    "import codecs\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "import numpy as np\n",
    "import nltk\n",
    "from konlpy.tag import Okt\n",
    "from tqdm import tqdm\n",
    "\n",
    "# train set\n",
    "name = \"2\"\n",
    "numb = \"1\"\n",
    "filename1 = './spy/definition'+name+'_spynorth_scaling_trust'+numb+'.txt'\n",
    "filename2 = './spy/definition'+name+'_spynorth_scaling_untrust'+numb+'.txt'\n",
    "\n",
    "\n",
    "\n",
    "with codecs.open(filename1, 'r', encoding='utf-8-sig') as f:\n",
    "    lines1 = f.readlines()\n",
    "with codecs.open(filename2, 'r', encoding='utf-8-sig') as f:\n",
    "    lines2 = f.readlines()\n",
    "\n",
    "\n",
    "# test set\n",
    "\n",
    "\n",
    "with codecs.open('./spy/definition'+name+'_spynorth_test_t'+numb+'.txt', 'r', 'utf-8-sig') as f:\n",
    "    test1 = f.readlines()\n",
    "with codecs.open('./spy/definition'+name+'_spynorth_test_ut'+numb+'.txt', 'r', 'utf-8-sig') as f:\n",
    "    test2 = f.readlines()\n",
    "\n",
    "\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0c724c17",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "73/73 [==============================] - 23s 67ms/step - loss: 0.6915 - acc: 0.5369 - val_loss: 0.6901 - val_acc: 0.5515\n",
      "Epoch 2/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 0.6895 - acc: 0.5489 - val_loss: 0.6882 - val_acc: 0.5598\n",
      "Epoch 3/100\n",
      "73/73 [==============================] - 1s 10ms/step - loss: 0.6874 - acc: 0.5535 - val_loss: 0.6864 - val_acc: 0.5598\n",
      "Epoch 4/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 0.6855 - acc: 0.5651 - val_loss: 0.6857 - val_acc: 0.5548\n",
      "Epoch 5/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 0.6840 - acc: 0.5630 - val_loss: 0.6846 - val_acc: 0.5630\n",
      "Epoch 6/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 0.6818 - acc: 0.5639 - val_loss: 0.6864 - val_acc: 0.5587\n",
      "Epoch 7/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 0.6810 - acc: 0.5624 - val_loss: 0.6840 - val_acc: 0.5548\n",
      "Epoch 8/100\n",
      "73/73 [==============================] - 1s 13ms/step - loss: 0.6794 - acc: 0.5661 - val_loss: 0.6835 - val_acc: 0.5543\n",
      "Epoch 9/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 0.6781 - acc: 0.5654 - val_loss: 0.6834 - val_acc: 0.5439\n",
      "Epoch 10/100\n",
      "73/73 [==============================] - 1s 8ms/step - loss: 0.6772 - acc: 0.5713 - val_loss: 0.6829 - val_acc: 0.5532\n",
      "Epoch 11/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 0.6762 - acc: 0.5728 - val_loss: 0.6818 - val_acc: 0.5652\n",
      "Epoch 12/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 0.6754 - acc: 0.5762 - val_loss: 0.6817 - val_acc: 0.5663\n",
      "Epoch 13/100\n",
      "73/73 [==============================] - 1s 10ms/step - loss: 0.6741 - acc: 0.5788 - val_loss: 0.6809 - val_acc: 0.5630\n",
      "Epoch 14/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 0.6733 - acc: 0.5816 - val_loss: 0.6795 - val_acc: 0.5652\n",
      "Epoch 15/100\n",
      "73/73 [==============================] - 1s 8ms/step - loss: 0.6721 - acc: 0.5862 - val_loss: 0.6785 - val_acc: 0.5702\n",
      "Epoch 16/100\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.6709 - acc: 0.5846 - val_loss: 0.6777 - val_acc: 0.5674\n",
      "Epoch 17/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 0.6697 - acc: 0.5866 - val_loss: 0.6769 - val_acc: 0.5724\n",
      "Epoch 18/100\n",
      "73/73 [==============================] - 0s 7ms/step - loss: 0.6688 - acc: 0.5894 - val_loss: 0.6750 - val_acc: 0.5768\n",
      "Epoch 19/100\n",
      "73/73 [==============================] - 1s 8ms/step - loss: 0.6681 - acc: 0.5899 - val_loss: 0.6758 - val_acc: 0.5729\n",
      "Epoch 20/100\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.6673 - acc: 0.5900 - val_loss: 0.6752 - val_acc: 0.5811\n",
      "Epoch 21/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 0.6675 - acc: 0.5910 - val_loss: 0.6732 - val_acc: 0.5784\n",
      "Epoch 22/100\n",
      "73/73 [==============================] - 0s 7ms/step - loss: 0.6665 - acc: 0.5890 - val_loss: 0.6728 - val_acc: 0.5784\n",
      "Epoch 23/100\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.6671 - acc: 0.5910 - val_loss: 0.6725 - val_acc: 0.5773\n",
      "Epoch 24/100\n",
      "73/73 [==============================] - 1s 8ms/step - loss: 0.6670 - acc: 0.5890 - val_loss: 0.6720 - val_acc: 0.5768\n",
      "Epoch 25/100\n",
      "73/73 [==============================] - 1s 11ms/step - loss: 0.6666 - acc: 0.5880 - val_loss: 0.6717 - val_acc: 0.5784\n",
      "Epoch 26/100\n",
      "73/73 [==============================] - 0s 7ms/step - loss: 0.6667 - acc: 0.5881 - val_loss: 0.6715 - val_acc: 0.5779\n",
      "Epoch 27/100\n",
      "73/73 [==============================] - 0s 7ms/step - loss: 0.6671 - acc: 0.5895 - val_loss: 0.6719 - val_acc: 0.5773\n",
      "Epoch 28/100\n",
      "73/73 [==============================] - 0s 7ms/step - loss: 0.6668 - acc: 0.5894 - val_loss: 0.6714 - val_acc: 0.5768\n",
      "Epoch 29/100\n",
      "73/73 [==============================] - 0s 6ms/step - loss: 0.6661 - acc: 0.5891 - val_loss: 0.6710 - val_acc: 0.5757\n",
      "Epoch 30/100\n",
      "73/73 [==============================] - 0s 7ms/step - loss: 0.6666 - acc: 0.5894 - val_loss: 0.6731 - val_acc: 0.5800\n",
      "72/72 [==============================] - 0s 3ms/step - loss: 0.6582 - acc: 0.6026\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.6582369208335876, 0.6026315689086914]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras.layers import Input, Dense\n",
    "from keras.models import Model\n",
    "lines_t = lines1\n",
    "lines_ut = lines2\n",
    "test_t = test1\n",
    "test_ut = test2\n",
    "\n",
    "\n",
    "lines_ = []\n",
    "test_lines_ = []\n",
    "\n",
    "lines1_ = []\n",
    "lines2_ = []\n",
    "lines3_ = []\n",
    "lines4_ = []\n",
    "feature1 = []\n",
    "feature2 = []\n",
    "rating = []\n",
    "sentiment = []\n",
    "correlation = []\n",
    "\n",
    "for line in lines_t:\n",
    "    a = line.split(\",\")[:3]\n",
    "    a = list(map(float, a))\n",
    "    feature1.append(a)\n",
    "    \n",
    "    \n",
    "\n",
    "for line in lines_ut:\n",
    "    a = line.split(\",\")[:3]\n",
    "    a = list(map(float, a))\n",
    "    feature1.append(a)\n",
    "\n",
    "for line in test_t:\n",
    "    a = line.split(\",\")[:3]\n",
    "    a = list(map(float, a))\n",
    "    feature2.append(a)\n",
    "    \n",
    "for line in test_ut:\n",
    "    a = line.split(\",\")[:3]\n",
    "    a = list(map(float, a))\n",
    "    feature2.append(a)\n",
    "    \n",
    "    \n",
    "train_labels = [] # train 데이터 label\n",
    "test_labels = [] # test 데이터 label\n",
    "for i in range(len(lines_t)):\n",
    "    train_labels.append(1)\n",
    "for j in range(len(lines_ut)):\n",
    "    train_labels.append(0)\n",
    "for i in range(len(test_t)):\n",
    "    test_labels.append(1)\n",
    "for j in range(len(test_ut)):\n",
    "    test_labels.append(0)\n",
    "\n",
    "train_labels = np.asarray(train_labels)\n",
    "test_labels = np.asarray(test_labels)\n",
    "input_train = np.asarray(feature1)\n",
    "input_test = np.asarray(feature2)\n",
    "\n",
    "input_train = input_train.reshape(-1,1,3)\n",
    "input_test = input_test.reshape(-1,1,3)\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "x_train, x_valid, y_train, y_valid = train_test_split(input_train, train_labels, test_size=0.2, shuffle=True, stratify=train_labels, random_state=34)\n",
    "# LSTM\n",
    "from keras.layers import LSTM\n",
    "from tensorflow.python.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Embedding, SimpleRNN\n",
    "\n",
    "from keras.layers import Dense\n",
    "\n",
    "from keras.preprocessing import sequence\n",
    "\n",
    "model = Sequential()\n",
    "model.add(LSTM(32, return_sequences=True))\n",
    "model.add(LSTM(32))\n",
    "# 'binary_crossentropy\n",
    "model.add(Dense(5))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "model.compile(optimizer='rmsprop',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['acc'])\n",
    "\n",
    "from keras.callbacks import EarlyStopping\n",
    "early_stopping = EarlyStopping(monitor='val_acc', patience=10, mode='auto')\n",
    "\n",
    "history = model.fit(x_train, y_train,validation_data=(x_valid, y_valid),\n",
    "                    epochs=100,\n",
    "                    batch_size=100,callbacks=[early_stopping]\n",
    "                    )\n",
    "\n",
    "\n",
    "\n",
    "model.evaluate(input_test, test_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d70be6c",
   "metadata": {},
   "source": [
    "# 두번째"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a2df627f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "61/61 [==============================] - 12s 39ms/step - loss: 0.6919 - acc: 0.5351 - val_loss: 0.6917 - val_acc: 0.5259\n",
      "Epoch 2/100\n",
      "61/61 [==============================] - 0s 6ms/step - loss: 0.6896 - acc: 0.5565 - val_loss: 0.6906 - val_acc: 0.5406\n",
      "Epoch 3/100\n",
      "61/61 [==============================] - 0s 7ms/step - loss: 0.6875 - acc: 0.5637 - val_loss: 0.6917 - val_acc: 0.4914\n",
      "Epoch 4/100\n",
      "61/61 [==============================] - 1s 9ms/step - loss: 0.6862 - acc: 0.5608 - val_loss: 0.6893 - val_acc: 0.5505\n",
      "Epoch 5/100\n",
      "61/61 [==============================] - 1s 10ms/step - loss: 0.6846 - acc: 0.5657 - val_loss: 0.6950 - val_acc: 0.5399\n",
      "Epoch 6/100\n",
      "61/61 [==============================] - 1s 8ms/step - loss: 0.6833 - acc: 0.5687 - val_loss: 0.6881 - val_acc: 0.5432\n",
      "Epoch 7/100\n",
      "61/61 [==============================] - 0s 8ms/step - loss: 0.6825 - acc: 0.5700 - val_loss: 0.6879 - val_acc: 0.5339\n",
      "Epoch 8/100\n",
      "61/61 [==============================] - 0s 7ms/step - loss: 0.6822 - acc: 0.5645 - val_loss: 0.6885 - val_acc: 0.5492\n",
      "Epoch 9/100\n",
      "61/61 [==============================] - 0s 7ms/step - loss: 0.6816 - acc: 0.5607 - val_loss: 0.6879 - val_acc: 0.5273\n",
      "Epoch 10/100\n",
      "61/61 [==============================] - 0s 8ms/step - loss: 0.6806 - acc: 0.5632 - val_loss: 0.6867 - val_acc: 0.5519\n",
      "Epoch 11/100\n",
      "61/61 [==============================] - 0s 7ms/step - loss: 0.6795 - acc: 0.5643 - val_loss: 0.6862 - val_acc: 0.5512\n",
      "Epoch 12/100\n",
      "61/61 [==============================] - 0s 8ms/step - loss: 0.6788 - acc: 0.5608 - val_loss: 0.6859 - val_acc: 0.5552\n",
      "Epoch 13/100\n",
      "61/61 [==============================] - 0s 8ms/step - loss: 0.6777 - acc: 0.5685 - val_loss: 0.6843 - val_acc: 0.5552\n",
      "Epoch 14/100\n",
      "61/61 [==============================] - 1s 10ms/step - loss: 0.6763 - acc: 0.5678 - val_loss: 0.6840 - val_acc: 0.5545\n",
      "Epoch 15/100\n",
      "61/61 [==============================] - 0s 8ms/step - loss: 0.6760 - acc: 0.5693 - val_loss: 0.6828 - val_acc: 0.5612\n",
      "Epoch 16/100\n",
      "61/61 [==============================] - 1s 9ms/step - loss: 0.6738 - acc: 0.5701 - val_loss: 0.6819 - val_acc: 0.5585\n",
      "Epoch 17/100\n",
      "61/61 [==============================] - 1s 10ms/step - loss: 0.6736 - acc: 0.5750 - val_loss: 0.6848 - val_acc: 0.5618\n",
      "Epoch 18/100\n",
      "61/61 [==============================] - 1s 9ms/step - loss: 0.6730 - acc: 0.5778 - val_loss: 0.6820 - val_acc: 0.5585\n",
      "Epoch 19/100\n",
      "61/61 [==============================] - 1s 9ms/step - loss: 0.6720 - acc: 0.5790 - val_loss: 0.6816 - val_acc: 0.5612\n",
      "Epoch 20/100\n",
      "61/61 [==============================] - 0s 8ms/step - loss: 0.6706 - acc: 0.5823 - val_loss: 0.6793 - val_acc: 0.5618\n",
      "Epoch 21/100\n",
      "61/61 [==============================] - 1s 9ms/step - loss: 0.6694 - acc: 0.5834 - val_loss: 0.6776 - val_acc: 0.5625\n",
      "Epoch 22/100\n",
      "61/61 [==============================] - 0s 8ms/step - loss: 0.6683 - acc: 0.5873 - val_loss: 0.6785 - val_acc: 0.5685\n",
      "Epoch 23/100\n",
      "61/61 [==============================] - 1s 8ms/step - loss: 0.6671 - acc: 0.5868 - val_loss: 0.6771 - val_acc: 0.5672\n",
      "Epoch 24/100\n",
      "61/61 [==============================] - 1s 8ms/step - loss: 0.6666 - acc: 0.5868 - val_loss: 0.6769 - val_acc: 0.5592\n",
      "Epoch 25/100\n",
      "61/61 [==============================] - 1s 10ms/step - loss: 0.6663 - acc: 0.5916 - val_loss: 0.6766 - val_acc: 0.5665\n",
      "Epoch 26/100\n",
      "61/61 [==============================] - 1s 9ms/step - loss: 0.6659 - acc: 0.5881 - val_loss: 0.6775 - val_acc: 0.5592\n",
      "Epoch 27/100\n",
      "61/61 [==============================] - 1s 10ms/step - loss: 0.6659 - acc: 0.5894 - val_loss: 0.6758 - val_acc: 0.5618\n",
      "Epoch 28/100\n",
      "61/61 [==============================] - 1s 10ms/step - loss: 0.6647 - acc: 0.5904 - val_loss: 0.6812 - val_acc: 0.5685\n",
      "Epoch 29/100\n",
      "61/61 [==============================] - 1s 10ms/step - loss: 0.6660 - acc: 0.5893 - val_loss: 0.6763 - val_acc: 0.5678\n",
      "Epoch 30/100\n",
      "61/61 [==============================] - 1s 9ms/step - loss: 0.6654 - acc: 0.5903 - val_loss: 0.6760 - val_acc: 0.5625\n",
      "Epoch 31/100\n",
      "61/61 [==============================] - 1s 10ms/step - loss: 0.6650 - acc: 0.5903 - val_loss: 0.6761 - val_acc: 0.5658\n",
      "Epoch 32/100\n",
      "61/61 [==============================] - 1s 9ms/step - loss: 0.6647 - acc: 0.5933 - val_loss: 0.6793 - val_acc: 0.5585\n",
      "59/59 [==============================] - 0s 4ms/step - loss: 0.6692 - acc: 0.5883\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.6692014932632446, 0.5882978439331055]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras.preprocessing.text import Tokenizer\n",
    "import codecs\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "import numpy as np\n",
    "import nltk\n",
    "from konlpy.tag import Okt\n",
    "from tqdm import tqdm\n",
    "\n",
    "# train set\n",
    "name = \"2\"\n",
    "numb = \"2\"\n",
    "filename1 = './spy/definition'+name+'_spynorth_scaling_trust'+numb+'.txt'\n",
    "filename2 = './spy/definition'+name+'_spynorth_scaling_untrust'+numb+'.txt'\n",
    "\n",
    "\n",
    "\n",
    "with codecs.open(filename1, 'r', encoding='utf-8-sig') as f:\n",
    "    lines1 = f.readlines()\n",
    "with codecs.open(filename2, 'r', encoding='utf-8-sig') as f:\n",
    "    lines2 = f.readlines()\n",
    "\n",
    "\n",
    "# test set\n",
    "\n",
    "\n",
    "with codecs.open('./spy/definition'+name+'_spynorth_test_t'+numb+'.txt', 'r', 'utf-8-sig') as f:\n",
    "    test1 = f.readlines()\n",
    "with codecs.open('./spy/definition'+name+'_spynorth_test_ut'+numb+'.txt', 'r', 'utf-8-sig') as f:\n",
    "    test2 = f.readlines()\n",
    "\n",
    "\n",
    "    \n",
    "\n",
    "\n",
    "from keras.layers import Input, Dense\n",
    "from keras.models import Model\n",
    "lines_t = lines1 \n",
    "lines_ut = lines2\n",
    "test_t = test1\n",
    "test_ut = test2\n",
    "\n",
    "\n",
    "lines_ = []\n",
    "test_lines_ = []\n",
    "\n",
    "lines1_ = []\n",
    "lines2_ = []\n",
    "lines3_ = []\n",
    "lines4_ = []\n",
    "feature1 = []\n",
    "feature2 = []\n",
    "rating = []\n",
    "sentiment = []\n",
    "correlation = []\n",
    "\n",
    "for line in lines_t:\n",
    "    a = line.split(\",\")[:3]\n",
    "    a = list(map(float, a))\n",
    "    feature1.append(a)\n",
    "    \n",
    "    \n",
    "\n",
    "for line in lines_ut:\n",
    "    a = line.split(\",\")[:3]\n",
    "    a = list(map(float, a))\n",
    "    feature1.append(a)\n",
    "\n",
    "for line in test_t:\n",
    "    a = line.split(\",\")[:3]\n",
    "    a = list(map(float, a))\n",
    "    feature2.append(a)\n",
    "    \n",
    "for line in test_ut:\n",
    "    a = line.split(\",\")[:3]\n",
    "    a = list(map(float, a))\n",
    "    feature2.append(a)\n",
    "    \n",
    "    \n",
    "train_labels = [] # train 데이터 label\n",
    "test_labels = [] # test 데이터 label\n",
    "for i in range(len(lines_t)):\n",
    "    train_labels.append(1)\n",
    "for j in range(len(lines_ut)):\n",
    "    train_labels.append(0)\n",
    "for i in range(len(test_t)):\n",
    "    test_labels.append(1)\n",
    "for j in range(len(test_ut)):\n",
    "    test_labels.append(0)\n",
    "\n",
    "train_labels = np.asarray(train_labels)\n",
    "test_labels = np.asarray(test_labels)\n",
    "input_train = np.asarray(feature1)\n",
    "input_test = np.asarray(feature2)\n",
    "\n",
    "input_train = input_train.reshape(-1,1,3)\n",
    "input_test = input_test.reshape(-1,1,3)\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "x_train, x_valid, y_train, y_valid = train_test_split(input_train, train_labels, test_size=0.2, shuffle=True, stratify=train_labels, random_state=34)\n",
    "# LSTM\n",
    "from keras.layers import LSTM\n",
    "from tensorflow.python.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Embedding, SimpleRNN\n",
    "\n",
    "from keras.layers import Dense\n",
    "\n",
    "from keras.preprocessing import sequence\n",
    "\n",
    "model = Sequential()\n",
    "model.add(LSTM(32, return_sequences=True))\n",
    "model.add(LSTM(32))\n",
    "# 'binary_crossentropy\n",
    "model.add(Dense(5))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "model.compile(optimizer='rmsprop',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['acc'])\n",
    "\n",
    "from keras.callbacks import EarlyStopping\n",
    "early_stopping = EarlyStopping(monitor='val_acc', patience=10, mode='auto')\n",
    "\n",
    "history = model.fit(x_train, y_train,validation_data=(x_valid, y_valid),\n",
    "                    epochs=100,\n",
    "                    batch_size=100,callbacks=[early_stopping]\n",
    "                    )\n",
    "\n",
    "\n",
    "\n",
    "model.evaluate(input_test, test_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d987d40",
   "metadata": {},
   "source": [
    "# 세번째"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bd5df845",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "48/48 [==============================] - 19s 80ms/step - loss: 0.6919 - acc: 0.5315 - val_loss: 0.6898 - val_acc: 0.5473\n",
      "Epoch 2/100\n",
      "48/48 [==============================] - 1s 12ms/step - loss: 0.6897 - acc: 0.5511 - val_loss: 0.6883 - val_acc: 0.5633\n",
      "Epoch 3/100\n",
      "48/48 [==============================] - 1s 12ms/step - loss: 0.6886 - acc: 0.5496 - val_loss: 0.6859 - val_acc: 0.5633\n",
      "Epoch 4/100\n",
      "48/48 [==============================] - 1s 11ms/step - loss: 0.6871 - acc: 0.5538 - val_loss: 0.6870 - val_acc: 0.5524\n",
      "Epoch 5/100\n",
      "48/48 [==============================] - 0s 9ms/step - loss: 0.6871 - acc: 0.5494 - val_loss: 0.6836 - val_acc: 0.5625\n",
      "Epoch 6/100\n",
      "48/48 [==============================] - 0s 10ms/step - loss: 0.6861 - acc: 0.5553 - val_loss: 0.6831 - val_acc: 0.5819\n",
      "Epoch 7/100\n",
      "48/48 [==============================] - 1s 13ms/step - loss: 0.6859 - acc: 0.5614 - val_loss: 0.6820 - val_acc: 0.5887\n",
      "Epoch 8/100\n",
      "48/48 [==============================] - 0s 10ms/step - loss: 0.6854 - acc: 0.5598 - val_loss: 0.6808 - val_acc: 0.5861\n",
      "Epoch 9/100\n",
      "48/48 [==============================] - 1s 11ms/step - loss: 0.6847 - acc: 0.5595 - val_loss: 0.6800 - val_acc: 0.5845\n",
      "Epoch 10/100\n",
      "48/48 [==============================] - 0s 10ms/step - loss: 0.6844 - acc: 0.5602 - val_loss: 0.6786 - val_acc: 0.5912\n",
      "Epoch 11/100\n",
      "48/48 [==============================] - 1s 11ms/step - loss: 0.6835 - acc: 0.5593 - val_loss: 0.6774 - val_acc: 0.5912\n",
      "Epoch 12/100\n",
      "48/48 [==============================] - 1s 11ms/step - loss: 0.6832 - acc: 0.5623 - val_loss: 0.6766 - val_acc: 0.5904\n",
      "Epoch 13/100\n",
      "48/48 [==============================] - 0s 10ms/step - loss: 0.6824 - acc: 0.5617 - val_loss: 0.6758 - val_acc: 0.5904\n",
      "Epoch 14/100\n",
      "48/48 [==============================] - 0s 9ms/step - loss: 0.6824 - acc: 0.5587 - val_loss: 0.6749 - val_acc: 0.5929\n",
      "Epoch 15/100\n",
      "48/48 [==============================] - 0s 10ms/step - loss: 0.6816 - acc: 0.5545 - val_loss: 0.6741 - val_acc: 0.5946\n",
      "Epoch 16/100\n",
      "48/48 [==============================] - 1s 13ms/step - loss: 0.6813 - acc: 0.5633 - val_loss: 0.6746 - val_acc: 0.5701\n",
      "Epoch 17/100\n",
      "48/48 [==============================] - 1s 11ms/step - loss: 0.6807 - acc: 0.5583 - val_loss: 0.6734 - val_acc: 0.5921\n",
      "Epoch 18/100\n",
      "48/48 [==============================] - 1s 12ms/step - loss: 0.6809 - acc: 0.5612 - val_loss: 0.6731 - val_acc: 0.5938\n",
      "Epoch 19/100\n",
      "48/48 [==============================] - 1s 13ms/step - loss: 0.6803 - acc: 0.5602 - val_loss: 0.6741 - val_acc: 0.5870\n",
      "Epoch 20/100\n",
      "48/48 [==============================] - 1s 12ms/step - loss: 0.6800 - acc: 0.5716 - val_loss: 0.6741 - val_acc: 0.5633\n",
      "Epoch 21/100\n",
      "48/48 [==============================] - 1s 14ms/step - loss: 0.6800 - acc: 0.5606 - val_loss: 0.6736 - val_acc: 0.5735\n",
      "Epoch 22/100\n",
      "48/48 [==============================] - 1s 18ms/step - loss: 0.6795 - acc: 0.5646 - val_loss: 0.6718 - val_acc: 0.5971\n",
      "Epoch 23/100\n",
      "48/48 [==============================] - 1s 20ms/step - loss: 0.6795 - acc: 0.5665 - val_loss: 0.6712 - val_acc: 0.5938\n",
      "Epoch 24/100\n",
      "48/48 [==============================] - 1s 17ms/step - loss: 0.6790 - acc: 0.5674 - val_loss: 0.6709 - val_acc: 0.5895\n",
      "Epoch 25/100\n",
      "48/48 [==============================] - 1s 23ms/step - loss: 0.6786 - acc: 0.5606 - val_loss: 0.6707 - val_acc: 0.5980\n",
      "Epoch 26/100\n",
      "48/48 [==============================] - 1s 19ms/step - loss: 0.6786 - acc: 0.5697 - val_loss: 0.6703 - val_acc: 0.5904\n",
      "Epoch 27/100\n",
      "48/48 [==============================] - 1s 18ms/step - loss: 0.6785 - acc: 0.5709 - val_loss: 0.6711 - val_acc: 0.5819\n",
      "Epoch 28/100\n",
      "48/48 [==============================] - 1s 15ms/step - loss: 0.6784 - acc: 0.5695 - val_loss: 0.6696 - val_acc: 0.5912\n",
      "Epoch 29/100\n",
      "48/48 [==============================] - 1s 14ms/step - loss: 0.6776 - acc: 0.5709 - val_loss: 0.6688 - val_acc: 0.5954\n",
      "Epoch 30/100\n",
      "48/48 [==============================] - 1s 12ms/step - loss: 0.6773 - acc: 0.5695 - val_loss: 0.6687 - val_acc: 0.6064\n",
      "Epoch 31/100\n",
      "48/48 [==============================] - 1s 12ms/step - loss: 0.6769 - acc: 0.5773 - val_loss: 0.6703 - val_acc: 0.5760\n",
      "Epoch 32/100\n",
      "48/48 [==============================] - 1s 15ms/step - loss: 0.6769 - acc: 0.5762 - val_loss: 0.6678 - val_acc: 0.5929\n",
      "Epoch 33/100\n",
      "48/48 [==============================] - 1s 11ms/step - loss: 0.6764 - acc: 0.5781 - val_loss: 0.6690 - val_acc: 0.6090\n",
      "Epoch 34/100\n",
      "48/48 [==============================] - 1s 15ms/step - loss: 0.6764 - acc: 0.5756 - val_loss: 0.6670 - val_acc: 0.6090\n",
      "Epoch 35/100\n",
      "48/48 [==============================] - 1s 16ms/step - loss: 0.6755 - acc: 0.5779 - val_loss: 0.6676 - val_acc: 0.5895\n",
      "Epoch 36/100\n",
      "48/48 [==============================] - 1s 12ms/step - loss: 0.6751 - acc: 0.5722 - val_loss: 0.6680 - val_acc: 0.5811\n",
      "Epoch 37/100\n",
      "48/48 [==============================] - 1s 11ms/step - loss: 0.6748 - acc: 0.5783 - val_loss: 0.6661 - val_acc: 0.6073\n",
      "Epoch 38/100\n",
      "48/48 [==============================] - 1s 11ms/step - loss: 0.6745 - acc: 0.5783 - val_loss: 0.6646 - val_acc: 0.6014\n",
      "Epoch 39/100\n",
      "48/48 [==============================] - 1s 12ms/step - loss: 0.6740 - acc: 0.5811 - val_loss: 0.6638 - val_acc: 0.6064\n",
      "Epoch 40/100\n",
      "48/48 [==============================] - 1s 11ms/step - loss: 0.6736 - acc: 0.5754 - val_loss: 0.6644 - val_acc: 0.6081\n",
      "Epoch 41/100\n",
      "48/48 [==============================] - 1s 11ms/step - loss: 0.6736 - acc: 0.5792 - val_loss: 0.6643 - val_acc: 0.6064\n",
      "Epoch 42/100\n",
      "48/48 [==============================] - 1s 12ms/step - loss: 0.6727 - acc: 0.5807 - val_loss: 0.6648 - val_acc: 0.6022\n",
      "Epoch 43/100\n",
      "48/48 [==============================] - 1s 16ms/step - loss: 0.6722 - acc: 0.5779 - val_loss: 0.6617 - val_acc: 0.6123\n",
      "Epoch 44/100\n",
      "48/48 [==============================] - 1s 18ms/step - loss: 0.6726 - acc: 0.5775 - val_loss: 0.6618 - val_acc: 0.6106\n",
      "Epoch 45/100\n",
      "48/48 [==============================] - 1s 13ms/step - loss: 0.6723 - acc: 0.5777 - val_loss: 0.6640 - val_acc: 0.6039\n",
      "Epoch 46/100\n",
      "48/48 [==============================] - 1s 11ms/step - loss: 0.6722 - acc: 0.5754 - val_loss: 0.6614 - val_acc: 0.6115\n",
      "Epoch 47/100\n",
      "48/48 [==============================] - 1s 11ms/step - loss: 0.6720 - acc: 0.5775 - val_loss: 0.6605 - val_acc: 0.6123\n",
      "Epoch 48/100\n",
      "48/48 [==============================] - 0s 9ms/step - loss: 0.6717 - acc: 0.5798 - val_loss: 0.6665 - val_acc: 0.5997\n",
      "Epoch 49/100\n",
      "48/48 [==============================] - 0s 9ms/step - loss: 0.6723 - acc: 0.5804 - val_loss: 0.6594 - val_acc: 0.6098\n",
      "Epoch 50/100\n",
      "48/48 [==============================] - 1s 11ms/step - loss: 0.6716 - acc: 0.5817 - val_loss: 0.6595 - val_acc: 0.6081\n",
      "Epoch 51/100\n",
      "48/48 [==============================] - 1s 11ms/step - loss: 0.6722 - acc: 0.5775 - val_loss: 0.6605 - val_acc: 0.6106\n",
      "Epoch 52/100\n",
      "48/48 [==============================] - 0s 10ms/step - loss: 0.6714 - acc: 0.5807 - val_loss: 0.6589 - val_acc: 0.6098\n",
      "Epoch 53/100\n",
      "48/48 [==============================] - 0s 10ms/step - loss: 0.6713 - acc: 0.5794 - val_loss: 0.6616 - val_acc: 0.6073\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.6635 - acc: 0.5980\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.6635398864746094, 0.5979729890823364]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras.preprocessing.text import Tokenizer\n",
    "import codecs\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "import numpy as np\n",
    "import nltk\n",
    "from konlpy.tag import Okt\n",
    "from tqdm import tqdm\n",
    "\n",
    "# train set\n",
    "name = \"2\"\n",
    "numb = \"3\"\n",
    "filename1 = './spy/definition'+name+'_spynorth_scaling_trust'+numb+'.txt'\n",
    "filename2 = './spy/definition'+name+'_spynorth_scaling_untrust'+numb+'.txt'\n",
    "\n",
    "\n",
    "\n",
    "with codecs.open(filename1, 'r', encoding='utf-8-sig') as f:\n",
    "    lines1 = f.readlines()\n",
    "with codecs.open(filename2, 'r', encoding='utf-8-sig') as f:\n",
    "    lines2 = f.readlines()\n",
    "\n",
    "\n",
    "# test set\n",
    "\n",
    "\n",
    "with codecs.open('./spy/definition'+name+'_spynorth_test_t'+numb+'.txt', 'r', 'utf-8-sig') as f:\n",
    "    test1 = f.readlines()\n",
    "with codecs.open('./spy/definition'+name+'_spynorth_test_ut'+numb+'.txt', 'r', 'utf-8-sig') as f:\n",
    "    test2 = f.readlines()\n",
    "\n",
    "\n",
    "    \n",
    "\n",
    "\n",
    "from keras.layers import Input, Dense\n",
    "from keras.models import Model\n",
    "lines_t = lines1\n",
    "lines_ut = lines2\n",
    "test_t = test1\n",
    "test_ut = test2\n",
    "\n",
    "\n",
    "lines_ = []\n",
    "test_lines_ = []\n",
    "\n",
    "lines1_ = []\n",
    "lines2_ = []\n",
    "lines3_ = []\n",
    "lines4_ = []\n",
    "feature1 = []\n",
    "feature2 = []\n",
    "rating = []\n",
    "sentiment = []\n",
    "correlation = []\n",
    "\n",
    "for line in lines_t:\n",
    "    a = line.split(\",\")[:3]\n",
    "    a = list(map(float, a))\n",
    "    feature1.append(a)\n",
    "    \n",
    "    \n",
    "\n",
    "for line in lines_ut:\n",
    "    a = line.split(\",\")[:3]\n",
    "    a = list(map(float, a))\n",
    "    feature1.append(a)\n",
    "\n",
    "for line in test_t:\n",
    "    a = line.split(\",\")[:3]\n",
    "    a = list(map(float, a))\n",
    "    feature2.append(a)\n",
    "    \n",
    "for line in test_ut:\n",
    "    a = line.split(\",\")[:3]\n",
    "    a = list(map(float, a))\n",
    "    feature2.append(a)\n",
    "    \n",
    "    \n",
    "train_labels = [] # train 데이터 label\n",
    "test_labels = [] # test 데이터 label\n",
    "for i in range(len(lines_t)):\n",
    "    train_labels.append(1)\n",
    "for j in range(len(lines_ut)):\n",
    "    train_labels.append(0)\n",
    "for i in range(len(test_t)):\n",
    "    test_labels.append(1)\n",
    "for j in range(len(test_ut)):\n",
    "    test_labels.append(0)\n",
    "\n",
    "train_labels = np.asarray(train_labels)\n",
    "test_labels = np.asarray(test_labels)\n",
    "input_train = np.asarray(feature1)\n",
    "input_test = np.asarray(feature2)\n",
    "\n",
    "input_train = input_train.reshape(-1,1,3)\n",
    "input_test = input_test.reshape(-1,1,3)\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "x_train, x_valid, y_train, y_valid = train_test_split(input_train, train_labels, test_size=0.2, shuffle=True, stratify=train_labels, random_state=34)\n",
    "# LSTM\n",
    "from keras.layers import LSTM\n",
    "from tensorflow.python.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Embedding, SimpleRNN\n",
    "\n",
    "from keras.layers import Dense\n",
    "\n",
    "from keras.preprocessing import sequence\n",
    "\n",
    "model = Sequential()\n",
    "model.add(LSTM(32, return_sequences=True))\n",
    "model.add(LSTM(32))\n",
    "# 'binary_crossentropy\n",
    "model.add(Dense(5))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "model.compile(optimizer='rmsprop',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['acc'])\n",
    "\n",
    "from keras.callbacks import EarlyStopping\n",
    "early_stopping = EarlyStopping(monitor='val_acc', patience=10, mode='auto')\n",
    "\n",
    "history = model.fit(x_train, y_train,validation_data=(x_valid, y_valid),\n",
    "                    epochs=100,\n",
    "                    batch_size=100,callbacks=[early_stopping]\n",
    "                    )\n",
    "\n",
    "\n",
    "\n",
    "model.evaluate(input_test, test_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "606ba1d7",
   "metadata": {},
   "source": [
    "# 네번째"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bb223c7e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "35/35 [==============================] - 22s 89ms/step - loss: 0.6929 - acc: 0.5130 - val_loss: 0.6916 - val_acc: 0.5428\n",
      "Epoch 2/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 0.6921 - acc: 0.5341 - val_loss: 0.6906 - val_acc: 0.5579\n",
      "Epoch 3/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 0.6912 - acc: 0.5417 - val_loss: 0.6895 - val_acc: 0.5625\n",
      "Epoch 4/100\n",
      "35/35 [==============================] - 0s 12ms/step - loss: 0.6905 - acc: 0.5448 - val_loss: 0.6884 - val_acc: 0.5694\n",
      "Epoch 5/100\n",
      "35/35 [==============================] - 0s 11ms/step - loss: 0.6893 - acc: 0.5524 - val_loss: 0.6869 - val_acc: 0.5671\n",
      "Epoch 6/100\n",
      "35/35 [==============================] - 0s 11ms/step - loss: 0.6888 - acc: 0.5518 - val_loss: 0.6861 - val_acc: 0.5810\n",
      "Epoch 7/100\n",
      "35/35 [==============================] - 0s 10ms/step - loss: 0.6881 - acc: 0.5556 - val_loss: 0.6850 - val_acc: 0.5775\n",
      "Epoch 8/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 0.6873 - acc: 0.5668 - val_loss: 0.6842 - val_acc: 0.5822\n",
      "Epoch 9/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 0.6869 - acc: 0.5666 - val_loss: 0.6835 - val_acc: 0.5810\n",
      "Epoch 10/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 0.6864 - acc: 0.5660 - val_loss: 0.6831 - val_acc: 0.5903\n",
      "Epoch 11/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 0.6859 - acc: 0.5674 - val_loss: 0.6827 - val_acc: 0.5729\n",
      "Epoch 12/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 0.6848 - acc: 0.5628 - val_loss: 0.6839 - val_acc: 0.5880\n",
      "Epoch 13/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 0.6848 - acc: 0.5631 - val_loss: 0.6820 - val_acc: 0.5833\n",
      "Epoch 14/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 0.6843 - acc: 0.5671 - val_loss: 0.6818 - val_acc: 0.5625\n",
      "Epoch 15/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 0.6840 - acc: 0.5625 - val_loss: 0.6814 - val_acc: 0.5602\n",
      "Epoch 16/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 0.6833 - acc: 0.5573 - val_loss: 0.6810 - val_acc: 0.5590\n",
      "Epoch 17/100\n",
      "35/35 [==============================] - 0s 10ms/step - loss: 0.6829 - acc: 0.5637 - val_loss: 0.6808 - val_acc: 0.5579\n",
      "Epoch 18/100\n",
      "35/35 [==============================] - 0s 10ms/step - loss: 0.6826 - acc: 0.5570 - val_loss: 0.6803 - val_acc: 0.5729\n",
      "Epoch 19/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 0.6820 - acc: 0.5602 - val_loss: 0.6801 - val_acc: 0.5602\n",
      "Epoch 20/100\n",
      "35/35 [==============================] - 0s 10ms/step - loss: 0.6812 - acc: 0.5613 - val_loss: 0.6802 - val_acc: 0.5521\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 0.6847 - acc: 0.5333\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.6847025752067566, 0.5333333611488342]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras.preprocessing.text import Tokenizer\n",
    "import codecs\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "import numpy as np\n",
    "import nltk\n",
    "from konlpy.tag import Okt\n",
    "from tqdm import tqdm\n",
    "\n",
    "# train set\n",
    "name = \"2\"\n",
    "numb = \"4\"\n",
    "filename1 = './spy/definition'+name+'_spynorth_scaling_trust'+numb+'.txt'\n",
    "filename2 = './spy/definition'+name+'_spynorth_scaling_untrust'+numb+'.txt'\n",
    "\n",
    "\n",
    "\n",
    "with codecs.open(filename1, 'r', encoding='utf-8-sig') as f:\n",
    "    lines1 = f.readlines()\n",
    "with codecs.open(filename2, 'r', encoding='utf-8-sig') as f:\n",
    "    lines2 = f.readlines()\n",
    "\n",
    "\n",
    "# test set\n",
    "\n",
    "\n",
    "with codecs.open('./spy/definition'+name+'_spynorth_test_t'+numb+'.txt', 'r', 'utf-8-sig') as f:\n",
    "    test1 = f.readlines()\n",
    "with codecs.open('./spy/definition'+name+'_spynorth_test_ut'+numb+'.txt', 'r', 'utf-8-sig') as f:\n",
    "    test2 = f.readlines()\n",
    "\n",
    "\n",
    "    \n",
    "\n",
    "\n",
    "from keras.layers import Input, Dense\n",
    "from keras.models import Model\n",
    "lines_t = lines1\n",
    "lines_ut = lines2\n",
    "test_t = test1\n",
    "test_ut = test2\n",
    "\n",
    "\n",
    "lines_ = []\n",
    "test_lines_ = []\n",
    "\n",
    "lines1_ = []\n",
    "lines2_ = []\n",
    "lines3_ = []\n",
    "lines4_ = []\n",
    "feature1 = []\n",
    "feature2 = []\n",
    "rating = []\n",
    "sentiment = []\n",
    "correlation = []\n",
    "\n",
    "for line in lines_t:\n",
    "    a = line.split(\",\")[:3]\n",
    "    a = list(map(float, a))\n",
    "    feature1.append(a)\n",
    "    \n",
    "    \n",
    "\n",
    "for line in lines_ut:\n",
    "    a = line.split(\",\")[:3]\n",
    "    a = list(map(float, a))\n",
    "    feature1.append(a)\n",
    "\n",
    "for line in test_t:\n",
    "    a = line.split(\",\")[:3]\n",
    "    a = list(map(float, a))\n",
    "    feature2.append(a)\n",
    "    \n",
    "for line in test_ut:\n",
    "    a = line.split(\",\")[:3]\n",
    "    a = list(map(float, a))\n",
    "    feature2.append(a)\n",
    "    \n",
    "    \n",
    "train_labels = [] # train 데이터 label\n",
    "test_labels = [] # test 데이터 label\n",
    "for i in range(len(lines_t)):\n",
    "    train_labels.append(1)\n",
    "for j in range(len(lines_ut)):\n",
    "    train_labels.append(0)\n",
    "for i in range(len(test_t)):\n",
    "    test_labels.append(1)\n",
    "for j in range(len(test_ut)):\n",
    "    test_labels.append(0)\n",
    "\n",
    "train_labels = np.asarray(train_labels)\n",
    "test_labels = np.asarray(test_labels)\n",
    "input_train = np.asarray(feature1)\n",
    "input_test = np.asarray(feature2)\n",
    "\n",
    "input_train = input_train.reshape(-1,1,3)\n",
    "input_test = input_test.reshape(-1,1,3)\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "x_train, x_valid, y_train, y_valid = train_test_split(input_train, train_labels, test_size=0.2, shuffle=True, stratify=train_labels, random_state=34)\n",
    "# LSTM\n",
    "from keras.layers import LSTM\n",
    "from tensorflow.python.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Embedding, SimpleRNN\n",
    "\n",
    "from keras.layers import Dense\n",
    "\n",
    "from keras.preprocessing import sequence\n",
    "\n",
    "model = Sequential()\n",
    "model.add(LSTM(32, return_sequences=True))\n",
    "model.add(LSTM(32))\n",
    "# 'binary_crossentropy\n",
    "model.add(Dense(5))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "model.compile(optimizer='rmsprop',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['acc'])\n",
    "\n",
    "from keras.callbacks import EarlyStopping\n",
    "early_stopping = EarlyStopping(monitor='val_acc', patience=10, mode='auto')\n",
    "\n",
    "history = model.fit(x_train, y_train,validation_data=(x_valid, y_valid),\n",
    "                    epochs=100,\n",
    "                    batch_size=100,callbacks=[early_stopping]\n",
    "                    )\n",
    "\n",
    "\n",
    "\n",
    "model.evaluate(input_test, test_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ae84f3d",
   "metadata": {},
   "source": [
    "# 다섯번째"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "66297233",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "22/22 [==============================] - 20s 251ms/step - loss: 0.6923 - acc: 0.5381 - val_loss: 0.6910 - val_acc: 0.5441\n",
      "Epoch 2/100\n",
      "22/22 [==============================] - 0s 12ms/step - loss: 0.6914 - acc: 0.5400 - val_loss: 0.6902 - val_acc: 0.5441\n",
      "Epoch 3/100\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 0.6908 - acc: 0.5386 - val_loss: 0.6896 - val_acc: 0.5588\n",
      "Epoch 4/100\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 0.6905 - acc: 0.5506 - val_loss: 0.6889 - val_acc: 0.5441\n",
      "Epoch 5/100\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 0.6898 - acc: 0.5510 - val_loss: 0.6886 - val_acc: 0.5478\n",
      "Epoch 6/100\n",
      "22/22 [==============================] - 0s 11ms/step - loss: 0.6896 - acc: 0.5386 - val_loss: 0.6880 - val_acc: 0.5570\n",
      "Epoch 7/100\n",
      "22/22 [==============================] - 0s 11ms/step - loss: 0.6894 - acc: 0.5460 - val_loss: 0.6873 - val_acc: 0.5515\n",
      "Epoch 8/100\n",
      "22/22 [==============================] - 0s 11ms/step - loss: 0.6888 - acc: 0.5483 - val_loss: 0.6875 - val_acc: 0.5570\n",
      "Epoch 9/100\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 0.6888 - acc: 0.5418 - val_loss: 0.6864 - val_acc: 0.5533\n",
      "Epoch 10/100\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 0.6885 - acc: 0.5515 - val_loss: 0.6859 - val_acc: 0.5460\n",
      "Epoch 11/100\n",
      "22/22 [==============================] - 0s 11ms/step - loss: 0.6884 - acc: 0.5533 - val_loss: 0.6854 - val_acc: 0.5515\n",
      "Epoch 12/100\n",
      "22/22 [==============================] - 0s 11ms/step - loss: 0.6879 - acc: 0.5506 - val_loss: 0.6852 - val_acc: 0.5588\n",
      "Epoch 13/100\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 0.6877 - acc: 0.5528 - val_loss: 0.6841 - val_acc: 0.5551\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.6845 - acc: 0.5721\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.6844873428344727, 0.5720587968826294]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras.preprocessing.text import Tokenizer\n",
    "import codecs\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "import numpy as np\n",
    "import nltk\n",
    "from konlpy.tag import Okt\n",
    "from tqdm import tqdm\n",
    "\n",
    "# train set\n",
    "name = \"2\"\n",
    "numb = \"5\"\n",
    "filename1 = './spy/definition'+name+'_spynorth_scaling_trust'+numb+'.txt'\n",
    "filename2 = './spy/definition'+name+'_spynorth_scaling_untrust'+numb+'.txt'\n",
    "\n",
    "\n",
    "\n",
    "with codecs.open(filename1, 'r', encoding='utf-8-sig') as f:\n",
    "    lines1 = f.readlines()\n",
    "with codecs.open(filename2, 'r', encoding='utf-8-sig') as f:\n",
    "    lines2 = f.readlines()\n",
    "\n",
    "\n",
    "# test set\n",
    "\n",
    "\n",
    "with codecs.open('./spy/definition'+name+'_spynorth_test_t'+numb+'.txt', 'r', 'utf-8-sig') as f:\n",
    "    test1 = f.readlines()\n",
    "with codecs.open('./spy/definition'+name+'_spynorth_test_ut'+numb+'.txt', 'r', 'utf-8-sig') as f:\n",
    "    test2 = f.readlines()\n",
    "\n",
    "\n",
    "    \n",
    "\n",
    "\n",
    "from keras.layers import Input, Dense\n",
    "from keras.models import Model\n",
    "lines_t = lines1 \n",
    "lines_ut = lines2\n",
    "test_t = test1\n",
    "test_ut = test2\n",
    "\n",
    "\n",
    "lines_ = []\n",
    "test_lines_ = []\n",
    "\n",
    "lines1_ = []\n",
    "lines2_ = []\n",
    "lines3_ = []\n",
    "lines4_ = []\n",
    "feature1 = []\n",
    "feature2 = []\n",
    "rating = []\n",
    "sentiment = []\n",
    "correlation = []\n",
    "\n",
    "for line in lines_t:\n",
    "    a = line.split(\",\")[:3]\n",
    "    a = list(map(float, a))\n",
    "    feature1.append(a)\n",
    "    \n",
    "    \n",
    "\n",
    "for line in lines_ut:\n",
    "    a = line.split(\",\")[:3]\n",
    "    a = list(map(float, a))\n",
    "    feature1.append(a)\n",
    "\n",
    "for line in test_t:\n",
    "    a = line.split(\",\")[:3]\n",
    "    a = list(map(float, a))\n",
    "    feature2.append(a)\n",
    "    \n",
    "for line in test_ut:\n",
    "    a = line.split(\",\")[:3]\n",
    "    a = list(map(float, a))\n",
    "    feature2.append(a)\n",
    "    \n",
    "    \n",
    "train_labels = [] # train 데이터 label\n",
    "test_labels = [] # test 데이터 label\n",
    "for i in range(len(lines_t)):\n",
    "    train_labels.append(1)\n",
    "for j in range(len(lines_ut)):\n",
    "    train_labels.append(0)\n",
    "for i in range(len(test_t)):\n",
    "    test_labels.append(1)\n",
    "for j in range(len(test_ut)):\n",
    "    test_labels.append(0)\n",
    "\n",
    "train_labels = np.asarray(train_labels)\n",
    "test_labels = np.asarray(test_labels)\n",
    "input_train = np.asarray(feature1)\n",
    "input_test = np.asarray(feature2)\n",
    "\n",
    "input_train = input_train.reshape(-1,1,3)\n",
    "input_test = input_test.reshape(-1,1,3)\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "x_train, x_valid, y_train, y_valid = train_test_split(input_train, train_labels, test_size=0.2, shuffle=True, stratify=train_labels, random_state=34)\n",
    "# LSTM\n",
    "from keras.layers import LSTM\n",
    "from tensorflow.python.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Embedding, SimpleRNN\n",
    "\n",
    "from keras.layers import Dense\n",
    "\n",
    "from keras.preprocessing import sequence\n",
    "\n",
    "model = Sequential()\n",
    "model.add(LSTM(32, return_sequences=True))\n",
    "model.add(LSTM(32))\n",
    "# 'binary_crossentropy\n",
    "model.add(Dense(5))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "model.compile(optimizer='rmsprop',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['acc'])\n",
    "\n",
    "from keras.callbacks import EarlyStopping\n",
    "early_stopping = EarlyStopping(monitor='val_acc', patience=10, mode='auto')\n",
    "\n",
    "history = model.fit(x_train, y_train,validation_data=(x_valid, y_valid),\n",
    "                    epochs=100,\n",
    "                    batch_size=100,callbacks=[early_stopping]\n",
    "                    )\n",
    "\n",
    "\n",
    "\n",
    "model.evaluate(input_test, test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "65f23780",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "9/9 [==============================] - 14s 329ms/step - loss: 0.6939 - acc: 0.4866 - val_loss: 0.6928 - val_acc: 0.5000\n",
      "Epoch 2/100\n",
      "9/9 [==============================] - 0s 16ms/step - loss: 0.6930 - acc: 0.4955 - val_loss: 0.6921 - val_acc: 0.5000\n",
      "Epoch 3/100\n",
      "9/9 [==============================] - 0s 16ms/step - loss: 0.6927 - acc: 0.5000 - val_loss: 0.6918 - val_acc: 0.5491\n",
      "Epoch 4/100\n",
      "9/9 [==============================] - 0s 16ms/step - loss: 0.6921 - acc: 0.5391 - val_loss: 0.6914 - val_acc: 0.5536\n",
      "Epoch 5/100\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 0.6920 - acc: 0.5301 - val_loss: 0.6909 - val_acc: 0.5580\n",
      "Epoch 6/100\n",
      "9/9 [==============================] - 0s 34ms/step - loss: 0.6918 - acc: 0.5357 - val_loss: 0.6904 - val_acc: 0.5580\n",
      "Epoch 7/100\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.6914 - acc: 0.5324 - val_loss: 0.6901 - val_acc: 0.5625\n",
      "Epoch 8/100\n",
      "9/9 [==============================] - 0s 16ms/step - loss: 0.6910 - acc: 0.5346 - val_loss: 0.6898 - val_acc: 0.5625\n",
      "Epoch 9/100\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.6906 - acc: 0.5547 - val_loss: 0.6892 - val_acc: 0.5625\n",
      "Epoch 10/100\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 0.6911 - acc: 0.5368 - val_loss: 0.6891 - val_acc: 0.5670\n",
      "Epoch 11/100\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 0.6903 - acc: 0.5469 - val_loss: 0.6889 - val_acc: 0.5670\n",
      "Epoch 12/100\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 0.6900 - acc: 0.5658 - val_loss: 0.6885 - val_acc: 0.5670\n",
      "Epoch 13/100\n",
      "9/9 [==============================] - 0s 17ms/step - loss: 0.6906 - acc: 0.5502 - val_loss: 0.6884 - val_acc: 0.5670\n",
      "Epoch 14/100\n",
      "9/9 [==============================] - 0s 15ms/step - loss: 0.6897 - acc: 0.5513 - val_loss: 0.6882 - val_acc: 0.5714\n",
      "Epoch 15/100\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.6891 - acc: 0.5469 - val_loss: 0.6883 - val_acc: 0.6071\n",
      "Epoch 16/100\n",
      "9/9 [==============================] - 0s 15ms/step - loss: 0.6893 - acc: 0.5491 - val_loss: 0.6881 - val_acc: 0.5670\n",
      "Epoch 17/100\n",
      "9/9 [==============================] - 0s 17ms/step - loss: 0.6892 - acc: 0.5502 - val_loss: 0.6881 - val_acc: 0.5848\n",
      "Epoch 18/100\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.6886 - acc: 0.5603 - val_loss: 0.6882 - val_acc: 0.6161\n",
      "Epoch 19/100\n",
      "9/9 [==============================] - 0s 15ms/step - loss: 0.6881 - acc: 0.5558 - val_loss: 0.6879 - val_acc: 0.5848\n",
      "Epoch 20/100\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 0.6880 - acc: 0.5658 - val_loss: 0.6879 - val_acc: 0.5893\n",
      "Epoch 21/100\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 0.6878 - acc: 0.5647 - val_loss: 0.6885 - val_acc: 0.5402\n",
      "Epoch 22/100\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 0.6884 - acc: 0.5513 - val_loss: 0.6882 - val_acc: 0.5759\n",
      "Epoch 23/100\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.6872 - acc: 0.5636 - val_loss: 0.6879 - val_acc: 0.5938\n",
      "Epoch 24/100\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 0.6869 - acc: 0.5636 - val_loss: 0.6879 - val_acc: 0.6071\n",
      "Epoch 25/100\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.6871 - acc: 0.5658 - val_loss: 0.6884 - val_acc: 0.5580\n",
      "Epoch 26/100\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.6873 - acc: 0.5513 - val_loss: 0.6881 - val_acc: 0.6116\n",
      "Epoch 27/100\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 0.6862 - acc: 0.5603 - val_loss: 0.6883 - val_acc: 0.6071\n",
      "Epoch 28/100\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 0.6865 - acc: 0.5670 - val_loss: 0.6885 - val_acc: 0.5670\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.6843 - acc: 0.5464\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.6842746734619141, 0.5464285612106323]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras.preprocessing.text import Tokenizer\n",
    "import codecs\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "import numpy as np\n",
    "import nltk\n",
    "from konlpy.tag import Okt\n",
    "from tqdm import tqdm\n",
    "\n",
    "# train set\n",
    "name = \"2\"\n",
    "numb = \"6\"\n",
    "filename1 = './spy/definition'+name+'_spynorth_scaling_trust'+numb+'.txt'\n",
    "filename2 = './spy/definition'+name+'_spynorth_scaling_untrust'+numb+'.txt'\n",
    "\n",
    "\n",
    "\n",
    "with codecs.open(filename1, 'r', encoding='utf-8-sig') as f:\n",
    "    lines1 = f.readlines()\n",
    "with codecs.open(filename2, 'r', encoding='utf-8-sig') as f:\n",
    "    lines2 = f.readlines()\n",
    "\n",
    "\n",
    "# test set\n",
    "\n",
    "\n",
    "with codecs.open('./spy/definition'+name+'_spynorth_test_t'+numb+'.txt', 'r', 'utf-8-sig') as f:\n",
    "    test1 = f.readlines()\n",
    "with codecs.open('./spy/definition'+name+'_spynorth_test_ut'+numb+'.txt', 'r', 'utf-8-sig') as f:\n",
    "    test2 = f.readlines()\n",
    "\n",
    "\n",
    "    \n",
    "\n",
    "\n",
    "from keras.layers import Input, Dense\n",
    "from keras.models import Model\n",
    "lines_t = lines1 \n",
    "lines_ut = lines2\n",
    "test_t = test1\n",
    "test_ut = test2\n",
    "\n",
    "\n",
    "lines_ = []\n",
    "test_lines_ = []\n",
    "\n",
    "lines1_ = []\n",
    "lines2_ = []\n",
    "lines3_ = []\n",
    "lines4_ = []\n",
    "feature1 = []\n",
    "feature2 = []\n",
    "rating = []\n",
    "sentiment = []\n",
    "correlation = []\n",
    "\n",
    "for line in lines_t:\n",
    "    a = line.split(\",\")[:3]\n",
    "    a = list(map(float, a))\n",
    "    feature1.append(a)\n",
    "    \n",
    "    \n",
    "\n",
    "for line in lines_ut:\n",
    "    a = line.split(\",\")[:3]\n",
    "    a = list(map(float, a))\n",
    "    feature1.append(a)\n",
    "\n",
    "for line in test_t:\n",
    "    a = line.split(\",\")[:3]\n",
    "    a = list(map(float, a))\n",
    "    feature2.append(a)\n",
    "    \n",
    "for line in test_ut:\n",
    "    a = line.split(\",\")[:3]\n",
    "    a = list(map(float, a))\n",
    "    feature2.append(a)\n",
    "    \n",
    "    \n",
    "train_labels = [] # train 데이터 label\n",
    "test_labels = [] # test 데이터 label\n",
    "for i in range(len(lines_t)):\n",
    "    train_labels.append(1)\n",
    "for j in range(len(lines_ut)):\n",
    "    train_labels.append(0)\n",
    "for i in range(len(test_t)):\n",
    "    test_labels.append(1)\n",
    "for j in range(len(test_ut)):\n",
    "    test_labels.append(0)\n",
    "\n",
    "train_labels = np.asarray(train_labels)\n",
    "test_labels = np.asarray(test_labels)\n",
    "input_train = np.asarray(feature1)\n",
    "input_test = np.asarray(feature2)\n",
    "\n",
    "input_train = input_train.reshape(-1,1,3)\n",
    "input_test = input_test.reshape(-1,1,3)\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "x_train, x_valid, y_train, y_valid = train_test_split(input_train, train_labels, test_size=0.2, shuffle=True, stratify=train_labels, random_state=34)\n",
    "# LSTM\n",
    "from keras.layers import LSTM\n",
    "from tensorflow.python.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Embedding, SimpleRNN\n",
    "\n",
    "from keras.layers import Dense\n",
    "\n",
    "from keras.preprocessing import sequence\n",
    "\n",
    "model = Sequential()\n",
    "model.add(LSTM(32, return_sequences=True))\n",
    "model.add(LSTM(32))\n",
    "# 'binary_crossentropy\n",
    "model.add(Dense(5))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "model.compile(optimizer='rmsprop',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['acc'])\n",
    "\n",
    "from keras.callbacks import EarlyStopping\n",
    "early_stopping = EarlyStopping(monitor='val_acc', patience=10, mode='auto')\n",
    "\n",
    "history = model.fit(x_train, y_train,validation_data=(x_valid, y_valid),\n",
    "                    epochs=100,\n",
    "                    batch_size=100,callbacks=[early_stopping]\n",
    "                    )\n",
    "\n",
    "\n",
    "\n",
    "model.evaluate(input_test, test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8867de4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
