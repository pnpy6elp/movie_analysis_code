{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4ce3e63c",
   "metadata": {},
   "source": [
    "# definition 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "42af27b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.text import Tokenizer\n",
    "import codecs\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "import numpy as np\n",
    "import nltk\n",
    "from konlpy.tag import Okt\n",
    "from tqdm import tqdm\n",
    "\n",
    "# train set\n",
    "name = \"1\"\n",
    "filename1 = './new_data/definition'+name+'_spynorth_scaling_trust.txt'\n",
    "filename2 = './new_data/definition'+name+'_spynorth_scaling_untrust.txt'\n",
    "filename3 = './new_data/definition'+name+'_intistranger_scaling_trust.txt'\n",
    "filename4 = './new_data/definition'+name+'_intistranger_scaling_untrust.txt'\n",
    "filename5 = './new_data/definition'+name+'_assassin_scaling_trust.txt'\n",
    "filename6 = './new_data/definition'+name+'_assassin_scaling_untrust.txt'\n",
    "filename7 = './new_data/definition'+name+'_1987_scaling_trust.txt'\n",
    "filename8 = './new_data/definition'+name+'_1987_scaling_untrust.txt'\n",
    "filename9 = './new_data/definition'+name+'_taxi_scaling_trust.txt'\n",
    "filename10 = './new_data/definition'+name+'_taxi_scaling_untrust.txt'\n",
    "\n",
    "\n",
    "with codecs.open(filename1, 'r', encoding='utf-8-sig') as f:\n",
    "    lines1 = f.readlines()\n",
    "with codecs.open(filename2, 'r', encoding='utf-8-sig') as f:\n",
    "    lines2 = f.readlines()\n",
    "with codecs.open(filename3, 'r', encoding='utf-8-sig') as f:\n",
    "    lines3 = f.readlines()\n",
    "with codecs.open(filename4, 'r', encoding='utf-8-sig') as f:\n",
    "    lines4 = f.readlines()\n",
    "with codecs.open(filename5, 'r', encoding='utf-8-sig') as f:\n",
    "    lines5 = f.readlines()\n",
    "with codecs.open(filename6, 'r', encoding='utf-8-sig') as f:\n",
    "    lines6 = f.readlines()\n",
    "with codecs.open(filename7, 'r', encoding='utf-8-sig') as f:\n",
    "    lines7 = f.readlines()\n",
    "with codecs.open(filename8, 'r', encoding='utf-8-sig') as f:\n",
    "    lines8 = f.readlines()\n",
    "with codecs.open(filename9, 'r', encoding='utf-8-sig') as f:\n",
    "    lines9 = f.readlines()\n",
    "with codecs.open(filename10, 'r', encoding='utf-8-sig') as f:\n",
    "    lines10 = f.readlines()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# test set\n",
    "\n",
    "\n",
    "with codecs.open('./new_data/definition'+name+'_spynorth_test_t.txt', 'r', 'utf-8-sig') as f:\n",
    "    test1 = f.readlines()\n",
    "with codecs.open('./new_data/definition'+name+'_spynorth_test_ut.txt', 'r', 'utf-8-sig') as f:\n",
    "    test2 = f.readlines()\n",
    "with codecs.open('./new_data/definition'+name+'_intistranger_test_t.txt', 'r', encoding='utf-8-sig') as f:\n",
    "    test3 = f.readlines()\n",
    "with codecs.open('./new_data/definition'+name+'_intistranger_test_ut.txt', 'r', encoding='utf-8-sig') as f:\n",
    "    test4 = f.readlines()\n",
    "with codecs.open('./new_data/definition'+name+'_assassin_test_t.txt', 'r', encoding='utf-8-sig') as f:\n",
    "    test5 = f.readlines()\n",
    "with codecs.open('./new_data/definition'+name+'_assassin_test_ut.txt', 'r', encoding='utf-8-sig') as f:\n",
    "    test6 = f.readlines()\n",
    "with codecs.open('./new_data/definition'+name+'_1987_test_t.txt', 'r', encoding='utf-8-sig') as f:\n",
    "    test7 = f.readlines()\n",
    "with codecs.open('./new_data/definition'+name+'_1987_test_ut.txt', 'r', encoding='utf-8-sig') as f:\n",
    "    test8 = f.readlines()\n",
    "with codecs.open('./new_data/definition'+name+'_taxi_test_t.txt', 'r', encoding='utf-8-sig') as f:\n",
    "    test9 = f.readlines()\n",
    "with codecs.open('./new_data/definition'+name+'_taxi_test_ut.txt', 'r', encoding='utf-8-sig') as f:\n",
    "    test10 = f.readlines()\n",
    "\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d17aa8b4",
   "metadata": {},
   "source": [
    "## 공작"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c21da864",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Input, Dense\n",
    "from keras.models import Model\n",
    "lines_t = lines1\n",
    "lines_ut = lines2\n",
    "test_t = test1\n",
    "test_ut = test2\n",
    "\n",
    "\n",
    "lines_ = []\n",
    "test_lines_ = []\n",
    "\n",
    "lines1_ = []\n",
    "lines2_ = []\n",
    "lines3_ = []\n",
    "lines4_ = []\n",
    "feature1 = []\n",
    "feature2 = []\n",
    "rating = []\n",
    "sentiment = []\n",
    "correlation = []\n",
    "for line in lines_t:\n",
    "    text = line.split(\",\")[3]\n",
    "    lines_.append(text.strip())\n",
    "    a = line.split(\",\")[:3]\n",
    "    a = list(map(float, a))\n",
    "    feature1.append(a)\n",
    "    \n",
    "    \n",
    "\n",
    "for line in lines_ut:\n",
    "    text = line.split(\",\")[3]\n",
    "    lines_.append(text.strip())\n",
    "    a = line.split(\",\")[:3]\n",
    "    a = list(map(float, a))\n",
    "    feature1.append(a)\n",
    "\n",
    "for line in test_t:\n",
    "    text = line.split(\",\")[3]\n",
    "    test_lines_.append(text.strip())\n",
    "    a = line.split(\",\")[:3]\n",
    "    a = list(map(float, a))\n",
    "    feature2.append(a)\n",
    "    \n",
    "for line in test_ut:\n",
    "    text = line.split(\",\")[3]\n",
    "    test_lines_.append(text.strip())\n",
    "    a = line.split(\",\")[:3]\n",
    "    a = list(map(float, a))\n",
    "    feature2.append(a)\n",
    "    \n",
    "    \n",
    "train_labels = [] # train 데이터 label\n",
    "test_labels = [] # test 데이터 label\n",
    "for i in range(len(lines_t)):\n",
    "    train_labels.append(0)\n",
    "for j in range(len(lines_ut)):\n",
    "    train_labels.append(1)\n",
    "for i in range(len(test_t)):\n",
    "    test_labels.append(0)\n",
    "for j in range(len(test_ut)):\n",
    "    test_labels.append(1)\n",
    "\n",
    "train_labels = np.asarray(train_labels)\n",
    "test_labels = np.asarray(test_labels)\n",
    "input_train = np.asarray(feature1)\n",
    "input_test = np.asarray(feature2)\n",
    "\n",
    "input_train = input_train.reshape(-1,1,3)\n",
    "input_test = input_test.reshape(-1,1,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7edf4a9b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "50/50 [==============================] - 4s 3ms/step - loss: 0.6569 - acc: 0.7016\n",
      "Epoch 2/1000\n",
      "50/50 [==============================] - 0s 3ms/step - loss: 0.6186 - acc: 0.7053\n",
      "Epoch 3/1000\n",
      "50/50 [==============================] - 0s 3ms/step - loss: 0.5914 - acc: 0.7038\n",
      "Epoch 4/1000\n",
      "50/50 [==============================] - 0s 3ms/step - loss: 0.5750 - acc: 0.7064\n",
      "Epoch 5/1000\n",
      "50/50 [==============================] - 0s 3ms/step - loss: 0.5647 - acc: 0.7077\n",
      "Epoch 6/1000\n",
      "50/50 [==============================] - 0s 3ms/step - loss: 0.5581 - acc: 0.7097\n",
      "Epoch 7/1000\n",
      "50/50 [==============================] - 0s 3ms/step - loss: 0.5546 - acc: 0.7095\n",
      "Epoch 8/1000\n",
      "50/50 [==============================] - 0s 3ms/step - loss: 0.5526 - acc: 0.7103\n",
      "Epoch 9/1000\n",
      "50/50 [==============================] - 0s 3ms/step - loss: 0.5517 - acc: 0.7081\n",
      "Epoch 10/1000\n",
      "50/50 [==============================] - 0s 3ms/step - loss: 0.5512 - acc: 0.7117\n",
      "Epoch 11/1000\n",
      "50/50 [==============================] - 0s 3ms/step - loss: 0.5504 - acc: 0.7152\n",
      "Epoch 12/1000\n",
      "50/50 [==============================] - 0s 3ms/step - loss: 0.5501 - acc: 0.7111\n",
      "Epoch 13/1000\n",
      "50/50 [==============================] - 0s 3ms/step - loss: 0.5492 - acc: 0.7105\n",
      "Epoch 14/1000\n",
      "50/50 [==============================] - 0s 3ms/step - loss: 0.5481 - acc: 0.7144\n",
      "Epoch 15/1000\n",
      "50/50 [==============================] - 0s 3ms/step - loss: 0.5481 - acc: 0.7141\n",
      "Epoch 16/1000\n",
      "50/50 [==============================] - 0s 3ms/step - loss: 0.5482 - acc: 0.7153\n",
      "Epoch 17/1000\n",
      "50/50 [==============================] - 0s 3ms/step - loss: 0.5483 - acc: 0.7117\n",
      "Epoch 18/1000\n",
      "50/50 [==============================] - 0s 3ms/step - loss: 0.5477 - acc: 0.7127\n",
      "Epoch 19/1000\n",
      "50/50 [==============================] - 0s 3ms/step - loss: 0.5475 - acc: 0.7128\n",
      "Epoch 20/1000\n",
      "50/50 [==============================] - 0s 3ms/step - loss: 0.5472 - acc: 0.7119\n",
      "Epoch 21/1000\n",
      "50/50 [==============================] - 0s 3ms/step - loss: 0.5470 - acc: 0.7122\n",
      "Epoch 22/1000\n",
      "50/50 [==============================] - 0s 4ms/step - loss: 0.5470 - acc: 0.7122\n",
      "Epoch 23/1000\n",
      "50/50 [==============================] - 0s 3ms/step - loss: 0.5466 - acc: 0.7109\n",
      "Epoch 24/1000\n",
      "50/50 [==============================] - 0s 3ms/step - loss: 0.5464 - acc: 0.7105\n",
      "Epoch 25/1000\n",
      "50/50 [==============================] - 0s 3ms/step - loss: 0.5464 - acc: 0.7123\n",
      "Epoch 26/1000\n",
      "50/50 [==============================] - 0s 3ms/step - loss: 0.5462 - acc: 0.7123\n",
      "50/50 [==============================] - 2s 2ms/step - loss: 0.5476 - acc: 0.7125\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.5475931763648987, 0.7124999761581421]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras.layers import Input, Dense\n",
    "from keras.models import Model\n",
    "lines_t = lines1[:3200]\n",
    "lines_ut = lines2[:3200]\n",
    "test_t = test1[:800]\n",
    "test_ut = test2[:800]\n",
    "\n",
    "\n",
    "lines_ = []\n",
    "test_lines_ = []\n",
    "\n",
    "lines1_ = []\n",
    "lines2_ = []\n",
    "lines3_ = []\n",
    "lines4_ = []\n",
    "feature1 = []\n",
    "feature2 = []\n",
    "rating = []\n",
    "sentiment = []\n",
    "correlation = []\n",
    "\n",
    "for line in lines_t:\n",
    "    a = line.split(\",\")[:3]\n",
    "    a = list(map(float, a))\n",
    "    feature1.append(a)\n",
    "    \n",
    "    \n",
    "\n",
    "for line in lines_ut:\n",
    "    a = line.split(\",\")[:3]\n",
    "    a = list(map(float, a))\n",
    "    feature1.append(a)\n",
    "\n",
    "for line in test_t:\n",
    "    a = line.split(\",\")[:3]\n",
    "    a = list(map(float, a))\n",
    "    feature2.append(a)\n",
    "    \n",
    "for line in test_ut:\n",
    "    a = line.split(\",\")[:3]\n",
    "    a = list(map(float, a))\n",
    "    feature2.append(a)\n",
    "    \n",
    "    \n",
    "train_labels = [] # train 데이터 label\n",
    "test_labels = [] # test 데이터 label\n",
    "for i in range(len(lines_t)):\n",
    "    train_labels.append(1)\n",
    "for j in range(len(lines_ut)):\n",
    "    train_labels.append(0)\n",
    "for i in range(len(test_t)):\n",
    "    test_labels.append(1)\n",
    "for j in range(len(test_ut)):\n",
    "    test_labels.append(0)\n",
    "\n",
    "train_labels = np.asarray(train_labels)\n",
    "test_labels = np.asarray(test_labels)\n",
    "input_train = np.asarray(feature1)\n",
    "input_test = np.asarray(feature2)\n",
    "\n",
    "input_train = input_train.reshape(-1,1,3)\n",
    "input_test = input_test.reshape(-1,1,3)\n",
    "\n",
    "# LSTM\n",
    "from keras.layers import LSTM\n",
    "from tensorflow.python.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Embedding, SimpleRNN\n",
    "\n",
    "from keras.layers import Dense\n",
    "\n",
    "from keras.preprocessing import sequence\n",
    "\n",
    "model = Sequential()\n",
    "model.add(LSTM(32, return_sequences=True))\n",
    "model.add(LSTM(32))\n",
    "# 'binary_crossentropy\n",
    "model.add(Dense(5))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "model.compile(optimizer='rmsprop',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['acc'])\n",
    "\n",
    "from keras.callbacks import EarlyStopping\n",
    "early_stopping = EarlyStopping(monitor='acc', patience=10, mode='auto')\n",
    "\n",
    "history = model.fit(input_train, train_labels,\n",
    "                    epochs=1000,\n",
    "                    batch_size=128,callbacks=[early_stopping]\n",
    "                    )\n",
    "\n",
    "\n",
    "\n",
    "model.evaluate(input_test, test_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "236be201",
   "metadata": {},
   "source": [
    "## 공작 + 완벽한 타인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d7e26655",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "100/100 [==============================] - 5s 3ms/step - loss: 0.6672 - acc: 0.6413\n",
      "Epoch 2/1000\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 0.6262 - acc: 0.6503\n",
      "Epoch 3/1000\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 0.6041 - acc: 0.6576\n",
      "Epoch 4/1000\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 0.5952 - acc: 0.6594\n",
      "Epoch 5/1000\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 0.5917 - acc: 0.6612\n",
      "Epoch 6/1000\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 0.5903 - acc: 0.6627\n",
      "Epoch 7/1000\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 0.5894 - acc: 0.6616\n",
      "Epoch 8/1000\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 0.5886 - acc: 0.6652\n",
      "Epoch 9/1000\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 0.5884 - acc: 0.6642\n",
      "Epoch 10/1000\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 0.5880 - acc: 0.6672\n",
      "Epoch 11/1000\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 0.5880 - acc: 0.6631\n",
      "Epoch 12/1000\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 0.5871 - acc: 0.6616\n",
      "Epoch 13/1000\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 0.5872 - acc: 0.6655\n",
      "Epoch 14/1000\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 0.5872 - acc: 0.6679\n",
      "Epoch 15/1000\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 0.5869 - acc: 0.6653\n",
      "Epoch 16/1000\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 0.5867 - acc: 0.6659\n",
      "Epoch 17/1000\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 0.5866 - acc: 0.6669\n",
      "Epoch 18/1000\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 0.5863 - acc: 0.6668\n",
      "Epoch 19/1000\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 0.5865 - acc: 0.6666\n",
      "Epoch 20/1000\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 0.5863 - acc: 0.6660\n",
      "Epoch 21/1000\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 0.5866 - acc: 0.6695\n",
      "Epoch 22/1000\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 0.5864 - acc: 0.6647\n",
      "Epoch 23/1000\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 0.5858 - acc: 0.6680\n",
      "Epoch 24/1000\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 0.5863 - acc: 0.6690\n",
      "Epoch 25/1000\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 0.5857 - acc: 0.6635\n",
      "Epoch 26/1000\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 0.5860 - acc: 0.6691\n",
      "Epoch 27/1000\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 0.5860 - acc: 0.6680\n",
      "Epoch 28/1000\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 0.5858 - acc: 0.6663\n",
      "Epoch 29/1000\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 0.5866 - acc: 0.6671\n",
      "Epoch 30/1000\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 0.5852 - acc: 0.6698\n",
      "Epoch 31/1000\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 0.5858 - acc: 0.6678\n",
      "Epoch 32/1000\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 0.5857 - acc: 0.6659\n",
      "Epoch 33/1000\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 0.5850 - acc: 0.6667\n",
      "Epoch 34/1000\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 0.5860 - acc: 0.6679\n",
      "Epoch 35/1000\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 0.5855 - acc: 0.6659\n",
      "Epoch 36/1000\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 0.5852 - acc: 0.6698\n",
      "Epoch 37/1000\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 0.5851 - acc: 0.6671\n",
      "Epoch 38/1000\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 0.5855 - acc: 0.6691\n",
      "Epoch 39/1000\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 0.5852 - acc: 0.6669\n",
      "Epoch 40/1000\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 0.5857 - acc: 0.6677\n",
      "Epoch 41/1000\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 0.5851 - acc: 0.6691\n",
      "Epoch 42/1000\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 0.5849 - acc: 0.6685\n",
      "Epoch 43/1000\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 0.5857 - acc: 0.6690\n",
      "Epoch 44/1000\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 0.5849 - acc: 0.6667\n",
      "Epoch 45/1000\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 0.5855 - acc: 0.6687\n",
      "Epoch 46/1000\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 0.5855 - acc: 0.6666\n",
      "100/100 [==============================] - 1s 1ms/step - loss: 0.5908 - acc: 0.6687\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.5908125042915344, 0.668749988079071]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras.layers import Input, Dense\n",
    "from keras.models import Model\n",
    "lines_t = lines1[:3200] + lines3[:3200]\n",
    "lines_ut = lines2[:3200] + lines4[:3200]\n",
    "test_t = test1[:800] + test3[:800]\n",
    "test_ut = test2[:800] + test4[:800]\n",
    "\n",
    "\n",
    "lines_ = []\n",
    "test_lines_ = []\n",
    "\n",
    "lines1_ = []\n",
    "lines2_ = []\n",
    "lines3_ = []\n",
    "lines4_ = []\n",
    "feature1 = []\n",
    "feature2 = []\n",
    "rating = []\n",
    "sentiment = []\n",
    "correlation = []\n",
    "\n",
    "for line in lines_t:\n",
    "    a = line.split(\",\")[:3]\n",
    "    a = list(map(float, a))\n",
    "    feature1.append(a)\n",
    "    \n",
    "    \n",
    "\n",
    "for line in lines_ut:\n",
    "    a = line.split(\",\")[:3]\n",
    "    a = list(map(float, a))\n",
    "    feature1.append(a)\n",
    "\n",
    "for line in test_t:\n",
    "    a = line.split(\",\")[:3]\n",
    "    a = list(map(float, a))\n",
    "    feature2.append(a)\n",
    "    \n",
    "for line in test_ut:\n",
    "    a = line.split(\",\")[:3]\n",
    "    a = list(map(float, a))\n",
    "    feature2.append(a)\n",
    "    \n",
    "    \n",
    "train_labels = [] # train 데이터 label\n",
    "test_labels = [] # test 데이터 label\n",
    "for i in range(len(lines_t)):\n",
    "    train_labels.append(1)\n",
    "for j in range(len(lines_ut)):\n",
    "    train_labels.append(0)\n",
    "for i in range(len(test_t)):\n",
    "    test_labels.append(1)\n",
    "for j in range(len(test_ut)):\n",
    "    test_labels.append(0)\n",
    "\n",
    "train_labels = np.asarray(train_labels)\n",
    "test_labels = np.asarray(test_labels)\n",
    "input_train = np.asarray(feature1)\n",
    "input_test = np.asarray(feature2)\n",
    "\n",
    "input_train = input_train.reshape(-1,1,3)\n",
    "input_test = input_test.reshape(-1,1,3)\n",
    "\n",
    "# LSTM\n",
    "from keras.layers import LSTM\n",
    "from tensorflow.python.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Embedding, SimpleRNN\n",
    "\n",
    "from keras.layers import Dense\n",
    "\n",
    "from keras.preprocessing import sequence\n",
    "\n",
    "model = Sequential()\n",
    "model.add(LSTM(32, return_sequences=True))\n",
    "model.add(LSTM(32))\n",
    "# 'binary_crossentropy\n",
    "model.add(Dense(5))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "model.compile(optimizer='rmsprop',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['acc'])\n",
    "\n",
    "from keras.callbacks import EarlyStopping\n",
    "early_stopping = EarlyStopping(monitor='acc', patience=10, mode='auto')\n",
    "\n",
    "history = model.fit(input_train, train_labels,\n",
    "                    epochs=1000,\n",
    "                    batch_size=128,callbacks=[early_stopping]\n",
    "                    )\n",
    "\n",
    "\n",
    "\n",
    "model.evaluate(input_test, test_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ededfff",
   "metadata": {},
   "source": [
    "## 공작 + 완벽한 타인 + 암살"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0c589a71",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "150/150 [==============================] - 4s 3ms/step - loss: 0.6640 - acc: 0.6125\n",
      "Epoch 2/1000\n",
      "150/150 [==============================] - 0s 3ms/step - loss: 0.6277 - acc: 0.6247\n",
      "Epoch 3/1000\n",
      "150/150 [==============================] - 0s 3ms/step - loss: 0.6170 - acc: 0.6320\n",
      "Epoch 4/1000\n",
      "150/150 [==============================] - 0s 3ms/step - loss: 0.6141 - acc: 0.6342\n",
      "Epoch 5/1000\n",
      "150/150 [==============================] - 0s 3ms/step - loss: 0.6126 - acc: 0.6386\n",
      "Epoch 6/1000\n",
      "150/150 [==============================] - 0s 3ms/step - loss: 0.6116 - acc: 0.6382\n",
      "Epoch 7/1000\n",
      "150/150 [==============================] - 0s 3ms/step - loss: 0.6114 - acc: 0.6394\n",
      "Epoch 8/1000\n",
      "150/150 [==============================] - 0s 3ms/step - loss: 0.6110 - acc: 0.6368\n",
      "Epoch 9/1000\n",
      "150/150 [==============================] - 0s 3ms/step - loss: 0.6109 - acc: 0.6414\n",
      "Epoch 10/1000\n",
      "150/150 [==============================] - 0s 3ms/step - loss: 0.6101 - acc: 0.6386\n",
      "Epoch 11/1000\n",
      "150/150 [==============================] - 0s 3ms/step - loss: 0.6100 - acc: 0.6395\n",
      "Epoch 12/1000\n",
      "150/150 [==============================] - 0s 3ms/step - loss: 0.6092 - acc: 0.6433\n",
      "Epoch 13/1000\n",
      "150/150 [==============================] - 0s 3ms/step - loss: 0.6092 - acc: 0.6448\n",
      "Epoch 14/1000\n",
      "150/150 [==============================] - 1s 3ms/step - loss: 0.6094 - acc: 0.6408\n",
      "Epoch 15/1000\n",
      "150/150 [==============================] - 0s 3ms/step - loss: 0.6090 - acc: 0.6426\n",
      "Epoch 16/1000\n",
      "150/150 [==============================] - 0s 3ms/step - loss: 0.6094 - acc: 0.6386\n",
      "Epoch 17/1000\n",
      "150/150 [==============================] - 1s 4ms/step - loss: 0.6084 - acc: 0.6437\n",
      "Epoch 18/1000\n",
      "150/150 [==============================] - 0s 3ms/step - loss: 0.6088 - acc: 0.6428\n",
      "Epoch 19/1000\n",
      "150/150 [==============================] - 0s 3ms/step - loss: 0.6090 - acc: 0.6422\n",
      "Epoch 20/1000\n",
      "150/150 [==============================] - 0s 3ms/step - loss: 0.6084 - acc: 0.6426\n",
      "Epoch 21/1000\n",
      "150/150 [==============================] - 0s 3ms/step - loss: 0.6083 - acc: 0.6422\n",
      "Epoch 22/1000\n",
      "150/150 [==============================] - 0s 3ms/step - loss: 0.6084 - acc: 0.6416\n",
      "Epoch 23/1000\n",
      "150/150 [==============================] - 0s 3ms/step - loss: 0.6084 - acc: 0.6443\n",
      "150/150 [==============================] - 1s 2ms/step - loss: 0.6150 - acc: 0.6317\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.6150451898574829, 0.6316666603088379]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras.layers import Input, Dense\n",
    "from keras.models import Model\n",
    "lines_t = lines1[:3200] + lines3[:3200] + lines5[:3200]\n",
    "lines_ut = lines2[:3200] + lines4[:3200] + lines6[:3200]\n",
    "test_t = test1[:800] + test3[:800] + test5[:800]\n",
    "test_ut = test2[:800] + test4[:800] + test6[:800]\n",
    "\n",
    "\n",
    "lines_ = []\n",
    "test_lines_ = []\n",
    "\n",
    "lines1_ = []\n",
    "lines2_ = []\n",
    "lines3_ = []\n",
    "lines4_ = []\n",
    "feature1 = []\n",
    "feature2 = []\n",
    "rating = []\n",
    "sentiment = []\n",
    "correlation = []\n",
    "\n",
    "for line in lines_t:\n",
    "    a = line.split(\",\")[:3]\n",
    "    a = list(map(float, a))\n",
    "    feature1.append(a)\n",
    "    \n",
    "    \n",
    "\n",
    "for line in lines_ut:\n",
    "    a = line.split(\",\")[:3]\n",
    "    a = list(map(float, a))\n",
    "    feature1.append(a)\n",
    "\n",
    "for line in test_t:\n",
    "    a = line.split(\",\")[:3]\n",
    "    a = list(map(float, a))\n",
    "    feature2.append(a)\n",
    "    \n",
    "for line in test_ut:\n",
    "    a = line.split(\",\")[:3]\n",
    "    a = list(map(float, a))\n",
    "    feature2.append(a)\n",
    "    \n",
    "    \n",
    "train_labels = [] # train 데이터 label\n",
    "test_labels = [] # test 데이터 label\n",
    "for i in range(len(lines_t)):\n",
    "    train_labels.append(1)\n",
    "for j in range(len(lines_ut)):\n",
    "    train_labels.append(0)\n",
    "for i in range(len(test_t)):\n",
    "    test_labels.append(1)\n",
    "for j in range(len(test_ut)):\n",
    "    test_labels.append(0)\n",
    "\n",
    "train_labels = np.asarray(train_labels)\n",
    "test_labels = np.asarray(test_labels)\n",
    "input_train = np.asarray(feature1)\n",
    "input_test = np.asarray(feature2)\n",
    "\n",
    "input_train = input_train.reshape(-1,1,3)\n",
    "input_test = input_test.reshape(-1,1,3)\n",
    "\n",
    "# LSTM\n",
    "from keras.layers import LSTM\n",
    "from tensorflow.python.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Embedding, SimpleRNN\n",
    "\n",
    "from keras.layers import Dense\n",
    "\n",
    "from keras.preprocessing import sequence\n",
    "\n",
    "model = Sequential()\n",
    "model.add(LSTM(32, return_sequences=True))\n",
    "model.add(LSTM(32))\n",
    "# 'binary_crossentropy\n",
    "model.add(Dense(5))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "model.compile(optimizer='rmsprop',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['acc'])\n",
    "\n",
    "from keras.callbacks import EarlyStopping\n",
    "early_stopping = EarlyStopping(monitor='acc', patience=10, mode='auto')\n",
    "\n",
    "history = model.fit(input_train, train_labels,\n",
    "                    epochs=1000,\n",
    "                    batch_size=128,callbacks=[early_stopping]\n",
    "                    )\n",
    "\n",
    "\n",
    "\n",
    "model.evaluate(input_test, test_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecce03ba",
   "metadata": {},
   "source": [
    "## 공작 + 완벽한 타인 + 암살 + 1987"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "66a33c78",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "200/200 [==============================] - 6s 4ms/step - loss: 0.6655 - acc: 0.6003\n",
      "Epoch 2/1000\n",
      "200/200 [==============================] - 1s 4ms/step - loss: 0.6348 - acc: 0.6061\n",
      "Epoch 3/1000\n",
      "200/200 [==============================] - 1s 4ms/step - loss: 0.6283 - acc: 0.6167\n",
      "Epoch 4/1000\n",
      "200/200 [==============================] - 1s 4ms/step - loss: 0.6266 - acc: 0.6182\n",
      "Epoch 5/1000\n",
      "200/200 [==============================] - 1s 4ms/step - loss: 0.6260 - acc: 0.6205\n",
      "Epoch 6/1000\n",
      "200/200 [==============================] - 1s 3ms/step - loss: 0.6254 - acc: 0.6213\n",
      "Epoch 7/1000\n",
      "200/200 [==============================] - 1s 3ms/step - loss: 0.6250 - acc: 0.6212\n",
      "Epoch 8/1000\n",
      "200/200 [==============================] - 1s 3ms/step - loss: 0.6248 - acc: 0.6208\n",
      "Epoch 9/1000\n",
      "200/200 [==============================] - 1s 3ms/step - loss: 0.6241 - acc: 0.6214\n",
      "Epoch 10/1000\n",
      "200/200 [==============================] - 1s 3ms/step - loss: 0.6234 - acc: 0.6224\n",
      "Epoch 11/1000\n",
      "200/200 [==============================] - 1s 4ms/step - loss: 0.6235 - acc: 0.6236\n",
      "Epoch 12/1000\n",
      "200/200 [==============================] - 1s 3ms/step - loss: 0.6231 - acc: 0.6263\n",
      "Epoch 13/1000\n",
      "200/200 [==============================] - 1s 4ms/step - loss: 0.6229 - acc: 0.6248\n",
      "Epoch 14/1000\n",
      "200/200 [==============================] - 1s 4ms/step - loss: 0.6230 - acc: 0.6251\n",
      "Epoch 15/1000\n",
      "200/200 [==============================] - 1s 4ms/step - loss: 0.6230 - acc: 0.6208\n",
      "Epoch 16/1000\n",
      "200/200 [==============================] - 1s 4ms/step - loss: 0.6231 - acc: 0.6233\n",
      "Epoch 17/1000\n",
      "200/200 [==============================] - 1s 3ms/step - loss: 0.6224 - acc: 0.6237\n",
      "Epoch 18/1000\n",
      "200/200 [==============================] - 1s 4ms/step - loss: 0.6230 - acc: 0.6245\n",
      "Epoch 19/1000\n",
      "200/200 [==============================] - 1s 4ms/step - loss: 0.6228 - acc: 0.6227\n",
      "Epoch 20/1000\n",
      "200/200 [==============================] - 1s 3ms/step - loss: 0.6221 - acc: 0.6262\n",
      "Epoch 21/1000\n",
      "200/200 [==============================] - 1s 3ms/step - loss: 0.6222 - acc: 0.6263\n",
      "Epoch 22/1000\n",
      "200/200 [==============================] - 1s 4ms/step - loss: 0.6220 - acc: 0.6263\n",
      "Epoch 23/1000\n",
      "200/200 [==============================] - 1s 4ms/step - loss: 0.6224 - acc: 0.6269\n",
      "Epoch 24/1000\n",
      "200/200 [==============================] - 1s 5ms/step - loss: 0.6213 - acc: 0.6297\n",
      "Epoch 25/1000\n",
      "200/200 [==============================] - 1s 4ms/step - loss: 0.6218 - acc: 0.6280\n",
      "Epoch 26/1000\n",
      "200/200 [==============================] - 1s 3ms/step - loss: 0.6217 - acc: 0.6262\n",
      "Epoch 27/1000\n",
      "200/200 [==============================] - 1s 3ms/step - loss: 0.6217 - acc: 0.6267\n",
      "Epoch 28/1000\n",
      "200/200 [==============================] - 1s 5ms/step - loss: 0.6221 - acc: 0.6268\n",
      "Epoch 29/1000\n",
      "200/200 [==============================] - 1s 4ms/step - loss: 0.6215 - acc: 0.6280\n",
      "Epoch 30/1000\n",
      "200/200 [==============================] - 1s 5ms/step - loss: 0.6210 - acc: 0.6266\n",
      "Epoch 31/1000\n",
      "200/200 [==============================] - 1s 4ms/step - loss: 0.6212 - acc: 0.6284\n",
      "Epoch 32/1000\n",
      "200/200 [==============================] - 1s 4ms/step - loss: 0.6212 - acc: 0.6279\n",
      "Epoch 33/1000\n",
      "200/200 [==============================] - 1s 3ms/step - loss: 0.6211 - acc: 0.6274\n",
      "Epoch 34/1000\n",
      "200/200 [==============================] - 1s 3ms/step - loss: 0.6212 - acc: 0.6260\n",
      "200/200 [==============================] - 2s 1ms/step - loss: 0.6240 - acc: 0.6225\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.6239743232727051, 0.6225000023841858]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras.layers import Input, Dense\n",
    "from keras.models import Model\n",
    "lines_t = lines1[:3200] + lines3[:3200] + lines5[:3200] + lines7[:3200]\n",
    "lines_ut = lines2[:3200] + lines4[:3200] + lines6[:3200] + lines8[:3200]\n",
    "test_t = test1[:800] + test3[:800] + test5[:800] + test7[:800]\n",
    "test_ut = test2[:800] + test4[:800] + test6[:800] + test8[:800]\n",
    "\n",
    "\n",
    "lines_ = []\n",
    "test_lines_ = []\n",
    "\n",
    "lines1_ = []\n",
    "lines2_ = []\n",
    "lines3_ = []\n",
    "lines4_ = []\n",
    "feature1 = []\n",
    "feature2 = []\n",
    "rating = []\n",
    "sentiment = []\n",
    "correlation = []\n",
    "\n",
    "for line in lines_t:\n",
    "    a = line.split(\",\")[:3]\n",
    "    a = list(map(float, a))\n",
    "    feature1.append(a)\n",
    "    \n",
    "    \n",
    "\n",
    "for line in lines_ut:\n",
    "    a = line.split(\",\")[:3]\n",
    "    a = list(map(float, a))\n",
    "    feature1.append(a)\n",
    "\n",
    "for line in test_t:\n",
    "    a = line.split(\",\")[:3]\n",
    "    a = list(map(float, a))\n",
    "    feature2.append(a)\n",
    "    \n",
    "for line in test_ut:\n",
    "    a = line.split(\",\")[:3]\n",
    "    a = list(map(float, a))\n",
    "    feature2.append(a)\n",
    "    \n",
    "    \n",
    "train_labels = [] # train 데이터 label\n",
    "test_labels = [] # test 데이터 label\n",
    "for i in range(len(lines_t)):\n",
    "    train_labels.append(1)\n",
    "for j in range(len(lines_ut)):\n",
    "    train_labels.append(0)\n",
    "for i in range(len(test_t)):\n",
    "    test_labels.append(1)\n",
    "for j in range(len(test_ut)):\n",
    "    test_labels.append(0)\n",
    "\n",
    "train_labels = np.asarray(train_labels)\n",
    "test_labels = np.asarray(test_labels)\n",
    "input_train = np.asarray(feature1)\n",
    "input_test = np.asarray(feature2)\n",
    "\n",
    "input_train = input_train.reshape(-1,1,3)\n",
    "input_test = input_test.reshape(-1,1,3)\n",
    "\n",
    "# LSTM\n",
    "from keras.layers import LSTM\n",
    "from tensorflow.python.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Embedding, SimpleRNN\n",
    "\n",
    "from keras.layers import Dense\n",
    "\n",
    "from keras.preprocessing import sequence\n",
    "\n",
    "model = Sequential()\n",
    "model.add(LSTM(32, return_sequences=True))\n",
    "model.add(LSTM(32))\n",
    "# 'binary_crossentropy\n",
    "model.add(Dense(5))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "model.compile(optimizer='rmsprop',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['acc'])\n",
    "\n",
    "from keras.callbacks import EarlyStopping\n",
    "early_stopping = EarlyStopping(monitor='acc', patience=10, mode='auto')\n",
    "\n",
    "history = model.fit(input_train, train_labels,\n",
    "                    epochs=1000,\n",
    "                    batch_size=128,callbacks=[early_stopping]\n",
    "                    )\n",
    "\n",
    "\n",
    "model.evaluate(input_test, test_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b17fb0fd",
   "metadata": {},
   "source": [
    "## 공작 + 완벽한 타인 + 암살 + 1987 + 택시운전사"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c706e086",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "250/250 [==============================] - 4s 3ms/step - loss: 0.6606 - acc: 0.5938\n",
      "Epoch 2/1000\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.6362 - acc: 0.6041\n",
      "Epoch 3/1000\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.6330 - acc: 0.6070\n",
      "Epoch 4/1000\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.6317 - acc: 0.6080\n",
      "Epoch 5/1000\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 0.6314 - acc: 0.6134\n",
      "Epoch 6/1000\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.6309 - acc: 0.6109\n",
      "Epoch 7/1000\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.6307 - acc: 0.6109\n",
      "Epoch 8/1000\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.6300 - acc: 0.6151\n",
      "Epoch 9/1000\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.6299 - acc: 0.6145\n",
      "Epoch 10/1000\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.6298 - acc: 0.6162\n",
      "Epoch 11/1000\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.6291 - acc: 0.6166\n",
      "Epoch 12/1000\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.6291 - acc: 0.6144\n",
      "Epoch 13/1000\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.6288 - acc: 0.6183\n",
      "Epoch 14/1000\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.6287 - acc: 0.6169\n",
      "Epoch 15/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 0.6287 - acc: 0.6169\n",
      "Epoch 16/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 0.6284 - acc: 0.6180\n",
      "Epoch 17/1000\n",
      "250/250 [==============================] - 2s 6ms/step - loss: 0.6284 - acc: 0.6179\n",
      "Epoch 18/1000\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.6287 - acc: 0.6163\n",
      "Epoch 19/1000\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.6283 - acc: 0.6162\n",
      "Epoch 20/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 0.6281 - acc: 0.6187\n",
      "Epoch 21/1000\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.6281 - acc: 0.6202\n",
      "Epoch 22/1000\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 0.6281 - acc: 0.6186\n",
      "Epoch 23/1000\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.6276 - acc: 0.6191\n",
      "Epoch 24/1000\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.6277 - acc: 0.6195\n",
      "Epoch 25/1000\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.6278 - acc: 0.6183\n",
      "Epoch 26/1000\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 0.6280 - acc: 0.6190\n",
      "Epoch 27/1000\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.6274 - acc: 0.6176\n",
      "Epoch 28/1000\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.6272 - acc: 0.6179\n",
      "Epoch 29/1000\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.6273 - acc: 0.6188\n",
      "Epoch 30/1000\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.6270 - acc: 0.6187\n",
      "Epoch 31/1000\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.6274 - acc: 0.6191\n",
      "250/250 [==============================] - 2s 2ms/step - loss: 0.6269 - acc: 0.6223\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.6268675923347473, 0.6222500205039978]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras.layers import Input, Dense\n",
    "from keras.models import Model\n",
    "lines_t = lines1[:3200] + lines3[:3200] + lines5[:3200] + lines7[:3200] + lines9[:3200]\n",
    "lines_ut = lines2[:3200] + lines4[:3200] + lines6[:3200] + lines8[:3200] + lines10[:3200]\n",
    "test_t = test1[:800] + test3[:800] + test5[:800] + test7[:800] + test9[:800]\n",
    "test_ut = test2[:800] + test4[:800] + test6[:800] + test8[:800] + test10[:800]\n",
    "\n",
    "\n",
    "lines_ = []\n",
    "test_lines_ = []\n",
    "\n",
    "lines1_ = []\n",
    "lines2_ = []\n",
    "lines3_ = []\n",
    "lines4_ = []\n",
    "feature1 = []\n",
    "feature2 = []\n",
    "rating = []\n",
    "sentiment = []\n",
    "correlation = []\n",
    "\n",
    "for line in lines_t:\n",
    "    a = line.split(\",\")[:3]\n",
    "    a = list(map(float, a))\n",
    "    feature1.append(a)\n",
    "    \n",
    "    \n",
    "\n",
    "for line in lines_ut:\n",
    "    a = line.split(\",\")[:3]\n",
    "    a = list(map(float, a))\n",
    "    feature1.append(a)\n",
    "\n",
    "for line in test_t:\n",
    "    a = line.split(\",\")[:3]\n",
    "    a = list(map(float, a))\n",
    "    feature2.append(a)\n",
    "    \n",
    "for line in test_ut:\n",
    "    a = line.split(\",\")[:3]\n",
    "    a = list(map(float, a))\n",
    "    feature2.append(a)\n",
    "    \n",
    "    \n",
    "train_labels = [] # train 데이터 label\n",
    "test_labels = [] # test 데이터 label\n",
    "for i in range(len(lines_t)):\n",
    "    train_labels.append(1)\n",
    "for j in range(len(lines_ut)):\n",
    "    train_labels.append(0)\n",
    "for i in range(len(test_t)):\n",
    "    test_labels.append(1)\n",
    "for j in range(len(test_ut)):\n",
    "    test_labels.append(0)\n",
    "\n",
    "train_labels = np.asarray(train_labels)\n",
    "test_labels = np.asarray(test_labels)\n",
    "input_train = np.asarray(feature1)\n",
    "input_test = np.asarray(feature2)\n",
    "\n",
    "input_train = input_train.reshape(-1,1,3)\n",
    "input_test = input_test.reshape(-1,1,3)\n",
    "\n",
    "# LSTM\n",
    "from keras.layers import LSTM\n",
    "from tensorflow.python.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Embedding, SimpleRNN\n",
    "\n",
    "from keras.layers import Dense\n",
    "\n",
    "from keras.preprocessing import sequence\n",
    "\n",
    "model = Sequential()\n",
    "model.add(LSTM(32, return_sequences=True))\n",
    "model.add(LSTM(32))\n",
    "# 'binary_crossentropy\n",
    "model.add(Dense(5))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "model.compile(optimizer='rmsprop',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['acc'])\n",
    "\n",
    "from keras.callbacks import EarlyStopping\n",
    "early_stopping = EarlyStopping(monitor='acc', patience=10, mode='auto')\n",
    "\n",
    "history = model.fit(input_train, train_labels,\n",
    "                    epochs=1000,\n",
    "                    batch_size=128,callbacks=[early_stopping]\n",
    "                    )\n",
    "\n",
    "\n",
    "\n",
    "model.evaluate(input_test, test_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56c17ee6",
   "metadata": {},
   "source": [
    "## 완벽한 타인 + 암살"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0c83a665",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "100/100 [==============================] - 5s 3ms/step - loss: 0.6825 - acc: 0.5819\n",
      "Epoch 2/1000\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 0.6583 - acc: 0.5881\n",
      "Epoch 3/1000\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 0.6451 - acc: 0.5934\n",
      "Epoch 4/1000\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 0.6392 - acc: 0.5964\n",
      "Epoch 5/1000\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 0.6364 - acc: 0.5998\n",
      "Epoch 6/1000\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 0.6348 - acc: 0.6070\n",
      "Epoch 7/1000\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 0.6338 - acc: 0.6048\n",
      "Epoch 8/1000\n",
      "100/100 [==============================] - 0s 4ms/step - loss: 0.6334 - acc: 0.6053\n",
      "Epoch 9/1000\n",
      "100/100 [==============================] - 0s 4ms/step - loss: 0.6332 - acc: 0.6094\n",
      "Epoch 10/1000\n",
      "100/100 [==============================] - 0s 4ms/step - loss: 0.6328 - acc: 0.6093\n",
      "Epoch 11/1000\n",
      "100/100 [==============================] - 0s 4ms/step - loss: 0.6324 - acc: 0.6066\n",
      "Epoch 12/1000\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 0.6323 - acc: 0.6092\n",
      "Epoch 13/1000\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 0.6320 - acc: 0.6118\n",
      "Epoch 14/1000\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 0.6313 - acc: 0.6111\n",
      "Epoch 15/1000\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 0.6305 - acc: 0.6141\n",
      "Epoch 16/1000\n",
      "100/100 [==============================] - 0s 4ms/step - loss: 0.6306 - acc: 0.6138\n",
      "Epoch 17/1000\n",
      "100/100 [==============================] - 0s 4ms/step - loss: 0.6308 - acc: 0.6137\n",
      "Epoch 18/1000\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 0.6306 - acc: 0.6106\n",
      "Epoch 19/1000\n",
      "100/100 [==============================] - 0s 4ms/step - loss: 0.6293 - acc: 0.6124\n",
      "Epoch 20/1000\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 0.6290 - acc: 0.6160\n",
      "Epoch 21/1000\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 0.6295 - acc: 0.6118\n",
      "Epoch 22/1000\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 0.6292 - acc: 0.6186\n",
      "Epoch 23/1000\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 0.6295 - acc: 0.6142\n",
      "Epoch 24/1000\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 0.6291 - acc: 0.6128\n",
      "Epoch 25/1000\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 0.6284 - acc: 0.6166\n",
      "Epoch 26/1000\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 0.6289 - acc: 0.6129\n",
      "Epoch 27/1000\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 0.6286 - acc: 0.6164\n",
      "Epoch 28/1000\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 0.6277 - acc: 0.6135\n",
      "Epoch 29/1000\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 0.6280 - acc: 0.6179\n",
      "Epoch 30/1000\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 0.6285 - acc: 0.6109\n",
      "Epoch 31/1000\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 0.6276 - acc: 0.6181\n",
      "Epoch 32/1000\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 0.6283 - acc: 0.6176\n",
      "100/100 [==============================] - 2s 2ms/step - loss: 0.6317 - acc: 0.6219\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.6316524744033813, 0.621874988079071]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras.layers import Input, Dense\n",
    "from keras.models import Model\n",
    "lines_t = lines3[:3200] + lines5[:3200] \n",
    "lines_ut = lines4[:3200] + lines6[:3200]\n",
    "test_t = test3[:800] + test5[:800] \n",
    "test_ut = test4[:800] + test6[:800] \n",
    "\n",
    "\n",
    "lines_ = []\n",
    "test_lines_ = []\n",
    "\n",
    "lines1_ = []\n",
    "lines2_ = []\n",
    "lines3_ = []\n",
    "lines4_ = []\n",
    "feature1 = []\n",
    "feature2 = []\n",
    "rating = []\n",
    "sentiment = []\n",
    "correlation = []\n",
    "\n",
    "for line in lines_t:\n",
    "    a = line.split(\",\")[:3]\n",
    "    a = list(map(float, a))\n",
    "    feature1.append(a)\n",
    "    \n",
    "    \n",
    "\n",
    "for line in lines_ut:\n",
    "    a = line.split(\",\")[:3]\n",
    "    a = list(map(float, a))\n",
    "    feature1.append(a)\n",
    "\n",
    "for line in test_t:\n",
    "    a = line.split(\",\")[:3]\n",
    "    a = list(map(float, a))\n",
    "    feature2.append(a)\n",
    "    \n",
    "for line in test_ut:\n",
    "    a = line.split(\",\")[:3]\n",
    "    a = list(map(float, a))\n",
    "    feature2.append(a)\n",
    "    \n",
    "    \n",
    "train_labels = [] # train 데이터 label\n",
    "test_labels = [] # test 데이터 label\n",
    "for i in range(len(lines_t)):\n",
    "    train_labels.append(1)\n",
    "for j in range(len(lines_ut)):\n",
    "    train_labels.append(0)\n",
    "for i in range(len(test_t)):\n",
    "    test_labels.append(1)\n",
    "for j in range(len(test_ut)):\n",
    "    test_labels.append(0)\n",
    "\n",
    "train_labels = np.asarray(train_labels)\n",
    "test_labels = np.asarray(test_labels)\n",
    "input_train = np.asarray(feature1)\n",
    "input_test = np.asarray(feature2)\n",
    "\n",
    "input_train = input_train.reshape(-1,1,3)\n",
    "input_test = input_test.reshape(-1,1,3)\n",
    "\n",
    "# LSTM\n",
    "from keras.layers import LSTM\n",
    "from tensorflow.python.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Embedding, SimpleRNN\n",
    "\n",
    "from keras.layers import Dense\n",
    "\n",
    "from keras.preprocessing import sequence\n",
    "\n",
    "model = Sequential()\n",
    "model.add(LSTM(32, return_sequences=True))\n",
    "model.add(LSTM(32))\n",
    "# 'binary_crossentropy\n",
    "model.add(Dense(5))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "model.compile(optimizer='rmsprop',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['acc'])\n",
    "\n",
    "from keras.callbacks import EarlyStopping\n",
    "early_stopping = EarlyStopping(monitor='acc', patience=10, mode='auto')\n",
    "\n",
    "history = model.fit(input_train, train_labels,\n",
    "                    epochs=1000,\n",
    "                    batch_size=128,callbacks=[early_stopping]\n",
    "                    )\n",
    "\n",
    "\n",
    "\n",
    "model.evaluate(input_test, test_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15ef26b5",
   "metadata": {},
   "source": [
    "## 완벽한 타인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0ad9f956",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "50/50 [==============================] - 4s 3ms/step - loss: 0.6863 - acc: 0.5861\n",
      "Epoch 2/1000\n",
      "50/50 [==============================] - 0s 3ms/step - loss: 0.6761 - acc: 0.6059\n",
      "Epoch 3/1000\n",
      "50/50 [==============================] - 0s 3ms/step - loss: 0.6625 - acc: 0.6016\n",
      "Epoch 4/1000\n",
      "50/50 [==============================] - 0s 3ms/step - loss: 0.6501 - acc: 0.5983\n",
      "Epoch 5/1000\n",
      "50/50 [==============================] - 0s 3ms/step - loss: 0.6414 - acc: 0.5998\n",
      "Epoch 6/1000\n",
      "50/50 [==============================] - 0s 3ms/step - loss: 0.6356 - acc: 0.6025\n",
      "Epoch 7/1000\n",
      "50/50 [==============================] - 0s 4ms/step - loss: 0.6322 - acc: 0.6069\n",
      "Epoch 8/1000\n",
      "50/50 [==============================] - 0s 4ms/step - loss: 0.6295 - acc: 0.6117\n",
      "Epoch 9/1000\n",
      "50/50 [==============================] - 0s 4ms/step - loss: 0.6272 - acc: 0.6147\n",
      "Epoch 10/1000\n",
      "50/50 [==============================] - 0s 4ms/step - loss: 0.6252 - acc: 0.6194\n",
      "Epoch 11/1000\n",
      "50/50 [==============================] - 0s 3ms/step - loss: 0.6246 - acc: 0.6178\n",
      "Epoch 12/1000\n",
      "50/50 [==============================] - 0s 3ms/step - loss: 0.6235 - acc: 0.6216\n",
      "Epoch 13/1000\n",
      "50/50 [==============================] - 0s 4ms/step - loss: 0.6236 - acc: 0.6222\n",
      "Epoch 14/1000\n",
      "50/50 [==============================] - 0s 4ms/step - loss: 0.6225 - acc: 0.6247\n",
      "Epoch 15/1000\n",
      "50/50 [==============================] - 0s 3ms/step - loss: 0.6221 - acc: 0.6245\n",
      "Epoch 16/1000\n",
      "50/50 [==============================] - 0s 3ms/step - loss: 0.6222 - acc: 0.6242\n",
      "Epoch 17/1000\n",
      "50/50 [==============================] - 0s 3ms/step - loss: 0.6212 - acc: 0.6275\n",
      "Epoch 18/1000\n",
      "50/50 [==============================] - 0s 3ms/step - loss: 0.6213 - acc: 0.6270\n",
      "Epoch 19/1000\n",
      "50/50 [==============================] - 0s 4ms/step - loss: 0.6215 - acc: 0.6234\n",
      "Epoch 20/1000\n",
      "50/50 [==============================] - 0s 3ms/step - loss: 0.6211 - acc: 0.6250\n",
      "Epoch 21/1000\n",
      "50/50 [==============================] - 0s 3ms/step - loss: 0.6209 - acc: 0.6239\n",
      "Epoch 22/1000\n",
      "50/50 [==============================] - 0s 3ms/step - loss: 0.6209 - acc: 0.6284\n",
      "Epoch 23/1000\n",
      "50/50 [==============================] - 0s 3ms/step - loss: 0.6207 - acc: 0.6275\n",
      "Epoch 24/1000\n",
      "50/50 [==============================] - 0s 3ms/step - loss: 0.6206 - acc: 0.6313\n",
      "Epoch 25/1000\n",
      "50/50 [==============================] - 0s 3ms/step - loss: 0.6198 - acc: 0.6278\n",
      "Epoch 26/1000\n",
      "50/50 [==============================] - 0s 3ms/step - loss: 0.6200 - acc: 0.6259\n",
      "Epoch 27/1000\n",
      "50/50 [==============================] - 0s 3ms/step - loss: 0.6198 - acc: 0.6283\n",
      "Epoch 28/1000\n",
      "50/50 [==============================] - 0s 3ms/step - loss: 0.6198 - acc: 0.6286\n",
      "Epoch 29/1000\n",
      "50/50 [==============================] - 0s 3ms/step - loss: 0.6193 - acc: 0.6284\n",
      "Epoch 30/1000\n",
      "50/50 [==============================] - 0s 3ms/step - loss: 0.6199 - acc: 0.6248\n",
      "Epoch 31/1000\n",
      "50/50 [==============================] - 0s 3ms/step - loss: 0.6197 - acc: 0.6244\n",
      "Epoch 32/1000\n",
      "50/50 [==============================] - 0s 3ms/step - loss: 0.6186 - acc: 0.6236\n",
      "Epoch 33/1000\n",
      "50/50 [==============================] - 0s 3ms/step - loss: 0.6197 - acc: 0.6256\n",
      "Epoch 34/1000\n",
      "50/50 [==============================] - 0s 3ms/step - loss: 0.6190 - acc: 0.6270\n",
      "50/50 [==============================] - 2s 3ms/step - loss: 0.6301 - acc: 0.6250\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.6301122903823853, 0.625]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "from keras.models import Model\n",
    "lines_t = lines3[:3200]\n",
    "lines_ut = lines4[:3200]\n",
    "test_t = test3[:800]\n",
    "test_ut = test4[:800]\n",
    "\n",
    "\n",
    "lines_ = []\n",
    "test_lines_ = []\n",
    "\n",
    "lines1_ = []\n",
    "lines2_ = []\n",
    "lines3_ = []\n",
    "lines4_ = []\n",
    "feature1 = []\n",
    "feature2 = []\n",
    "rating = []\n",
    "sentiment = []\n",
    "correlation = []\n",
    "\n",
    "for line in lines_t:\n",
    "    a = line.split(\",\")[:3]\n",
    "    a = list(map(float, a))\n",
    "    feature1.append(a)\n",
    "    \n",
    "    \n",
    "\n",
    "for line in lines_ut:\n",
    "    a = line.split(\",\")[:3]\n",
    "    a = list(map(float, a))\n",
    "    feature1.append(a)\n",
    "\n",
    "for line in test_t:\n",
    "    a = line.split(\",\")[:3]\n",
    "    a = list(map(float, a))\n",
    "    feature2.append(a)\n",
    "    \n",
    "for line in test_ut:\n",
    "    a = line.split(\",\")[:3]\n",
    "    a = list(map(float, a))\n",
    "    feature2.append(a)\n",
    "    \n",
    "    \n",
    "train_labels = [] # train 데이터 label\n",
    "test_labels = [] # test 데이터 label\n",
    "for i in range(len(lines_t)):\n",
    "    train_labels.append(1)\n",
    "for j in range(len(lines_ut)):\n",
    "    train_labels.append(0)\n",
    "for i in range(len(test_t)):\n",
    "    test_labels.append(1)\n",
    "for j in range(len(test_ut)):\n",
    "    test_labels.append(0)\n",
    "\n",
    "train_labels = np.asarray(train_labels)\n",
    "test_labels = np.asarray(test_labels)\n",
    "input_train = np.asarray(feature1)\n",
    "input_test = np.asarray(feature2)\n",
    "\n",
    "input_train = input_train.reshape(-1,1,3)\n",
    "input_test = input_test.reshape(-1,1,3)\n",
    "\n",
    "# LSTM\n",
    "from keras.layers import LSTM\n",
    "from tensorflow.python.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Embedding, SimpleRNN\n",
    "\n",
    "from keras.layers import Dense\n",
    "\n",
    "from keras.preprocessing import sequence\n",
    "\n",
    "model = Sequential()\n",
    "model.add(LSTM(32, return_sequences=True))\n",
    "model.add(LSTM(32))\n",
    "# 'binary_crossentropy\n",
    "model.add(Dense(5))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "model.compile(optimizer='rmsprop',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['acc'])\n",
    "\n",
    "from keras.callbacks import EarlyStopping\n",
    "early_stopping = EarlyStopping(monitor='acc', patience=10, mode='auto')\n",
    "\n",
    "history = model.fit(input_train, train_labels,\n",
    "                    epochs=1000,\n",
    "                    batch_size=128,callbacks=[early_stopping]\n",
    "                    )\n",
    "\n",
    "model.evaluate(input_test, test_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "effabdd3",
   "metadata": {},
   "source": [
    "## 암살"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "90bc0ef4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "50/50 [==============================] - 5s 3ms/step - loss: 0.6886 - acc: 0.5723\n",
      "Epoch 2/1000\n",
      "50/50 [==============================] - 0s 3ms/step - loss: 0.6793 - acc: 0.5950\n",
      "Epoch 3/1000\n",
      "50/50 [==============================] - 0s 3ms/step - loss: 0.6681 - acc: 0.5900\n",
      "Epoch 4/1000\n",
      "50/50 [==============================] - 0s 3ms/step - loss: 0.6565 - acc: 0.5922\n",
      "Epoch 5/1000\n",
      "50/50 [==============================] - 0s 3ms/step - loss: 0.6500 - acc: 0.5952\n",
      "Epoch 6/1000\n",
      "50/50 [==============================] - 0s 3ms/step - loss: 0.6466 - acc: 0.5883\n",
      "Epoch 7/1000\n",
      "50/50 [==============================] - 0s 3ms/step - loss: 0.6436 - acc: 0.5933\n",
      "Epoch 8/1000\n",
      "50/50 [==============================] - 0s 3ms/step - loss: 0.6414 - acc: 0.5964\n",
      "Epoch 9/1000\n",
      "50/50 [==============================] - 0s 3ms/step - loss: 0.6400 - acc: 0.5994\n",
      "Epoch 10/1000\n",
      "50/50 [==============================] - 0s 3ms/step - loss: 0.6378 - acc: 0.6005\n",
      "Epoch 11/1000\n",
      "50/50 [==============================] - 0s 3ms/step - loss: 0.6378 - acc: 0.6030\n",
      "Epoch 12/1000\n",
      "50/50 [==============================] - 0s 3ms/step - loss: 0.6372 - acc: 0.6009\n",
      "Epoch 13/1000\n",
      "50/50 [==============================] - 0s 3ms/step - loss: 0.6370 - acc: 0.6012\n",
      "Epoch 14/1000\n",
      "50/50 [==============================] - 0s 3ms/step - loss: 0.6355 - acc: 0.6073\n",
      "Epoch 15/1000\n",
      "50/50 [==============================] - 0s 3ms/step - loss: 0.6360 - acc: 0.6072\n",
      "Epoch 16/1000\n",
      "50/50 [==============================] - 0s 3ms/step - loss: 0.6353 - acc: 0.6069\n",
      "Epoch 17/1000\n",
      "50/50 [==============================] - 0s 3ms/step - loss: 0.6357 - acc: 0.6022\n",
      "Epoch 18/1000\n",
      "50/50 [==============================] - 0s 3ms/step - loss: 0.6346 - acc: 0.6023\n",
      "Epoch 19/1000\n",
      "50/50 [==============================] - 0s 3ms/step - loss: 0.6353 - acc: 0.6052\n",
      "Epoch 20/1000\n",
      "50/50 [==============================] - 0s 3ms/step - loss: 0.6349 - acc: 0.6052\n",
      "Epoch 21/1000\n",
      "50/50 [==============================] - 0s 3ms/step - loss: 0.6344 - acc: 0.6041\n",
      "Epoch 22/1000\n",
      "50/50 [==============================] - 0s 3ms/step - loss: 0.6345 - acc: 0.6083\n",
      "Epoch 23/1000\n",
      "50/50 [==============================] - 0s 4ms/step - loss: 0.6343 - acc: 0.6053\n",
      "Epoch 24/1000\n",
      "50/50 [==============================] - 0s 3ms/step - loss: 0.6342 - acc: 0.6072\n",
      "Epoch 25/1000\n",
      "50/50 [==============================] - 0s 3ms/step - loss: 0.6342 - acc: 0.6042\n",
      "Epoch 26/1000\n",
      "50/50 [==============================] - 0s 3ms/step - loss: 0.6338 - acc: 0.6102\n",
      "Epoch 27/1000\n",
      "50/50 [==============================] - 0s 3ms/step - loss: 0.6335 - acc: 0.6069\n",
      "Epoch 28/1000\n",
      "50/50 [==============================] - 0s 3ms/step - loss: 0.6337 - acc: 0.6072\n",
      "Epoch 29/1000\n",
      "50/50 [==============================] - 0s 3ms/step - loss: 0.6325 - acc: 0.6139\n",
      "Epoch 30/1000\n",
      "50/50 [==============================] - 0s 3ms/step - loss: 0.6328 - acc: 0.6034\n",
      "Epoch 31/1000\n",
      "50/50 [==============================] - 0s 3ms/step - loss: 0.6330 - acc: 0.6102\n",
      "Epoch 32/1000\n",
      "50/50 [==============================] - 0s 3ms/step - loss: 0.6321 - acc: 0.6070\n",
      "Epoch 33/1000\n",
      "50/50 [==============================] - 0s 3ms/step - loss: 0.6320 - acc: 0.6108\n",
      "Epoch 34/1000\n",
      "50/50 [==============================] - 0s 3ms/step - loss: 0.6324 - acc: 0.6064\n",
      "Epoch 35/1000\n",
      "50/50 [==============================] - 0s 3ms/step - loss: 0.6319 - acc: 0.6077\n",
      "Epoch 36/1000\n",
      "50/50 [==============================] - 0s 3ms/step - loss: 0.6322 - acc: 0.6098\n",
      "Epoch 37/1000\n",
      "50/50 [==============================] - 0s 3ms/step - loss: 0.6317 - acc: 0.6119\n",
      "Epoch 38/1000\n",
      "50/50 [==============================] - 0s 3ms/step - loss: 0.6303 - acc: 0.6109\n",
      "Epoch 39/1000\n",
      "50/50 [==============================] - 0s 3ms/step - loss: 0.6313 - acc: 0.6058\n",
      "50/50 [==============================] - 2s 2ms/step - loss: 0.6269 - acc: 0.6106\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.6269325017929077, 0.6106250286102295]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras.layers import Input, Dense\n",
    "from keras.models import Model\n",
    "lines_t = lines5[:3200]\n",
    "lines_ut = lines6[:3200]\n",
    "test_t = test5[:800]\n",
    "test_ut = test6[:800]\n",
    "\n",
    "\n",
    "lines_ = []\n",
    "test_lines_ = []\n",
    "\n",
    "lines1_ = []\n",
    "lines2_ = []\n",
    "lines3_ = []\n",
    "lines4_ = []\n",
    "feature1 = []\n",
    "feature2 = []\n",
    "rating = []\n",
    "sentiment = []\n",
    "correlation = []\n",
    "\n",
    "for line in lines_t:\n",
    "    a = line.split(\",\")[:3]\n",
    "    a = list(map(float, a))\n",
    "    feature1.append(a)\n",
    "    \n",
    "    \n",
    "\n",
    "for line in lines_ut:\n",
    "    a = line.split(\",\")[:3]\n",
    "    a = list(map(float, a))\n",
    "    feature1.append(a)\n",
    "\n",
    "for line in test_t:\n",
    "    a = line.split(\",\")[:3]\n",
    "    a = list(map(float, a))\n",
    "    feature2.append(a)\n",
    "    \n",
    "for line in test_ut:\n",
    "    a = line.split(\",\")[:3]\n",
    "    a = list(map(float, a))\n",
    "    feature2.append(a)\n",
    "    \n",
    "    \n",
    "train_labels = [] # train 데이터 label\n",
    "test_labels = [] # test 데이터 label\n",
    "for i in range(len(lines_t)):\n",
    "    train_labels.append(1)\n",
    "for j in range(len(lines_ut)):\n",
    "    train_labels.append(0)\n",
    "for i in range(len(test_t)):\n",
    "    test_labels.append(1)\n",
    "for j in range(len(test_ut)):\n",
    "    test_labels.append(0)\n",
    "\n",
    "train_labels = np.asarray(train_labels)\n",
    "test_labels = np.asarray(test_labels)\n",
    "input_train = np.asarray(feature1)\n",
    "input_test = np.asarray(feature2)\n",
    "\n",
    "input_train = input_train.reshape(-1,1,3)\n",
    "input_test = input_test.reshape(-1,1,3)\n",
    "\n",
    "# LSTM\n",
    "from keras.layers import LSTM\n",
    "from tensorflow.python.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Embedding, SimpleRNN\n",
    "\n",
    "from keras.layers import Dense\n",
    "\n",
    "from keras.preprocessing import sequence\n",
    "\n",
    "model = Sequential()\n",
    "model.add(LSTM(32, return_sequences=True))\n",
    "model.add(LSTM(32))\n",
    "# 'binary_crossentropy\n",
    "model.add(Dense(5))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "model.compile(optimizer='rmsprop',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['acc'])\n",
    "\n",
    "from keras.callbacks import EarlyStopping\n",
    "early_stopping = EarlyStopping(monitor='acc', patience=10, mode='auto')\n",
    "\n",
    "history = model.fit(input_train, train_labels,\n",
    "                    epochs=1000,\n",
    "                    batch_size=128,callbacks=[early_stopping]\n",
    "                    )\n",
    "\n",
    "model.evaluate(input_test, test_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a91538ac",
   "metadata": {},
   "source": [
    "## 1987"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4d46026f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "50/50 [==============================] - 4s 4ms/step - loss: 0.6910 - acc: 0.5345\n",
      "Epoch 2/1000\n",
      "50/50 [==============================] - 0s 3ms/step - loss: 0.6859 - acc: 0.5619\n",
      "Epoch 3/1000\n",
      "50/50 [==============================] - 0s 3ms/step - loss: 0.6788 - acc: 0.5645\n",
      "Epoch 4/1000\n",
      "50/50 [==============================] - 0s 3ms/step - loss: 0.6699 - acc: 0.5716\n",
      "Epoch 5/1000\n",
      "50/50 [==============================] - 0s 4ms/step - loss: 0.6638 - acc: 0.5733\n",
      "Epoch 6/1000\n",
      "50/50 [==============================] - 0s 3ms/step - loss: 0.6615 - acc: 0.5673\n",
      "Epoch 7/1000\n",
      "50/50 [==============================] - 0s 4ms/step - loss: 0.6591 - acc: 0.5758\n",
      "Epoch 8/1000\n",
      "50/50 [==============================] - 0s 3ms/step - loss: 0.6587 - acc: 0.5700\n",
      "Epoch 9/1000\n",
      "50/50 [==============================] - 0s 4ms/step - loss: 0.6582 - acc: 0.5755\n",
      "Epoch 10/1000\n",
      "50/50 [==============================] - 0s 3ms/step - loss: 0.6587 - acc: 0.5741\n",
      "Epoch 11/1000\n",
      "50/50 [==============================] - 0s 4ms/step - loss: 0.6581 - acc: 0.5766\n",
      "Epoch 12/1000\n",
      "50/50 [==============================] - 0s 4ms/step - loss: 0.6575 - acc: 0.5747\n",
      "Epoch 13/1000\n",
      "50/50 [==============================] - 0s 4ms/step - loss: 0.6571 - acc: 0.5744\n",
      "Epoch 14/1000\n",
      "50/50 [==============================] - 0s 5ms/step - loss: 0.6570 - acc: 0.5753\n",
      "Epoch 15/1000\n",
      "50/50 [==============================] - 0s 4ms/step - loss: 0.6568 - acc: 0.5766\n",
      "Epoch 16/1000\n",
      "50/50 [==============================] - 0s 4ms/step - loss: 0.6568 - acc: 0.5794\n",
      "Epoch 17/1000\n",
      "50/50 [==============================] - 0s 4ms/step - loss: 0.6565 - acc: 0.5752\n",
      "Epoch 18/1000\n",
      "50/50 [==============================] - 0s 4ms/step - loss: 0.6567 - acc: 0.5738\n",
      "Epoch 19/1000\n",
      "50/50 [==============================] - 0s 4ms/step - loss: 0.6562 - acc: 0.5788\n",
      "Epoch 20/1000\n",
      "50/50 [==============================] - 0s 5ms/step - loss: 0.6567 - acc: 0.5794\n",
      "Epoch 21/1000\n",
      "50/50 [==============================] - 0s 5ms/step - loss: 0.6558 - acc: 0.5822\n",
      "Epoch 22/1000\n",
      "50/50 [==============================] - 0s 5ms/step - loss: 0.6566 - acc: 0.5836\n",
      "Epoch 23/1000\n",
      "50/50 [==============================] - 0s 4ms/step - loss: 0.6563 - acc: 0.5784\n",
      "Epoch 24/1000\n",
      "50/50 [==============================] - 0s 4ms/step - loss: 0.6559 - acc: 0.5805\n",
      "Epoch 25/1000\n",
      "50/50 [==============================] - 0s 5ms/step - loss: 0.6567 - acc: 0.5788\n",
      "Epoch 26/1000\n",
      "50/50 [==============================] - 0s 5ms/step - loss: 0.6565 - acc: 0.5784\n",
      "Epoch 27/1000\n",
      "50/50 [==============================] - 0s 3ms/step - loss: 0.6562 - acc: 0.5839\n",
      "Epoch 28/1000\n",
      "50/50 [==============================] - 0s 5ms/step - loss: 0.6561 - acc: 0.5800\n",
      "Epoch 29/1000\n",
      "50/50 [==============================] - 0s 4ms/step - loss: 0.6563 - acc: 0.5784\n",
      "Epoch 30/1000\n",
      "50/50 [==============================] - 0s 4ms/step - loss: 0.6559 - acc: 0.5791\n",
      "Epoch 31/1000\n",
      "50/50 [==============================] - 0s 4ms/step - loss: 0.6560 - acc: 0.5819\n",
      "Epoch 32/1000\n",
      "50/50 [==============================] - 0s 4ms/step - loss: 0.6559 - acc: 0.5777\n",
      "Epoch 33/1000\n",
      "50/50 [==============================] - 0s 4ms/step - loss: 0.6559 - acc: 0.5792\n",
      "Epoch 34/1000\n",
      "50/50 [==============================] - 0s 6ms/step - loss: 0.6559 - acc: 0.5827\n",
      "Epoch 35/1000\n",
      "50/50 [==============================] - 0s 4ms/step - loss: 0.6558 - acc: 0.5872\n",
      "Epoch 36/1000\n",
      "50/50 [==============================] - 0s 4ms/step - loss: 0.6558 - acc: 0.5775\n",
      "Epoch 37/1000\n",
      "50/50 [==============================] - 0s 4ms/step - loss: 0.6563 - acc: 0.5791\n",
      "Epoch 38/1000\n",
      "50/50 [==============================] - 0s 4ms/step - loss: 0.6558 - acc: 0.5838\n",
      "Epoch 39/1000\n",
      "50/50 [==============================] - 0s 4ms/step - loss: 0.6562 - acc: 0.5789\n",
      "Epoch 40/1000\n",
      "50/50 [==============================] - 0s 4ms/step - loss: 0.6557 - acc: 0.5806\n",
      "Epoch 41/1000\n",
      "50/50 [==============================] - 0s 4ms/step - loss: 0.6560 - acc: 0.5842\n",
      "Epoch 42/1000\n",
      "50/50 [==============================] - 0s 4ms/step - loss: 0.6556 - acc: 0.5809\n",
      "Epoch 43/1000\n",
      "50/50 [==============================] - 0s 4ms/step - loss: 0.6560 - acc: 0.5842\n",
      "Epoch 44/1000\n",
      "50/50 [==============================] - 0s 6ms/step - loss: 0.6554 - acc: 0.5823\n",
      "Epoch 45/1000\n",
      "50/50 [==============================] - 0s 5ms/step - loss: 0.6557 - acc: 0.5789\n",
      "50/50 [==============================] - 2s 2ms/step - loss: 0.6486 - acc: 0.5906\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.6486273407936096, 0.590624988079071]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras.layers import Input, Dense\n",
    "from keras.models import Model\n",
    "lines_t = lines7[:3200]\n",
    "lines_ut = lines8[:3200]\n",
    "test_t = test7[:800]\n",
    "test_ut = test8[:800]\n",
    "\n",
    "\n",
    "lines_ = []\n",
    "test_lines_ = []\n",
    "\n",
    "lines1_ = []\n",
    "lines2_ = []\n",
    "lines3_ = []\n",
    "lines4_ = []\n",
    "feature1 = []\n",
    "feature2 = []\n",
    "rating = []\n",
    "sentiment = []\n",
    "correlation = []\n",
    "\n",
    "for line in lines_t:\n",
    "    a = line.split(\",\")[:3]\n",
    "    a = list(map(float, a))\n",
    "    feature1.append(a)\n",
    "    \n",
    "    \n",
    "\n",
    "for line in lines_ut:\n",
    "    a = line.split(\",\")[:3]\n",
    "    a = list(map(float, a))\n",
    "    feature1.append(a)\n",
    "\n",
    "for line in test_t:\n",
    "    a = line.split(\",\")[:3]\n",
    "    a = list(map(float, a))\n",
    "    feature2.append(a)\n",
    "    \n",
    "for line in test_ut:\n",
    "    a = line.split(\",\")[:3]\n",
    "    a = list(map(float, a))\n",
    "    feature2.append(a)\n",
    "    \n",
    "    \n",
    "train_labels = [] # train 데이터 label\n",
    "test_labels = [] # test 데이터 label\n",
    "for i in range(len(lines_t)):\n",
    "    train_labels.append(1)\n",
    "for j in range(len(lines_ut)):\n",
    "    train_labels.append(0)\n",
    "for i in range(len(test_t)):\n",
    "    test_labels.append(1)\n",
    "for j in range(len(test_ut)):\n",
    "    test_labels.append(0)\n",
    "\n",
    "train_labels = np.asarray(train_labels)\n",
    "test_labels = np.asarray(test_labels)\n",
    "input_train = np.asarray(feature1)\n",
    "input_test = np.asarray(feature2)\n",
    "\n",
    "input_train = input_train.reshape(-1,1,3)\n",
    "input_test = input_test.reshape(-1,1,3)\n",
    "\n",
    "# LSTM\n",
    "from keras.layers import LSTM\n",
    "from tensorflow.python.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Embedding, SimpleRNN\n",
    "\n",
    "from keras.layers import Dense\n",
    "\n",
    "from keras.preprocessing import sequence\n",
    "\n",
    "model = Sequential()\n",
    "model.add(LSTM(32, return_sequences=True))\n",
    "model.add(LSTM(32))\n",
    "# 'binary_crossentropy\n",
    "model.add(Dense(5))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "model.compile(optimizer='rmsprop',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['acc'])\n",
    "\n",
    "from keras.callbacks import EarlyStopping\n",
    "early_stopping = EarlyStopping(monitor='acc', patience=10, mode='auto')\n",
    "\n",
    "history = model.fit(input_train, train_labels,\n",
    "                    epochs=1000,\n",
    "                    batch_size=128,callbacks=[early_stopping]\n",
    "                    )\n",
    "\n",
    "\n",
    "\n",
    "model.evaluate(input_test, test_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ddd14bb",
   "metadata": {},
   "source": [
    "## 택시운전사"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d61d0f39",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "50/50 [==============================] - 4s 4ms/step - loss: 0.6901 - acc: 0.5578\n",
      "Epoch 2/1000\n",
      "50/50 [==============================] - 0s 4ms/step - loss: 0.6813 - acc: 0.5867\n",
      "Epoch 3/1000\n",
      "50/50 [==============================] - 0s 4ms/step - loss: 0.6696 - acc: 0.5894\n",
      "Epoch 4/1000\n",
      "50/50 [==============================] - 0s 4ms/step - loss: 0.6576 - acc: 0.5819\n",
      "Epoch 5/1000\n",
      "50/50 [==============================] - 0s 4ms/step - loss: 0.6517 - acc: 0.5764\n",
      "Epoch 6/1000\n",
      "50/50 [==============================] - 0s 4ms/step - loss: 0.6486 - acc: 0.5758\n",
      "Epoch 7/1000\n",
      "50/50 [==============================] - 0s 4ms/step - loss: 0.6470 - acc: 0.5786\n",
      "Epoch 8/1000\n",
      "50/50 [==============================] - 0s 3ms/step - loss: 0.6463 - acc: 0.5817\n",
      "Epoch 9/1000\n",
      "50/50 [==============================] - 0s 4ms/step - loss: 0.6452 - acc: 0.5819\n",
      "Epoch 10/1000\n",
      "50/50 [==============================] - 0s 4ms/step - loss: 0.6447 - acc: 0.5844\n",
      "Epoch 11/1000\n",
      "50/50 [==============================] - 0s 4ms/step - loss: 0.6450 - acc: 0.5822\n",
      "Epoch 12/1000\n",
      "50/50 [==============================] - 0s 4ms/step - loss: 0.6441 - acc: 0.5838\n",
      "Epoch 13/1000\n",
      "50/50 [==============================] - 0s 4ms/step - loss: 0.6443 - acc: 0.5816\n",
      "50/50 [==============================] - 2s 2ms/step - loss: 0.6403 - acc: 0.5856\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.6402776837348938, 0.5856249928474426]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras.layers import Input, Dense\n",
    "from keras.models import Model\n",
    "lines_t = lines9[:3200]\n",
    "lines_ut = lines10[:3200]\n",
    "test_t = test9[:800]\n",
    "test_ut = test10[:800]\n",
    "\n",
    "\n",
    "lines_ = []\n",
    "test_lines_ = []\n",
    "\n",
    "lines1_ = []\n",
    "lines2_ = []\n",
    "lines3_ = []\n",
    "lines4_ = []\n",
    "feature1 = []\n",
    "feature2 = []\n",
    "rating = []\n",
    "sentiment = []\n",
    "correlation = []\n",
    "\n",
    "for line in lines_t:\n",
    "    a = line.split(\",\")[:3]\n",
    "    a = list(map(float, a))\n",
    "    feature1.append(a)\n",
    "    \n",
    "    \n",
    "\n",
    "for line in lines_ut:\n",
    "    a = line.split(\",\")[:3]\n",
    "    a = list(map(float, a))\n",
    "    feature1.append(a)\n",
    "\n",
    "for line in test_t:\n",
    "    a = line.split(\",\")[:3]\n",
    "    a = list(map(float, a))\n",
    "    feature2.append(a)\n",
    "    \n",
    "for line in test_ut:\n",
    "    a = line.split(\",\")[:3]\n",
    "    a = list(map(float, a))\n",
    "    feature2.append(a)\n",
    "    \n",
    "    \n",
    "train_labels = [] # train 데이터 label\n",
    "test_labels = [] # test 데이터 label\n",
    "for i in range(len(lines_t)):\n",
    "    train_labels.append(1)\n",
    "for j in range(len(lines_ut)):\n",
    "    train_labels.append(0)\n",
    "for i in range(len(test_t)):\n",
    "    test_labels.append(1)\n",
    "for j in range(len(test_ut)):\n",
    "    test_labels.append(0)\n",
    "\n",
    "train_labels = np.asarray(train_labels)\n",
    "test_labels = np.asarray(test_labels)\n",
    "input_train = np.asarray(feature1)\n",
    "input_test = np.asarray(feature2)\n",
    "\n",
    "input_train = input_train.reshape(-1,1,3)\n",
    "input_test = input_test.reshape(-1,1,3)\n",
    "\n",
    "# LSTM\n",
    "from keras.layers import LSTM\n",
    "from tensorflow.python.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Embedding, SimpleRNN\n",
    "\n",
    "from keras.layers import Dense\n",
    "\n",
    "from keras.preprocessing import sequence\n",
    "\n",
    "model = Sequential()\n",
    "model.add(LSTM(32, return_sequences=True))\n",
    "model.add(LSTM(32))\n",
    "# 'binary_crossentropy\n",
    "model.add(Dense(5))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "model.compile(optimizer='rmsprop',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['acc'])\n",
    "\n",
    "from keras.callbacks import EarlyStopping\n",
    "early_stopping = EarlyStopping(monitor='acc', patience=10, mode='auto')\n",
    "\n",
    "history = model.fit(input_train, train_labels,\n",
    "                    epochs=1000,\n",
    "                    batch_size=128,callbacks=[early_stopping]\n",
    "                    )\n",
    "\n",
    "\n",
    "model.evaluate(input_test, test_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fb872ef",
   "metadata": {},
   "source": [
    "## 택시운전사 - corelation과 sentiment만"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1e88c741",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "50/50 [==============================] - 4s 3ms/step - loss: 0.6914 - acc: 0.5400\n",
      "Epoch 2/1000\n",
      "50/50 [==============================] - 0s 3ms/step - loss: 0.6873 - acc: 0.5714\n",
      "Epoch 3/1000\n",
      "50/50 [==============================] - 0s 4ms/step - loss: 0.6830 - acc: 0.5750\n",
      "Epoch 4/1000\n",
      "50/50 [==============================] - 0s 4ms/step - loss: 0.6811 - acc: 0.5772\n",
      "Epoch 5/1000\n",
      "50/50 [==============================] - 0s 4ms/step - loss: 0.6802 - acc: 0.5750\n",
      "Epoch 6/1000\n",
      "50/50 [==============================] - 0s 4ms/step - loss: 0.6794 - acc: 0.5755\n",
      "Epoch 7/1000\n",
      "50/50 [==============================] - 0s 4ms/step - loss: 0.6787 - acc: 0.5764\n",
      "Epoch 8/1000\n",
      "50/50 [==============================] - 0s 3ms/step - loss: 0.6780 - acc: 0.5750\n",
      "Epoch 9/1000\n",
      "50/50 [==============================] - 0s 4ms/step - loss: 0.6772 - acc: 0.5734\n",
      "Epoch 10/1000\n",
      "50/50 [==============================] - 0s 3ms/step - loss: 0.6765 - acc: 0.5741\n",
      "Epoch 11/1000\n",
      "50/50 [==============================] - 0s 3ms/step - loss: 0.6760 - acc: 0.5697\n",
      "Epoch 12/1000\n",
      "50/50 [==============================] - 0s 4ms/step - loss: 0.6751 - acc: 0.5723\n",
      "Epoch 13/1000\n",
      "50/50 [==============================] - 0s 3ms/step - loss: 0.6745 - acc: 0.5677\n",
      "Epoch 14/1000\n",
      "50/50 [==============================] - 0s 3ms/step - loss: 0.6738 - acc: 0.5675\n",
      "50/50 [==============================] - 1s 2ms/step - loss: 0.6715 - acc: 0.5731\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.671456515789032, 0.5731250047683716]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras.layers import Input, Dense\n",
    "from keras.models import Model\n",
    "lines_t = lines9[:3200]\n",
    "lines_ut = lines10[:3200]\n",
    "test_t = test9[:800]\n",
    "test_ut = test10[:800]\n",
    "\n",
    "\n",
    "lines_ = []\n",
    "test_lines_ = []\n",
    "\n",
    "lines1_ = []\n",
    "lines2_ = []\n",
    "lines3_ = []\n",
    "lines4_ = []\n",
    "feature1 = []\n",
    "feature2 = []\n",
    "rating = []\n",
    "sentiment = []\n",
    "correlation = []\n",
    "\n",
    "for line in lines_t:\n",
    "    a = line.split(\",\")[1]\n",
    "    b = line.split(\",\")[2]\n",
    "    k = []\n",
    "    k.append(a)\n",
    "    k.append(b)\n",
    "    a = list(map(float, k))\n",
    "    feature1.append(a)\n",
    "    \n",
    "    \n",
    "\n",
    "for line in lines_ut:\n",
    "    a = line.split(\",\")[1]\n",
    "    b = line.split(\",\")[2]\n",
    "    k = []\n",
    "    k.append(a)\n",
    "    k.append(b)\n",
    "    a = list(map(float, k))\n",
    "    feature1.append(a)\n",
    "\n",
    "for line in test_t:\n",
    "    a = line.split(\",\")[1]\n",
    "    b = line.split(\",\")[2]\n",
    "    k = []\n",
    "    k.append(a)\n",
    "    k.append(b)\n",
    "    a = list(map(float, k))\n",
    "    feature2.append(a)\n",
    "    \n",
    "for line in test_ut:\n",
    "    a = line.split(\",\")[1]\n",
    "    b = line.split(\",\")[2]\n",
    "    k = []\n",
    "    k.append(a)\n",
    "    k.append(b)\n",
    "    a = list(map(float, k))\n",
    "    feature2.append(a)\n",
    "    \n",
    "    \n",
    "train_labels = [] # train 데이터 label\n",
    "test_labels = [] # test 데이터 label\n",
    "for i in range(len(lines_t)):\n",
    "    train_labels.append(1)\n",
    "for j in range(len(lines_ut)):\n",
    "    train_labels.append(0)\n",
    "for i in range(len(test_t)):\n",
    "    test_labels.append(1)\n",
    "for j in range(len(test_ut)):\n",
    "    test_labels.append(0)\n",
    "\n",
    "train_labels = np.asarray(train_labels)\n",
    "test_labels = np.asarray(test_labels)\n",
    "input_train = np.asarray(feature1)\n",
    "input_test = np.asarray(feature2)\n",
    "\n",
    "input_train = input_train.reshape(-1,1,2)\n",
    "input_test = input_test.reshape(-1,1,2)\n",
    "\n",
    "# LSTM\n",
    "from keras.layers import LSTM\n",
    "from tensorflow.python.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Embedding, SimpleRNN\n",
    "\n",
    "from keras.layers import Dense\n",
    "\n",
    "from keras.preprocessing import sequence\n",
    "\n",
    "model = Sequential()\n",
    "model.add(LSTM(32, return_sequences=True))\n",
    "model.add(LSTM(32))\n",
    "# 'binary_crossentropy\n",
    "model.add(Dense(5))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "model.compile(optimizer='rmsprop',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['acc'])\n",
    "\n",
    "from keras.callbacks import EarlyStopping\n",
    "early_stopping = EarlyStopping(monitor='acc', patience=10, mode='auto')\n",
    "\n",
    "history = model.fit(input_train, train_labels,\n",
    "                    epochs=1000,\n",
    "                    batch_size=128,callbacks=[early_stopping]\n",
    "                    )\n",
    "\n",
    "\n",
    "\n",
    "model.evaluate(input_test, test_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97575df0",
   "metadata": {},
   "source": [
    "# definition 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "898793cc",
   "metadata": {},
   "source": [
    "## 공작"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30ff7706",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "69d9ba7a",
   "metadata": {},
   "source": [
    "## 공작 + 완벽한 타인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a5c7616",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d6aac127",
   "metadata": {},
   "source": [
    "## 완벽한 타인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d17524c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "5f0db0bf",
   "metadata": {},
   "source": [
    "## 암살"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3088c2f9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "6332ce5b",
   "metadata": {},
   "source": [
    "## 1987"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ace1c6e0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39c9f44e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a147e4a1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86c21546",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a83fe89",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "bdc51c5e",
   "metadata": {},
   "source": [
    "# definition 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c4fa8bd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "384px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
