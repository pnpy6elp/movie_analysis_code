{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4ce3e63c",
   "metadata": {},
   "source": [
    "# definition 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "42af27b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.text import Tokenizer\n",
    "import codecs\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "import numpy as np\n",
    "import nltk\n",
    "from konlpy.tag import Okt\n",
    "from tqdm import tqdm\n",
    "\n",
    "# train set\n",
    "name = \"1\"\n",
    "filename1 = './new_data/definition'+name+'_spynorth_scaling_trust.txt'\n",
    "filename2 = './new_data/definition'+name+'_spynorth_scaling_untrust.txt'\n",
    "filename3 = './new_data/definition'+name+'_intistranger_scaling_trust.txt'\n",
    "filename4 = './new_data/definition'+name+'_intistranger_scaling_untrust.txt'\n",
    "filename5 = './new_data/definition'+name+'_assassin_scaling_trust.txt'\n",
    "filename6 = './new_data/definition'+name+'_assassin_scaling_untrust.txt'\n",
    "filename7 = './new_data/definition'+name+'_1987_scaling_trust.txt'\n",
    "filename8 = './new_data/definition'+name+'_1987_scaling_untrust.txt'\n",
    "filename9 = './new_data/definition'+name+'_taxi_scaling_trust.txt'\n",
    "filename10 = './new_data/definition'+name+'_taxi_scaling_untrust.txt'\n",
    "\n",
    "\n",
    "with codecs.open(filename1, 'r', encoding='utf-8-sig') as f:\n",
    "    lines1 = f.readlines()\n",
    "with codecs.open(filename2, 'r', encoding='utf-8-sig') as f:\n",
    "    lines2 = f.readlines()\n",
    "with codecs.open(filename3, 'r', encoding='utf-8-sig') as f:\n",
    "    lines3 = f.readlines()\n",
    "with codecs.open(filename4, 'r', encoding='utf-8-sig') as f:\n",
    "    lines4 = f.readlines()\n",
    "with codecs.open(filename5, 'r', encoding='utf-8-sig') as f:\n",
    "    lines5 = f.readlines()\n",
    "with codecs.open(filename6, 'r', encoding='utf-8-sig') as f:\n",
    "    lines6 = f.readlines()\n",
    "with codecs.open(filename7, 'r', encoding='utf-8-sig') as f:\n",
    "    lines7 = f.readlines()\n",
    "with codecs.open(filename8, 'r', encoding='utf-8-sig') as f:\n",
    "    lines8 = f.readlines()\n",
    "with codecs.open(filename9, 'r', encoding='utf-8-sig') as f:\n",
    "    lines9 = f.readlines()\n",
    "with codecs.open(filename10, 'r', encoding='utf-8-sig') as f:\n",
    "    lines10 = f.readlines()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# test set\n",
    "\n",
    "\n",
    "with codecs.open('./new_data/definition'+name+'_spynorth_test_t.txt', 'r', 'utf-8-sig') as f:\n",
    "    test1 = f.readlines()\n",
    "with codecs.open('./new_data/definition'+name+'_spynorth_test_ut.txt', 'r', 'utf-8-sig') as f:\n",
    "    test2 = f.readlines()\n",
    "with codecs.open('./new_data/definition'+name+'_intistranger_test_t.txt', 'r', encoding='utf-8-sig') as f:\n",
    "    test3 = f.readlines()\n",
    "with codecs.open('./new_data/definition'+name+'_intistranger_test_ut.txt', 'r', encoding='utf-8-sig') as f:\n",
    "    test4 = f.readlines()\n",
    "with codecs.open('./new_data/definition'+name+'_assassin_test_t.txt', 'r', encoding='utf-8-sig') as f:\n",
    "    test5 = f.readlines()\n",
    "with codecs.open('./new_data/definition'+name+'_assassin_test_ut.txt', 'r', encoding='utf-8-sig') as f:\n",
    "    test6 = f.readlines()\n",
    "with codecs.open('./new_data/definition'+name+'_1987_test_t.txt', 'r', encoding='utf-8-sig') as f:\n",
    "    test7 = f.readlines()\n",
    "with codecs.open('./new_data/definition'+name+'_1987_test_ut.txt', 'r', encoding='utf-8-sig') as f:\n",
    "    test8 = f.readlines()\n",
    "with codecs.open('./new_data/definition'+name+'_taxi_test_t.txt', 'r', encoding='utf-8-sig') as f:\n",
    "    test9 = f.readlines()\n",
    "with codecs.open('./new_data/definition'+name+'_taxi_test_ut.txt', 'r', encoding='utf-8-sig') as f:\n",
    "    test10 = f.readlines()\n",
    "\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d17aa8b4",
   "metadata": {},
   "source": [
    "## 공작"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c21da864",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Input, Dense\n",
    "from keras.models import Model\n",
    "lines_t = lines1[:2560]\n",
    "lines_ut = lines2[:2560]\n",
    "test_t = test1[:640]\n",
    "test_ut = test2[:640]\n",
    "\n",
    "\n",
    "lines_ = []\n",
    "test_lines_ = []\n",
    "\n",
    "lines1_ = []\n",
    "lines2_ = []\n",
    "lines3_ = []\n",
    "lines4_ = []\n",
    "feature1 = []\n",
    "feature2 = []\n",
    "rating = []\n",
    "sentiment = []\n",
    "correlation = []\n",
    "for line in lines_t:\n",
    "    text = line.split(\",\")[3]\n",
    "    lines_.append(text.strip())\n",
    "    a = line.split(\",\")[:3]\n",
    "    a = list(map(float, a))\n",
    "    feature1.append(a)\n",
    "    \n",
    "    \n",
    "\n",
    "for line in lines_ut:\n",
    "    text = line.split(\",\")[3]\n",
    "    lines_.append(text.strip())\n",
    "    a = line.split(\",\")[:3]\n",
    "    a = list(map(float, a))\n",
    "    feature1.append(a)\n",
    "\n",
    "for line in test_t:\n",
    "    text = line.split(\",\")[3]\n",
    "    test_lines_.append(text.strip())\n",
    "    a = line.split(\",\")[:3]\n",
    "    a = list(map(float, a))\n",
    "    feature2.append(a)\n",
    "    \n",
    "for line in test_ut:\n",
    "    text = line.split(\",\")[3]\n",
    "    test_lines_.append(text.strip())\n",
    "    a = line.split(\",\")[:3]\n",
    "    a = list(map(float, a))\n",
    "    feature2.append(a)\n",
    "    \n",
    "    \n",
    "train_labels = [] # train 데이터 label\n",
    "test_labels = [] # test 데이터 label\n",
    "for i in range(len(lines_t)):\n",
    "    train_labels.append(0)\n",
    "for j in range(len(lines_ut)):\n",
    "    train_labels.append(1)\n",
    "for i in range(len(test_t)):\n",
    "    test_labels.append(0)\n",
    "for j in range(len(test_ut)):\n",
    "    test_labels.append(1)\n",
    "\n",
    "train_labels = np.asarray(train_labels)\n",
    "test_labels = np.asarray(test_labels)\n",
    "input_train = np.asarray(feature1)\n",
    "input_test = np.asarray(feature2)\n",
    "\n",
    "input_train = input_train.reshape(-1,1,3)\n",
    "input_test = input_test.reshape(-1,1,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7edf4a9b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "41/41 [==============================] - 13s 38ms/step - loss: 0.6819 - acc: 0.5596 - val_loss: 0.6630 - val_acc: 0.7090\n",
      "Epoch 2/100\n",
      "41/41 [==============================] - 0s 5ms/step - loss: 0.6499 - acc: 0.7012 - val_loss: 0.6304 - val_acc: 0.7168\n",
      "Epoch 3/100\n",
      "41/41 [==============================] - 0s 6ms/step - loss: 0.6224 - acc: 0.7007 - val_loss: 0.6033 - val_acc: 0.7168\n",
      "Epoch 4/100\n",
      "41/41 [==============================] - 0s 7ms/step - loss: 0.6011 - acc: 0.7000 - val_loss: 0.5841 - val_acc: 0.7148\n",
      "Epoch 5/100\n",
      "41/41 [==============================] - 0s 7ms/step - loss: 0.5875 - acc: 0.7000 - val_loss: 0.5717 - val_acc: 0.7168\n",
      "Epoch 6/100\n",
      "41/41 [==============================] - 0s 6ms/step - loss: 0.5793 - acc: 0.7009 - val_loss: 0.5639 - val_acc: 0.7188\n",
      "Epoch 7/100\n",
      "41/41 [==============================] - 0s 8ms/step - loss: 0.5729 - acc: 0.7014 - val_loss: 0.5604 - val_acc: 0.7188\n",
      "Epoch 8/100\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 0.5699 - acc: 0.7024 - val_loss: 0.5546 - val_acc: 0.7119\n",
      "Epoch 9/100\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 0.5661 - acc: 0.7021 - val_loss: 0.5519 - val_acc: 0.7119\n",
      "Epoch 10/100\n",
      "41/41 [==============================] - 0s 8ms/step - loss: 0.5642 - acc: 0.7017 - val_loss: 0.5497 - val_acc: 0.7119\n",
      "Epoch 11/100\n",
      "41/41 [==============================] - 0s 7ms/step - loss: 0.5627 - acc: 0.7024 - val_loss: 0.5466 - val_acc: 0.7119\n",
      "Epoch 12/100\n",
      "41/41 [==============================] - 0s 6ms/step - loss: 0.5620 - acc: 0.6997 - val_loss: 0.5458 - val_acc: 0.7119\n",
      "Epoch 13/100\n",
      "41/41 [==============================] - 0s 6ms/step - loss: 0.5609 - acc: 0.7043 - val_loss: 0.5443 - val_acc: 0.7119\n",
      "Epoch 14/100\n",
      "41/41 [==============================] - 0s 6ms/step - loss: 0.5612 - acc: 0.7012 - val_loss: 0.5451 - val_acc: 0.7168\n",
      "Epoch 15/100\n",
      "41/41 [==============================] - 0s 8ms/step - loss: 0.5600 - acc: 0.7036 - val_loss: 0.5426 - val_acc: 0.7090\n",
      "Epoch 16/100\n",
      "41/41 [==============================] - 0s 7ms/step - loss: 0.5586 - acc: 0.7039 - val_loss: 0.5416 - val_acc: 0.7119\n",
      "40/40 [==============================] - 2s 3ms/step - loss: 0.5415 - acc: 0.7117\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.5415308475494385, 0.711718738079071]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras.layers import Input, Dense\n",
    "from keras.models import Model\n",
    "\n",
    "\n",
    "\n",
    "lines_ = []\n",
    "test_lines_ = []\n",
    "\n",
    "lines1_ = []\n",
    "lines2_ = []\n",
    "lines3_ = []\n",
    "lines4_ = []\n",
    "feature1 = []\n",
    "feature2 = []\n",
    "rating = []\n",
    "sentiment = []\n",
    "correlation = []\n",
    "\n",
    "for line in lines_t:\n",
    "    a = line.split(\",\")[:3]\n",
    "    a = list(map(float, a))\n",
    "    feature1.append(a)\n",
    "    \n",
    "    \n",
    "\n",
    "for line in lines_ut:\n",
    "    a = line.split(\",\")[:3]\n",
    "    a = list(map(float, a))\n",
    "    feature1.append(a)\n",
    "\n",
    "for line in test_t:\n",
    "    a = line.split(\",\")[:3]\n",
    "    a = list(map(float, a))\n",
    "    feature2.append(a)\n",
    "    \n",
    "for line in test_ut:\n",
    "    a = line.split(\",\")[:3]\n",
    "    a = list(map(float, a))\n",
    "    feature2.append(a)\n",
    "    \n",
    "    \n",
    "train_labels = [] # train 데이터 label\n",
    "test_labels = [] # test 데이터 label\n",
    "for i in range(len(lines_t)):\n",
    "    train_labels.append(1)\n",
    "for j in range(len(lines_ut)):\n",
    "    train_labels.append(0)\n",
    "for i in range(len(test_t)):\n",
    "    test_labels.append(1)\n",
    "for j in range(len(test_ut)):\n",
    "    test_labels.append(0)\n",
    "\n",
    "train_labels = np.asarray(train_labels)\n",
    "test_labels = np.asarray(test_labels)\n",
    "input_train = np.asarray(feature1)\n",
    "input_test = np.asarray(feature2)\n",
    "\n",
    "input_train = input_train.reshape(-1,1,3)\n",
    "input_test = input_test.reshape(-1,1,3)\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "x_train, x_valid, y_train, y_valid = train_test_split(input_train, train_labels, test_size=0.2, shuffle=True, stratify=train_labels, random_state=34)\n",
    "# LSTM\n",
    "from keras.layers import LSTM\n",
    "from tensorflow.python.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Embedding, SimpleRNN\n",
    "\n",
    "from keras.layers import Dense\n",
    "\n",
    "from keras.preprocessing import sequence\n",
    "\n",
    "model = Sequential()\n",
    "model.add(LSTM(32, return_sequences=True))\n",
    "model.add(LSTM(32))\n",
    "# 'binary_crossentropy\n",
    "model.add(Dense(5))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "model.compile(optimizer='rmsprop',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['acc'])\n",
    "\n",
    "from keras.callbacks import EarlyStopping\n",
    "early_stopping = EarlyStopping(monitor='val_acc', patience=10, mode='auto')\n",
    "\n",
    "history = model.fit(x_train, y_train,validation_data=(x_valid, y_valid),\n",
    "                    epochs=100,\n",
    "                    batch_size=100,callbacks=[early_stopping]\n",
    "                    )\n",
    "\n",
    "\n",
    "\n",
    "model.evaluate(input_test, test_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "236be201",
   "metadata": {},
   "source": [
    "## 공작 + 완벽한 타인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d7e26655",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "82/82 [==============================] - 13s 38ms/step - loss: 0.6741 - acc: 0.6241 - val_loss: 0.6611 - val_acc: 0.6470\n",
      "Epoch 2/100\n",
      "82/82 [==============================] - 1s 9ms/step - loss: 0.6440 - acc: 0.6556 - val_loss: 0.6367 - val_acc: 0.6440\n",
      "Epoch 3/100\n",
      "82/82 [==============================] - 1s 10ms/step - loss: 0.6203 - acc: 0.6543 - val_loss: 0.6266 - val_acc: 0.6475\n",
      "Epoch 4/100\n",
      "82/82 [==============================] - 1s 10ms/step - loss: 0.6078 - acc: 0.6587 - val_loss: 0.6126 - val_acc: 0.6475\n",
      "Epoch 5/100\n",
      "82/82 [==============================] - 1s 10ms/step - loss: 0.6009 - acc: 0.6584 - val_loss: 0.6086 - val_acc: 0.6455\n",
      "Epoch 6/100\n",
      "82/82 [==============================] - 1s 11ms/step - loss: 0.5974 - acc: 0.6603 - val_loss: 0.6053 - val_acc: 0.6431\n",
      "Epoch 7/100\n",
      "82/82 [==============================] - 1s 9ms/step - loss: 0.5960 - acc: 0.6599 - val_loss: 0.6045 - val_acc: 0.6484\n",
      "Epoch 8/100\n",
      "82/82 [==============================] - 1s 9ms/step - loss: 0.5950 - acc: 0.6610 - val_loss: 0.6041 - val_acc: 0.6440\n",
      "Epoch 9/100\n",
      "82/82 [==============================] - 1s 8ms/step - loss: 0.5947 - acc: 0.6589 - val_loss: 0.6031 - val_acc: 0.6494\n",
      "Epoch 10/100\n",
      "82/82 [==============================] - 1s 8ms/step - loss: 0.5940 - acc: 0.6602 - val_loss: 0.6032 - val_acc: 0.6436\n",
      "Epoch 11/100\n",
      "82/82 [==============================] - 1s 8ms/step - loss: 0.5941 - acc: 0.6566 - val_loss: 0.6024 - val_acc: 0.6426\n",
      "Epoch 12/100\n",
      "82/82 [==============================] - 1s 9ms/step - loss: 0.5937 - acc: 0.6584 - val_loss: 0.6015 - val_acc: 0.6562\n",
      "Epoch 13/100\n",
      "82/82 [==============================] - 1s 8ms/step - loss: 0.5925 - acc: 0.6666 - val_loss: 0.6025 - val_acc: 0.6655\n",
      "Epoch 14/100\n",
      "82/82 [==============================] - 1s 8ms/step - loss: 0.5934 - acc: 0.6565 - val_loss: 0.6006 - val_acc: 0.6597\n",
      "Epoch 15/100\n",
      "82/82 [==============================] - 1s 8ms/step - loss: 0.5932 - acc: 0.6617 - val_loss: 0.6021 - val_acc: 0.6611\n",
      "Epoch 16/100\n",
      "82/82 [==============================] - 1s 7ms/step - loss: 0.5926 - acc: 0.6597 - val_loss: 0.6041 - val_acc: 0.6558\n",
      "Epoch 17/100\n",
      "82/82 [==============================] - 1s 8ms/step - loss: 0.5914 - acc: 0.6624 - val_loss: 0.6014 - val_acc: 0.6606\n",
      "Epoch 18/100\n",
      "82/82 [==============================] - 1s 8ms/step - loss: 0.5910 - acc: 0.6636 - val_loss: 0.6004 - val_acc: 0.6646\n",
      "Epoch 19/100\n",
      "82/82 [==============================] - 1s 8ms/step - loss: 0.5914 - acc: 0.6616 - val_loss: 0.5997 - val_acc: 0.6641\n",
      "Epoch 20/100\n",
      "82/82 [==============================] - 1s 8ms/step - loss: 0.5923 - acc: 0.6573 - val_loss: 0.5990 - val_acc: 0.6631\n",
      "Epoch 21/100\n",
      "82/82 [==============================] - 1s 8ms/step - loss: 0.5910 - acc: 0.6647 - val_loss: 0.6010 - val_acc: 0.6470\n",
      "Epoch 22/100\n",
      "82/82 [==============================] - 1s 8ms/step - loss: 0.5915 - acc: 0.6617 - val_loss: 0.6018 - val_acc: 0.6479\n",
      "Epoch 23/100\n",
      "82/82 [==============================] - 1s 8ms/step - loss: 0.5910 - acc: 0.6604 - val_loss: 0.5988 - val_acc: 0.6519\n",
      "80/80 [==============================] - 3s 7ms/step - loss: 0.5809 - acc: 0.6762\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.5809420943260193, 0.6761718988418579]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras.layers import Input, Dense\n",
    "from keras.models import Model\n",
    "lines_t = lines1[:2560] + lines3[:2560]\n",
    "lines_ut = lines2[:2560] + lines4[:2560]\n",
    "test_t = test1[:640] + test3[:640]\n",
    "test_ut = test2[:640] + test4[:640]\n",
    "\n",
    "\n",
    "lines_ = []\n",
    "test_lines_ = []\n",
    "\n",
    "lines1_ = []\n",
    "lines2_ = []\n",
    "lines3_ = []\n",
    "lines4_ = []\n",
    "feature1 = []\n",
    "feature2 = []\n",
    "rating = []\n",
    "sentiment = []\n",
    "correlation = []\n",
    "\n",
    "for line in lines_t:\n",
    "    a = line.split(\",\")[:3]\n",
    "    a = list(map(float, a))\n",
    "    feature1.append(a)\n",
    "    \n",
    "    \n",
    "\n",
    "for line in lines_ut:\n",
    "    a = line.split(\",\")[:3]\n",
    "    a = list(map(float, a))\n",
    "    feature1.append(a)\n",
    "\n",
    "for line in test_t:\n",
    "    a = line.split(\",\")[:3]\n",
    "    a = list(map(float, a))\n",
    "    feature2.append(a)\n",
    "    \n",
    "for line in test_ut:\n",
    "    a = line.split(\",\")[:3]\n",
    "    a = list(map(float, a))\n",
    "    feature2.append(a)\n",
    "    \n",
    "    \n",
    "train_labels = [] # train 데이터 label\n",
    "test_labels = [] # test 데이터 label\n",
    "for i in range(len(lines_t)):\n",
    "    train_labels.append(1)\n",
    "for j in range(len(lines_ut)):\n",
    "    train_labels.append(0)\n",
    "for i in range(len(test_t)):\n",
    "    test_labels.append(1)\n",
    "for j in range(len(test_ut)):\n",
    "    test_labels.append(0)\n",
    "\n",
    "train_labels = np.asarray(train_labels)\n",
    "test_labels = np.asarray(test_labels)\n",
    "input_train = np.asarray(feature1)\n",
    "input_test = np.asarray(feature2)\n",
    "\n",
    "input_train = input_train.reshape(-1,1,3)\n",
    "input_test = input_test.reshape(-1,1,3)\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "x_train, x_valid, y_train, y_valid = train_test_split(input_train, train_labels, test_size=0.2, shuffle=True, stratify=train_labels, random_state=34)\n",
    "# LSTM\n",
    "from keras.layers import LSTM\n",
    "from tensorflow.python.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Embedding, SimpleRNN\n",
    "\n",
    "from keras.layers import Dense\n",
    "\n",
    "from keras.preprocessing import sequence\n",
    "\n",
    "model = Sequential()\n",
    "model.add(LSTM(32, return_sequences=True))\n",
    "model.add(LSTM(32))\n",
    "# 'binary_crossentropy\n",
    "model.add(Dense(5))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "model.compile(optimizer='rmsprop',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['acc'])\n",
    "\n",
    "from keras.callbacks import EarlyStopping\n",
    "early_stopping = EarlyStopping(monitor='val_acc', patience=10, mode='auto')\n",
    "\n",
    "history = model.fit(x_train, y_train,validation_data=(x_valid, y_valid),\n",
    "                    epochs=100,\n",
    "                    batch_size=100,callbacks=[early_stopping]\n",
    "                    )\n",
    "\n",
    "\n",
    "\n",
    "model.evaluate(input_test, test_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ededfff",
   "metadata": {},
   "source": [
    "## 공작 + 완벽한 타인 + 암살"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0c589a71",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "123/123 [==============================] - 19s 31ms/step - loss: 0.6716 - acc: 0.5994 - val_loss: 0.6466 - val_acc: 0.6221\n",
      "Epoch 2/100\n",
      "123/123 [==============================] - 1s 8ms/step - loss: 0.6366 - acc: 0.6169 - val_loss: 0.6285 - val_acc: 0.6133\n",
      "Epoch 3/100\n",
      "123/123 [==============================] - 1s 10ms/step - loss: 0.6253 - acc: 0.6270 - val_loss: 0.6197 - val_acc: 0.6338\n",
      "Epoch 4/100\n",
      "123/123 [==============================] - 1s 11ms/step - loss: 0.6207 - acc: 0.6288 - val_loss: 0.6171 - val_acc: 0.6315\n",
      "Epoch 5/100\n",
      "123/123 [==============================] - 1s 10ms/step - loss: 0.6189 - acc: 0.6288 - val_loss: 0.6201 - val_acc: 0.6331\n",
      "Epoch 6/100\n",
      "123/123 [==============================] - 1s 12ms/step - loss: 0.6175 - acc: 0.6351 - val_loss: 0.6161 - val_acc: 0.6393\n",
      "Epoch 7/100\n",
      "123/123 [==============================] - 1s 8ms/step - loss: 0.6175 - acc: 0.6301 - val_loss: 0.6146 - val_acc: 0.6357\n",
      "Epoch 8/100\n",
      "123/123 [==============================] - 1s 7ms/step - loss: 0.6167 - acc: 0.6349 - val_loss: 0.6134 - val_acc: 0.6429\n",
      "Epoch 9/100\n",
      "123/123 [==============================] - 1s 8ms/step - loss: 0.6162 - acc: 0.6350 - val_loss: 0.6187 - val_acc: 0.6263\n",
      "Epoch 10/100\n",
      "123/123 [==============================] - 1s 10ms/step - loss: 0.6158 - acc: 0.6363 - val_loss: 0.6149 - val_acc: 0.6299\n",
      "Epoch 11/100\n",
      "123/123 [==============================] - 1s 10ms/step - loss: 0.6155 - acc: 0.6345 - val_loss: 0.6121 - val_acc: 0.6383\n",
      "Epoch 12/100\n",
      "123/123 [==============================] - 1s 8ms/step - loss: 0.6151 - acc: 0.6353 - val_loss: 0.6122 - val_acc: 0.6406\n",
      "Epoch 13/100\n",
      "123/123 [==============================] - 1s 8ms/step - loss: 0.6143 - acc: 0.6373 - val_loss: 0.6116 - val_acc: 0.6390\n",
      "Epoch 14/100\n",
      "123/123 [==============================] - 1s 8ms/step - loss: 0.6148 - acc: 0.6333 - val_loss: 0.6130 - val_acc: 0.6439\n",
      "Epoch 15/100\n",
      "123/123 [==============================] - 1s 9ms/step - loss: 0.6146 - acc: 0.6338 - val_loss: 0.6109 - val_acc: 0.6380\n",
      "Epoch 16/100\n",
      "123/123 [==============================] - 1s 9ms/step - loss: 0.6142 - acc: 0.6333 - val_loss: 0.6106 - val_acc: 0.6413\n",
      "Epoch 17/100\n",
      "123/123 [==============================] - 1s 8ms/step - loss: 0.6139 - acc: 0.6352 - val_loss: 0.6102 - val_acc: 0.6423\n",
      "Epoch 18/100\n",
      "123/123 [==============================] - 1s 7ms/step - loss: 0.6140 - acc: 0.6390 - val_loss: 0.6101 - val_acc: 0.6429\n",
      "Epoch 19/100\n",
      "123/123 [==============================] - 1s 7ms/step - loss: 0.6137 - acc: 0.6356 - val_loss: 0.6130 - val_acc: 0.6380\n",
      "Epoch 20/100\n",
      "123/123 [==============================] - 1s 6ms/step - loss: 0.6132 - acc: 0.6370 - val_loss: 0.6107 - val_acc: 0.6419\n",
      "Epoch 21/100\n",
      "123/123 [==============================] - 1s 7ms/step - loss: 0.6139 - acc: 0.6342 - val_loss: 0.6121 - val_acc: 0.6403\n",
      "Epoch 22/100\n",
      "123/123 [==============================] - 1s 7ms/step - loss: 0.6134 - acc: 0.6365 - val_loss: 0.6103 - val_acc: 0.6452\n",
      "Epoch 23/100\n",
      "123/123 [==============================] - 1s 7ms/step - loss: 0.6126 - acc: 0.6380 - val_loss: 0.6104 - val_acc: 0.6432\n",
      "Epoch 24/100\n",
      "123/123 [==============================] - 1s 8ms/step - loss: 0.6131 - acc: 0.6390 - val_loss: 0.6094 - val_acc: 0.6445\n",
      "Epoch 25/100\n",
      "123/123 [==============================] - 1s 9ms/step - loss: 0.6127 - acc: 0.6370 - val_loss: 0.6090 - val_acc: 0.6416\n",
      "Epoch 26/100\n",
      "123/123 [==============================] - 1s 9ms/step - loss: 0.6132 - acc: 0.6341 - val_loss: 0.6104 - val_acc: 0.6432\n",
      "Epoch 27/100\n",
      "123/123 [==============================] - 1s 10ms/step - loss: 0.6126 - acc: 0.6357 - val_loss: 0.6172 - val_acc: 0.6270\n",
      "Epoch 28/100\n",
      "123/123 [==============================] - 1s 10ms/step - loss: 0.6121 - acc: 0.6366 - val_loss: 0.6085 - val_acc: 0.6390\n",
      "Epoch 29/100\n",
      "123/123 [==============================] - 1s 9ms/step - loss: 0.6127 - acc: 0.6365 - val_loss: 0.6203 - val_acc: 0.6045\n",
      "Epoch 30/100\n",
      "123/123 [==============================] - 1s 6ms/step - loss: 0.6117 - acc: 0.6365 - val_loss: 0.6086 - val_acc: 0.6410\n",
      "Epoch 31/100\n",
      "123/123 [==============================] - 1s 6ms/step - loss: 0.6133 - acc: 0.6334 - val_loss: 0.6089 - val_acc: 0.6429\n",
      "Epoch 32/100\n",
      "123/123 [==============================] - 1s 7ms/step - loss: 0.6121 - acc: 0.6353 - val_loss: 0.6145 - val_acc: 0.6406\n",
      "120/120 [==============================] - 2s 3ms/step - loss: 0.6120 - acc: 0.6331\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.6120414137840271, 0.6330729126930237]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras.layers import Input, Dense\n",
    "from keras.models import Model\n",
    "lines_t = lines1[:2560] + lines3[:2560] + lines5[:2560]\n",
    "lines_ut = lines2[:2560] + lines4[:2560] + lines6[:2560]\n",
    "test_t = test1[:640] + test3[:640] + test5[:640]\n",
    "test_ut = test2[:640] + test4[:640] + test6[:640]\n",
    "\n",
    "\n",
    "lines_ = []\n",
    "test_lines_ = []\n",
    "\n",
    "lines1_ = []\n",
    "lines2_ = []\n",
    "lines3_ = []\n",
    "lines4_ = []\n",
    "feature1 = []\n",
    "feature2 = []\n",
    "rating = []\n",
    "sentiment = []\n",
    "correlation = []\n",
    "\n",
    "for line in lines_t:\n",
    "    a = line.split(\",\")[:3]\n",
    "    a = list(map(float, a))\n",
    "    feature1.append(a)\n",
    "    \n",
    "    \n",
    "\n",
    "for line in lines_ut:\n",
    "    a = line.split(\",\")[:3]\n",
    "    a = list(map(float, a))\n",
    "    feature1.append(a)\n",
    "\n",
    "for line in test_t:\n",
    "    a = line.split(\",\")[:3]\n",
    "    a = list(map(float, a))\n",
    "    feature2.append(a)\n",
    "    \n",
    "for line in test_ut:\n",
    "    a = line.split(\",\")[:3]\n",
    "    a = list(map(float, a))\n",
    "    feature2.append(a)\n",
    "    \n",
    "    \n",
    "train_labels = [] # train 데이터 label\n",
    "test_labels = [] # test 데이터 label\n",
    "for i in range(len(lines_t)):\n",
    "    train_labels.append(1)\n",
    "for j in range(len(lines_ut)):\n",
    "    train_labels.append(0)\n",
    "for i in range(len(test_t)):\n",
    "    test_labels.append(1)\n",
    "for j in range(len(test_ut)):\n",
    "    test_labels.append(0)\n",
    "\n",
    "train_labels = np.asarray(train_labels)\n",
    "test_labels = np.asarray(test_labels)\n",
    "input_train = np.asarray(feature1)\n",
    "input_test = np.asarray(feature2)\n",
    "\n",
    "input_train = input_train.reshape(-1,1,3)\n",
    "input_test = input_test.reshape(-1,1,3)\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "x_train, x_valid, y_train, y_valid = train_test_split(input_train, train_labels, test_size=0.2, shuffle=True, stratify=train_labels, random_state=34)\n",
    "# LSTM\n",
    "from keras.layers import LSTM\n",
    "from tensorflow.python.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Embedding, SimpleRNN\n",
    "\n",
    "from keras.layers import Dense\n",
    "\n",
    "from keras.preprocessing import sequence\n",
    "\n",
    "model = Sequential()\n",
    "model.add(LSTM(32, return_sequences=True))\n",
    "model.add(LSTM(32))\n",
    "# 'binary_crossentropy\n",
    "model.add(Dense(5))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "model.compile(optimizer='rmsprop',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['acc'])\n",
    "\n",
    "from keras.callbacks import EarlyStopping\n",
    "early_stopping = EarlyStopping(monitor='val_acc', patience=10, mode='auto')\n",
    "\n",
    "history = model.fit(x_train, y_train,validation_data=(x_valid, y_valid),\n",
    "                    epochs=100,\n",
    "                    batch_size=100,callbacks=[early_stopping]\n",
    "                    )\n",
    "\n",
    "\n",
    "\n",
    "model.evaluate(input_test, test_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecce03ba",
   "metadata": {},
   "source": [
    "## 공작 + 완벽한 타인 + 암살 + 1987"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "66a33c78",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "164/164 [==============================] - 17s 30ms/step - loss: 0.6693 - acc: 0.5966 - val_loss: 0.6535 - val_acc: 0.6069\n",
      "Epoch 2/100\n",
      "164/164 [==============================] - 1s 8ms/step - loss: 0.6414 - acc: 0.5983 - val_loss: 0.6372 - val_acc: 0.6067\n",
      "Epoch 3/100\n",
      "164/164 [==============================] - 2s 9ms/step - loss: 0.6326 - acc: 0.6112 - val_loss: 0.6378 - val_acc: 0.6128\n",
      "Epoch 4/100\n",
      "164/164 [==============================] - 1s 8ms/step - loss: 0.6300 - acc: 0.6125 - val_loss: 0.6323 - val_acc: 0.6152\n",
      "Epoch 5/100\n",
      "164/164 [==============================] - 1s 7ms/step - loss: 0.6293 - acc: 0.6134 - val_loss: 0.6318 - val_acc: 0.6179\n",
      "Epoch 6/100\n",
      "164/164 [==============================] - 1s 8ms/step - loss: 0.6288 - acc: 0.6133 - val_loss: 0.6302 - val_acc: 0.6182\n",
      "Epoch 7/100\n",
      "164/164 [==============================] - 1s 9ms/step - loss: 0.6286 - acc: 0.6173 - val_loss: 0.6318 - val_acc: 0.6150\n",
      "Epoch 8/100\n",
      "164/164 [==============================] - 2s 9ms/step - loss: 0.6278 - acc: 0.6166 - val_loss: 0.6277 - val_acc: 0.6270\n",
      "Epoch 9/100\n",
      "164/164 [==============================] - 1s 9ms/step - loss: 0.6277 - acc: 0.6158 - val_loss: 0.6293 - val_acc: 0.6179\n",
      "Epoch 10/100\n",
      "164/164 [==============================] - 1s 9ms/step - loss: 0.6273 - acc: 0.6177 - val_loss: 0.6266 - val_acc: 0.6260\n",
      "Epoch 11/100\n",
      "164/164 [==============================] - 1s 8ms/step - loss: 0.6266 - acc: 0.6193 - val_loss: 0.6290 - val_acc: 0.6199\n",
      "Epoch 12/100\n",
      "164/164 [==============================] - 1s 8ms/step - loss: 0.6271 - acc: 0.6135 - val_loss: 0.6268 - val_acc: 0.6191\n",
      "Epoch 13/100\n",
      "164/164 [==============================] - 1s 7ms/step - loss: 0.6266 - acc: 0.6174 - val_loss: 0.6305 - val_acc: 0.6135\n",
      "Epoch 14/100\n",
      "164/164 [==============================] - 1s 7ms/step - loss: 0.6258 - acc: 0.6163 - val_loss: 0.6254 - val_acc: 0.6309\n",
      "Epoch 15/100\n",
      "164/164 [==============================] - 1s 7ms/step - loss: 0.6255 - acc: 0.6204 - val_loss: 0.6247 - val_acc: 0.6287\n",
      "Epoch 16/100\n",
      "164/164 [==============================] - 1s 7ms/step - loss: 0.6257 - acc: 0.6210 - val_loss: 0.6266 - val_acc: 0.6196\n",
      "Epoch 17/100\n",
      "164/164 [==============================] - 1s 6ms/step - loss: 0.6255 - acc: 0.6186 - val_loss: 0.6238 - val_acc: 0.6262\n",
      "Epoch 18/100\n",
      "164/164 [==============================] - 1s 6ms/step - loss: 0.6256 - acc: 0.6169 - val_loss: 0.6242 - val_acc: 0.6326\n",
      "Epoch 19/100\n",
      "164/164 [==============================] - 1s 5ms/step - loss: 0.6251 - acc: 0.6186 - val_loss: 0.6235 - val_acc: 0.6313\n",
      "Epoch 20/100\n",
      "164/164 [==============================] - 1s 6ms/step - loss: 0.6253 - acc: 0.6189 - val_loss: 0.6295 - val_acc: 0.6174\n",
      "Epoch 21/100\n",
      "164/164 [==============================] - 1s 5ms/step - loss: 0.6252 - acc: 0.6217 - val_loss: 0.6231 - val_acc: 0.6252\n",
      "Epoch 22/100\n",
      "164/164 [==============================] - 1s 7ms/step - loss: 0.6253 - acc: 0.6180 - val_loss: 0.6227 - val_acc: 0.6267\n",
      "Epoch 23/100\n",
      "164/164 [==============================] - 1s 7ms/step - loss: 0.6248 - acc: 0.6213 - val_loss: 0.6245 - val_acc: 0.6274\n",
      "Epoch 24/100\n",
      "164/164 [==============================] - 1s 6ms/step - loss: 0.6249 - acc: 0.6176 - val_loss: 0.6249 - val_acc: 0.6199\n",
      "Epoch 25/100\n",
      "164/164 [==============================] - 1s 7ms/step - loss: 0.6248 - acc: 0.6154 - val_loss: 0.6274 - val_acc: 0.6301\n",
      "Epoch 26/100\n",
      "164/164 [==============================] - 1s 7ms/step - loss: 0.6248 - acc: 0.6215 - val_loss: 0.6248 - val_acc: 0.6201\n",
      "Epoch 27/100\n",
      "164/164 [==============================] - 1s 6ms/step - loss: 0.6248 - acc: 0.6208 - val_loss: 0.6227 - val_acc: 0.6270\n",
      "Epoch 28/100\n",
      "164/164 [==============================] - 1s 7ms/step - loss: 0.6251 - acc: 0.6185 - val_loss: 0.6221 - val_acc: 0.6289\n",
      "160/160 [==============================] - 3s 5ms/step - loss: 0.6173 - acc: 0.6334\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.617308497428894, 0.6333984136581421]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras.layers import Input, Dense\n",
    "from keras.models import Model\n",
    "lines_t = lines1[:2560] + lines3[:2560] + lines5[:2560] + lines7[:2560]\n",
    "lines_ut = lines2[:2560] + lines4[:2560] + lines6[:2560] + lines8[:2560]\n",
    "test_t = test1[:640] + test3[:640] + test5[:640] + test7[:640]\n",
    "test_ut = test2[:640] + test4[:640] + test6[:640] + test8[:640]\n",
    "\n",
    "\n",
    "lines_ = []\n",
    "test_lines_ = []\n",
    "\n",
    "lines1_ = []\n",
    "lines2_ = []\n",
    "lines3_ = []\n",
    "lines4_ = []\n",
    "feature1 = []\n",
    "feature2 = []\n",
    "rating = []\n",
    "sentiment = []\n",
    "correlation = []\n",
    "\n",
    "for line in lines_t:\n",
    "    a = line.split(\",\")[:3]\n",
    "    a = list(map(float, a))\n",
    "    feature1.append(a)\n",
    "    \n",
    "    \n",
    "\n",
    "for line in lines_ut:\n",
    "    a = line.split(\",\")[:3]\n",
    "    a = list(map(float, a))\n",
    "    feature1.append(a)\n",
    "\n",
    "for line in test_t:\n",
    "    a = line.split(\",\")[:3]\n",
    "    a = list(map(float, a))\n",
    "    feature2.append(a)\n",
    "    \n",
    "for line in test_ut:\n",
    "    a = line.split(\",\")[:3]\n",
    "    a = list(map(float, a))\n",
    "    feature2.append(a)\n",
    "    \n",
    "    \n",
    "train_labels = [] # train 데이터 label\n",
    "test_labels = [] # test 데이터 label\n",
    "for i in range(len(lines_t)):\n",
    "    train_labels.append(1)\n",
    "for j in range(len(lines_ut)):\n",
    "    train_labels.append(0)\n",
    "for i in range(len(test_t)):\n",
    "    test_labels.append(1)\n",
    "for j in range(len(test_ut)):\n",
    "    test_labels.append(0)\n",
    "\n",
    "train_labels = np.asarray(train_labels)\n",
    "test_labels = np.asarray(test_labels)\n",
    "input_train = np.asarray(feature1)\n",
    "input_test = np.asarray(feature2)\n",
    "\n",
    "input_train = input_train.reshape(-1,1,3)\n",
    "input_test = input_test.reshape(-1,1,3)\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "x_train, x_valid, y_train, y_valid = train_test_split(input_train, train_labels, test_size=0.2, shuffle=True, stratify=train_labels, random_state=34)\n",
    "# LSTM\n",
    "from keras.layers import LSTM\n",
    "from tensorflow.python.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Embedding, SimpleRNN\n",
    "\n",
    "from keras.layers import Dense\n",
    "\n",
    "from keras.preprocessing import sequence\n",
    "\n",
    "model = Sequential()\n",
    "model.add(LSTM(32, return_sequences=True))\n",
    "model.add(LSTM(32))\n",
    "# 'binary_crossentropy\n",
    "model.add(Dense(5))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "model.compile(optimizer='rmsprop',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['acc'])\n",
    "\n",
    "from keras.callbacks import EarlyStopping\n",
    "early_stopping = EarlyStopping(monitor='val_acc', patience=10, mode='auto')\n",
    "\n",
    "history = model.fit(x_train, y_train,validation_data=(x_valid, y_valid),\n",
    "                    epochs=100,\n",
    "                    batch_size=100,callbacks=[early_stopping]\n",
    "                    )\n",
    "\n",
    "\n",
    "\n",
    "model.evaluate(input_test, test_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b17fb0fd",
   "metadata": {},
   "source": [
    "## 공작 + 완벽한 타인 + 암살 + 1987 + 택시운전사"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c706e086",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "205/205 [==============================] - 15s 18ms/step - loss: 0.6697 - acc: 0.5912 - val_loss: 0.6450 - val_acc: 0.6061\n",
      "Epoch 2/100\n",
      "205/205 [==============================] - 2s 8ms/step - loss: 0.6418 - acc: 0.5978 - val_loss: 0.6345 - val_acc: 0.6107\n",
      "Epoch 3/100\n",
      "205/205 [==============================] - 2s 8ms/step - loss: 0.6358 - acc: 0.6062 - val_loss: 0.6316 - val_acc: 0.6119\n",
      "Epoch 4/100\n",
      "205/205 [==============================] - 2s 8ms/step - loss: 0.6342 - acc: 0.6072 - val_loss: 0.6311 - val_acc: 0.6115\n",
      "Epoch 5/100\n",
      "205/205 [==============================] - 1s 7ms/step - loss: 0.6333 - acc: 0.6099 - val_loss: 0.6295 - val_acc: 0.6156\n",
      "Epoch 6/100\n",
      "205/205 [==============================] - 2s 7ms/step - loss: 0.6332 - acc: 0.6098 - val_loss: 0.6312 - val_acc: 0.6070\n",
      "Epoch 7/100\n",
      "205/205 [==============================] - 2s 9ms/step - loss: 0.6327 - acc: 0.6094 - val_loss: 0.6381 - val_acc: 0.6100\n",
      "Epoch 8/100\n",
      "205/205 [==============================] - 2s 8ms/step - loss: 0.6324 - acc: 0.6096 - val_loss: 0.6280 - val_acc: 0.6164\n",
      "Epoch 9/100\n",
      "205/205 [==============================] - 2s 8ms/step - loss: 0.6320 - acc: 0.6109 - val_loss: 0.6280 - val_acc: 0.6166\n",
      "Epoch 10/100\n",
      "205/205 [==============================] - 2s 8ms/step - loss: 0.6317 - acc: 0.6139 - val_loss: 0.6283 - val_acc: 0.6168\n",
      "Epoch 11/100\n",
      "205/205 [==============================] - 2s 8ms/step - loss: 0.6318 - acc: 0.6142 - val_loss: 0.6270 - val_acc: 0.6172\n",
      "Epoch 12/100\n",
      "205/205 [==============================] - 1s 7ms/step - loss: 0.6312 - acc: 0.6133 - val_loss: 0.6277 - val_acc: 0.6184\n",
      "Epoch 13/100\n",
      "205/205 [==============================] - 2s 7ms/step - loss: 0.6304 - acc: 0.6165 - val_loss: 0.6266 - val_acc: 0.6162\n",
      "Epoch 14/100\n",
      "205/205 [==============================] - 2s 10ms/step - loss: 0.6309 - acc: 0.6128 - val_loss: 0.6282 - val_acc: 0.6156\n",
      "Epoch 15/100\n",
      "205/205 [==============================] - 2s 9ms/step - loss: 0.6306 - acc: 0.6113 - val_loss: 0.6268 - val_acc: 0.6174\n",
      "Epoch 16/100\n",
      "205/205 [==============================] - 2s 8ms/step - loss: 0.6306 - acc: 0.6142 - val_loss: 0.6298 - val_acc: 0.6125\n",
      "Epoch 17/100\n",
      "205/205 [==============================] - 2s 7ms/step - loss: 0.6307 - acc: 0.6128 - val_loss: 0.6257 - val_acc: 0.6191\n",
      "Epoch 18/100\n",
      "205/205 [==============================] - 1s 7ms/step - loss: 0.6303 - acc: 0.6144 - val_loss: 0.6275 - val_acc: 0.6156\n",
      "Epoch 19/100\n",
      "205/205 [==============================] - 2s 8ms/step - loss: 0.6303 - acc: 0.6142 - val_loss: 0.6269 - val_acc: 0.6146\n",
      "Epoch 20/100\n",
      "205/205 [==============================] - 2s 8ms/step - loss: 0.6304 - acc: 0.6140 - val_loss: 0.6268 - val_acc: 0.6184\n",
      "Epoch 21/100\n",
      "205/205 [==============================] - 2s 8ms/step - loss: 0.6300 - acc: 0.6124 - val_loss: 0.6249 - val_acc: 0.6184\n",
      "Epoch 22/100\n",
      "205/205 [==============================] - 2s 8ms/step - loss: 0.6299 - acc: 0.6192 - val_loss: 0.6332 - val_acc: 0.6121\n",
      "Epoch 23/100\n",
      "205/205 [==============================] - 2s 9ms/step - loss: 0.6298 - acc: 0.6155 - val_loss: 0.6250 - val_acc: 0.6197\n",
      "Epoch 24/100\n",
      "205/205 [==============================] - 2s 10ms/step - loss: 0.6298 - acc: 0.6162 - val_loss: 0.6308 - val_acc: 0.6078\n",
      "Epoch 25/100\n",
      "205/205 [==============================] - 2s 12ms/step - loss: 0.6299 - acc: 0.6163 - val_loss: 0.6243 - val_acc: 0.6193\n",
      "Epoch 26/100\n",
      "205/205 [==============================] - 2s 9ms/step - loss: 0.6300 - acc: 0.6153 - val_loss: 0.6253 - val_acc: 0.6236\n",
      "Epoch 27/100\n",
      "205/205 [==============================] - 2s 9ms/step - loss: 0.6300 - acc: 0.6176 - val_loss: 0.6258 - val_acc: 0.6240\n",
      "Epoch 28/100\n",
      "205/205 [==============================] - 2s 10ms/step - loss: 0.6294 - acc: 0.6174 - val_loss: 0.6242 - val_acc: 0.6203\n",
      "Epoch 29/100\n",
      "205/205 [==============================] - 2s 8ms/step - loss: 0.6296 - acc: 0.6175 - val_loss: 0.6240 - val_acc: 0.6217\n",
      "Epoch 30/100\n",
      "205/205 [==============================] - 1s 7ms/step - loss: 0.6292 - acc: 0.6169 - val_loss: 0.6256 - val_acc: 0.6225\n",
      "Epoch 31/100\n",
      "205/205 [==============================] - 1s 7ms/step - loss: 0.6297 - acc: 0.6159 - val_loss: 0.6251 - val_acc: 0.6191\n",
      "Epoch 32/100\n",
      "205/205 [==============================] - 2s 8ms/step - loss: 0.6296 - acc: 0.6133 - val_loss: 0.6293 - val_acc: 0.6131\n",
      "Epoch 33/100\n",
      "205/205 [==============================] - 2s 8ms/step - loss: 0.6294 - acc: 0.6167 - val_loss: 0.6245 - val_acc: 0.6219\n",
      "Epoch 34/100\n",
      "205/205 [==============================] - 2s 8ms/step - loss: 0.6291 - acc: 0.6171 - val_loss: 0.6238 - val_acc: 0.6203\n",
      "Epoch 35/100\n",
      "205/205 [==============================] - 2s 8ms/step - loss: 0.6286 - acc: 0.6181 - val_loss: 0.6276 - val_acc: 0.6146\n",
      "Epoch 36/100\n",
      "205/205 [==============================] - 1s 7ms/step - loss: 0.6288 - acc: 0.6167 - val_loss: 0.6336 - val_acc: 0.6158\n",
      "Epoch 37/100\n",
      "205/205 [==============================] - 2s 8ms/step - loss: 0.6291 - acc: 0.6180 - val_loss: 0.6242 - val_acc: 0.6219\n",
      "200/200 [==============================] - 3s 4ms/step - loss: 0.6247 - acc: 0.6212\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.6247337460517883, 0.6212499737739563]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras.layers import Input, Dense\n",
    "from keras.models import Model\n",
    "lines_t = lines1[:2560] + lines3[:2560] + lines5[:2560] + lines7[:2560] + lines9[:2560]\n",
    "lines_ut = lines2[:2560] + lines4[:2560] + lines6[:2560] + lines8[:2560] + lines10[:2560]\n",
    "test_t = test1[:640] + test3[:640] + test5[:640] + test7[:640] + test9[:640]\n",
    "test_ut = test2[:640] + test4[:640] + test6[:640] + test8[:640] + test10[:640]\n",
    "\n",
    "\n",
    "lines_ = []\n",
    "test_lines_ = []\n",
    "\n",
    "lines1_ = []\n",
    "lines2_ = []\n",
    "lines3_ = []\n",
    "lines4_ = []\n",
    "feature1 = []\n",
    "feature2 = []\n",
    "rating = []\n",
    "sentiment = []\n",
    "correlation = []\n",
    "\n",
    "for line in lines_t:\n",
    "    a = line.split(\",\")[:3]\n",
    "    a = list(map(float, a))\n",
    "    feature1.append(a)\n",
    "    \n",
    "    \n",
    "\n",
    "for line in lines_ut:\n",
    "    a = line.split(\",\")[:3]\n",
    "    a = list(map(float, a))\n",
    "    feature1.append(a)\n",
    "\n",
    "for line in test_t:\n",
    "    a = line.split(\",\")[:3]\n",
    "    a = list(map(float, a))\n",
    "    feature2.append(a)\n",
    "    \n",
    "for line in test_ut:\n",
    "    a = line.split(\",\")[:3]\n",
    "    a = list(map(float, a))\n",
    "    feature2.append(a)\n",
    "    \n",
    "    \n",
    "train_labels = [] # train 데이터 label\n",
    "test_labels = [] # test 데이터 label\n",
    "for i in range(len(lines_t)):\n",
    "    train_labels.append(1)\n",
    "for j in range(len(lines_ut)):\n",
    "    train_labels.append(0)\n",
    "for i in range(len(test_t)):\n",
    "    test_labels.append(1)\n",
    "for j in range(len(test_ut)):\n",
    "    test_labels.append(0)\n",
    "\n",
    "train_labels = np.asarray(train_labels)\n",
    "test_labels = np.asarray(test_labels)\n",
    "input_train = np.asarray(feature1)\n",
    "input_test = np.asarray(feature2)\n",
    "\n",
    "input_train = input_train.reshape(-1,1,3)\n",
    "input_test = input_test.reshape(-1,1,3)\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "x_train, x_valid, y_train, y_valid = train_test_split(input_train, train_labels, test_size=0.2, shuffle=True, stratify=train_labels, random_state=34)\n",
    "# LSTM\n",
    "from keras.layers import LSTM\n",
    "from tensorflow.python.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Embedding, SimpleRNN\n",
    "\n",
    "from keras.layers import Dense\n",
    "\n",
    "from keras.preprocessing import sequence\n",
    "\n",
    "model = Sequential()\n",
    "model.add(LSTM(32, return_sequences=True))\n",
    "model.add(LSTM(32))\n",
    "# 'binary_crossentropy\n",
    "model.add(Dense(5))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "model.compile(optimizer='rmsprop',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['acc'])\n",
    "\n",
    "from keras.callbacks import EarlyStopping\n",
    "early_stopping = EarlyStopping(monitor='val_acc', patience=10, mode='auto')\n",
    "\n",
    "history = model.fit(x_train, y_train,validation_data=(x_valid, y_valid),\n",
    "                    epochs=100,\n",
    "                    batch_size=100,callbacks=[early_stopping]\n",
    "                    )\n",
    "\n",
    "\n",
    "\n",
    "model.evaluate(input_test, test_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56c17ee6",
   "metadata": {},
   "source": [
    "## 완벽한 타인 + 암살"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0c83a665",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "82/82 [==============================] - 18s 26ms/step - loss: 0.6864 - acc: 0.5580 - val_loss: 0.6743 - val_acc: 0.6040\n",
      "Epoch 2/100\n",
      "82/82 [==============================] - 0s 6ms/step - loss: 0.6674 - acc: 0.5914 - val_loss: 0.6511 - val_acc: 0.5962\n",
      "Epoch 3/100\n",
      "82/82 [==============================] - 0s 6ms/step - loss: 0.6520 - acc: 0.5870 - val_loss: 0.6391 - val_acc: 0.5947\n",
      "Epoch 4/100\n",
      "82/82 [==============================] - 0s 5ms/step - loss: 0.6459 - acc: 0.5953 - val_loss: 0.6339 - val_acc: 0.6050\n",
      "Epoch 5/100\n",
      "82/82 [==============================] - 0s 6ms/step - loss: 0.6425 - acc: 0.5945 - val_loss: 0.6298 - val_acc: 0.6104\n",
      "Epoch 6/100\n",
      "82/82 [==============================] - 0s 5ms/step - loss: 0.6417 - acc: 0.5983 - val_loss: 0.6278 - val_acc: 0.6162\n",
      "Epoch 7/100\n",
      "82/82 [==============================] - 0s 5ms/step - loss: 0.6404 - acc: 0.6028 - val_loss: 0.6286 - val_acc: 0.6138\n",
      "Epoch 8/100\n",
      "82/82 [==============================] - 0s 5ms/step - loss: 0.6397 - acc: 0.6010 - val_loss: 0.6271 - val_acc: 0.6040\n",
      "Epoch 9/100\n",
      "82/82 [==============================] - 0s 5ms/step - loss: 0.6388 - acc: 0.6034 - val_loss: 0.6246 - val_acc: 0.6221\n",
      "Epoch 10/100\n",
      "82/82 [==============================] - 0s 5ms/step - loss: 0.6391 - acc: 0.6036 - val_loss: 0.6240 - val_acc: 0.6201\n",
      "Epoch 11/100\n",
      "82/82 [==============================] - 0s 5ms/step - loss: 0.6387 - acc: 0.6006 - val_loss: 0.6236 - val_acc: 0.6235\n",
      "Epoch 12/100\n",
      "82/82 [==============================] - 0s 6ms/step - loss: 0.6381 - acc: 0.6005 - val_loss: 0.6233 - val_acc: 0.6226\n",
      "Epoch 13/100\n",
      "82/82 [==============================] - 1s 6ms/step - loss: 0.6383 - acc: 0.6010 - val_loss: 0.6230 - val_acc: 0.6226\n",
      "Epoch 14/100\n",
      "82/82 [==============================] - 0s 6ms/step - loss: 0.6377 - acc: 0.5989 - val_loss: 0.6274 - val_acc: 0.6099\n",
      "Epoch 15/100\n",
      "82/82 [==============================] - 0s 6ms/step - loss: 0.6379 - acc: 0.5981 - val_loss: 0.6226 - val_acc: 0.6191\n",
      "Epoch 16/100\n",
      "82/82 [==============================] - 0s 5ms/step - loss: 0.6364 - acc: 0.6051 - val_loss: 0.6243 - val_acc: 0.6118\n",
      "Epoch 17/100\n",
      "82/82 [==============================] - 1s 6ms/step - loss: 0.6370 - acc: 0.6044 - val_loss: 0.6223 - val_acc: 0.6177\n",
      "Epoch 18/100\n",
      "82/82 [==============================] - 0s 6ms/step - loss: 0.6368 - acc: 0.6021 - val_loss: 0.6210 - val_acc: 0.6201\n",
      "Epoch 19/100\n",
      "82/82 [==============================] - 0s 6ms/step - loss: 0.6373 - acc: 0.6016 - val_loss: 0.6211 - val_acc: 0.6211\n",
      "Epoch 20/100\n",
      "82/82 [==============================] - 0s 5ms/step - loss: 0.6354 - acc: 0.6088 - val_loss: 0.6206 - val_acc: 0.6226\n",
      "Epoch 21/100\n",
      "82/82 [==============================] - 0s 5ms/step - loss: 0.6357 - acc: 0.6115 - val_loss: 0.6203 - val_acc: 0.6157\n",
      "80/80 [==============================] - 1s 2ms/step - loss: 0.6313 - acc: 0.6094\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.631283164024353, 0.609375]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras.layers import Input, Dense\n",
    "from keras.models import Model\n",
    "lines_t = lines3[:2560] + lines5[:2560] \n",
    "lines_ut = lines4[:2560] + lines6[:2560]\n",
    "test_t = test3[:640] + test5[:640] \n",
    "test_ut = test4[:640] + test6[:640] \n",
    "\n",
    "\n",
    "lines_ = []\n",
    "test_lines_ = []\n",
    "\n",
    "lines1_ = []\n",
    "lines2_ = []\n",
    "lines3_ = []\n",
    "lines4_ = []\n",
    "feature1 = []\n",
    "feature2 = []\n",
    "rating = []\n",
    "sentiment = []\n",
    "correlation = []\n",
    "\n",
    "for line in lines_t:\n",
    "    a = line.split(\",\")[:3]\n",
    "    a = list(map(float, a))\n",
    "    feature1.append(a)\n",
    "    \n",
    "    \n",
    "\n",
    "for line in lines_ut:\n",
    "    a = line.split(\",\")[:3]\n",
    "    a = list(map(float, a))\n",
    "    feature1.append(a)\n",
    "\n",
    "for line in test_t:\n",
    "    a = line.split(\",\")[:3]\n",
    "    a = list(map(float, a))\n",
    "    feature2.append(a)\n",
    "    \n",
    "for line in test_ut:\n",
    "    a = line.split(\",\")[:3]\n",
    "    a = list(map(float, a))\n",
    "    feature2.append(a)\n",
    "    \n",
    "    \n",
    "train_labels = [] # train 데이터 label\n",
    "test_labels = [] # test 데이터 label\n",
    "for i in range(len(lines_t)):\n",
    "    train_labels.append(1)\n",
    "for j in range(len(lines_ut)):\n",
    "    train_labels.append(0)\n",
    "for i in range(len(test_t)):\n",
    "    test_labels.append(1)\n",
    "for j in range(len(test_ut)):\n",
    "    test_labels.append(0)\n",
    "\n",
    "train_labels = np.asarray(train_labels)\n",
    "test_labels = np.asarray(test_labels)\n",
    "input_train = np.asarray(feature1)\n",
    "input_test = np.asarray(feature2)\n",
    "\n",
    "input_train = input_train.reshape(-1,1,3)\n",
    "input_test = input_test.reshape(-1,1,3)\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "x_train, x_valid, y_train, y_valid = train_test_split(input_train, train_labels, test_size=0.2, shuffle=True, stratify=train_labels, random_state=34)\n",
    "# LSTM\n",
    "from keras.layers import LSTM\n",
    "from tensorflow.python.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Embedding, SimpleRNN\n",
    "\n",
    "from keras.layers import Dense\n",
    "\n",
    "from keras.preprocessing import sequence\n",
    "\n",
    "model = Sequential()\n",
    "model.add(LSTM(32, return_sequences=True))\n",
    "model.add(LSTM(32))\n",
    "# 'binary_crossentropy\n",
    "model.add(Dense(5))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "model.compile(optimizer='rmsprop',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['acc'])\n",
    "\n",
    "from keras.callbacks import EarlyStopping\n",
    "early_stopping = EarlyStopping(monitor='val_acc', patience=10, mode='auto')\n",
    "\n",
    "history = model.fit(x_train, y_train,validation_data=(x_valid, y_valid),\n",
    "                    epochs=100,\n",
    "                    batch_size=100,callbacks=[early_stopping]\n",
    "                    )\n",
    "\n",
    "\n",
    "\n",
    "model.evaluate(input_test, test_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15ef26b5",
   "metadata": {},
   "source": [
    "## 완벽한 타인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0ad9f956",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "41/41 [==============================] - 7s 31ms/step - loss: 0.6866 - acc: 0.5830 - val_loss: 0.6795 - val_acc: 0.6191\n",
      "Epoch 2/100\n",
      "41/41 [==============================] - 0s 5ms/step - loss: 0.6782 - acc: 0.6033 - val_loss: 0.6712 - val_acc: 0.5986\n",
      "Epoch 3/100\n",
      "41/41 [==============================] - 0s 5ms/step - loss: 0.6701 - acc: 0.5942 - val_loss: 0.6597 - val_acc: 0.6064\n",
      "Epoch 4/100\n",
      "41/41 [==============================] - 0s 6ms/step - loss: 0.6615 - acc: 0.5974 - val_loss: 0.6502 - val_acc: 0.5957\n",
      "Epoch 5/100\n",
      "41/41 [==============================] - 0s 6ms/step - loss: 0.6545 - acc: 0.5920 - val_loss: 0.6417 - val_acc: 0.6064\n",
      "Epoch 6/100\n",
      "41/41 [==============================] - 0s 6ms/step - loss: 0.6494 - acc: 0.5957 - val_loss: 0.6365 - val_acc: 0.6074\n",
      "Epoch 7/100\n",
      "41/41 [==============================] - 0s 6ms/step - loss: 0.6457 - acc: 0.5957 - val_loss: 0.6323 - val_acc: 0.6035\n",
      "Epoch 8/100\n",
      "41/41 [==============================] - 0s 7ms/step - loss: 0.6424 - acc: 0.5957 - val_loss: 0.6294 - val_acc: 0.6113\n",
      "Epoch 9/100\n",
      "41/41 [==============================] - 0s 7ms/step - loss: 0.6401 - acc: 0.5994 - val_loss: 0.6276 - val_acc: 0.6035\n",
      "Epoch 10/100\n",
      "41/41 [==============================] - 0s 6ms/step - loss: 0.6374 - acc: 0.5979 - val_loss: 0.6287 - val_acc: 0.6191\n",
      "Epoch 11/100\n",
      "41/41 [==============================] - 0s 8ms/step - loss: 0.6370 - acc: 0.5994 - val_loss: 0.6235 - val_acc: 0.6152\n",
      "40/40 [==============================] - 2s 4ms/step - loss: 0.6263 - acc: 0.6141\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.6263059377670288, 0.614062488079071]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "from keras.models import Model\n",
    "lines_t = lines3[:2560]\n",
    "lines_ut = lines4[:2560]\n",
    "test_t = test3[:640]\n",
    "test_ut = test4[:640]\n",
    "\n",
    "\n",
    "lines_ = []\n",
    "test_lines_ = []\n",
    "\n",
    "lines1_ = []\n",
    "lines2_ = []\n",
    "lines3_ = []\n",
    "lines4_ = []\n",
    "feature1 = []\n",
    "feature2 = []\n",
    "rating = []\n",
    "sentiment = []\n",
    "correlation = []\n",
    "\n",
    "for line in lines_t:\n",
    "    a = line.split(\",\")[:3]\n",
    "    a = list(map(float, a))\n",
    "    feature1.append(a)\n",
    "    \n",
    "    \n",
    "\n",
    "for line in lines_ut:\n",
    "    a = line.split(\",\")[:3]\n",
    "    a = list(map(float, a))\n",
    "    feature1.append(a)\n",
    "\n",
    "for line in test_t:\n",
    "    a = line.split(\",\")[:3]\n",
    "    a = list(map(float, a))\n",
    "    feature2.append(a)\n",
    "    \n",
    "for line in test_ut:\n",
    "    a = line.split(\",\")[:3]\n",
    "    a = list(map(float, a))\n",
    "    feature2.append(a)\n",
    "    \n",
    "    \n",
    "train_labels = [] # train 데이터 label\n",
    "test_labels = [] # test 데이터 label\n",
    "for i in range(len(lines_t)):\n",
    "    train_labels.append(1)\n",
    "for j in range(len(lines_ut)):\n",
    "    train_labels.append(0)\n",
    "for i in range(len(test_t)):\n",
    "    test_labels.append(1)\n",
    "for j in range(len(test_ut)):\n",
    "    test_labels.append(0)\n",
    "\n",
    "train_labels = np.asarray(train_labels)\n",
    "test_labels = np.asarray(test_labels)\n",
    "input_train = np.asarray(feature1)\n",
    "input_test = np.asarray(feature2)\n",
    "\n",
    "input_train = input_train.reshape(-1,1,3)\n",
    "input_test = input_test.reshape(-1,1,3)\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "x_train, x_valid, y_train, y_valid = train_test_split(input_train, train_labels, test_size=0.2, shuffle=True, stratify=train_labels, random_state=34)\n",
    "# LSTM\n",
    "from keras.layers import LSTM\n",
    "from tensorflow.python.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Embedding, SimpleRNN\n",
    "\n",
    "from keras.layers import Dense\n",
    "\n",
    "from keras.preprocessing import sequence\n",
    "\n",
    "model = Sequential()\n",
    "model.add(LSTM(32, return_sequences=True))\n",
    "model.add(LSTM(32))\n",
    "# 'binary_crossentropy\n",
    "model.add(Dense(5))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "model.compile(optimizer='rmsprop',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['acc'])\n",
    "\n",
    "from keras.callbacks import EarlyStopping\n",
    "early_stopping = EarlyStopping(monitor='val_acc', patience=10, mode='auto')\n",
    "\n",
    "history = model.fit(x_train, y_train,validation_data=(x_valid, y_valid),\n",
    "                    epochs=100,\n",
    "                    batch_size=100,callbacks=[early_stopping]\n",
    "                    )\n",
    "\n",
    "\n",
    "\n",
    "model.evaluate(input_test, test_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "effabdd3",
   "metadata": {},
   "source": [
    "## 암살"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "90bc0ef4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "41/41 [==============================] - 4s 19ms/step - loss: 0.6888 - acc: 0.5725 - val_loss: 0.6873 - val_acc: 0.5615\n",
      "Epoch 2/100\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 0.6839 - acc: 0.5876 - val_loss: 0.6825 - val_acc: 0.5840\n",
      "Epoch 3/100\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 0.6764 - acc: 0.5962 - val_loss: 0.6751 - val_acc: 0.5684\n",
      "Epoch 4/100\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 0.6673 - acc: 0.5947 - val_loss: 0.6692 - val_acc: 0.5908\n",
      "Epoch 5/100\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 0.6595 - acc: 0.5957 - val_loss: 0.6629 - val_acc: 0.5723\n",
      "Epoch 6/100\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 0.6527 - acc: 0.6006 - val_loss: 0.6643 - val_acc: 0.5596\n",
      "Epoch 7/100\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 0.6489 - acc: 0.6025 - val_loss: 0.6575 - val_acc: 0.5703\n",
      "Epoch 8/100\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 0.6466 - acc: 0.6003 - val_loss: 0.6555 - val_acc: 0.5674\n",
      "Epoch 9/100\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 0.6451 - acc: 0.6055 - val_loss: 0.6554 - val_acc: 0.5752\n",
      "Epoch 10/100\n",
      "41/41 [==============================] - 0s 5ms/step - loss: 0.6429 - acc: 0.6052 - val_loss: 0.6526 - val_acc: 0.5723\n",
      "Epoch 11/100\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 0.6414 - acc: 0.6091 - val_loss: 0.6512 - val_acc: 0.5723\n",
      "Epoch 12/100\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 0.6400 - acc: 0.6050 - val_loss: 0.6510 - val_acc: 0.5635\n",
      "Epoch 13/100\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 0.6393 - acc: 0.6008 - val_loss: 0.6489 - val_acc: 0.5684\n",
      "Epoch 14/100\n",
      "41/41 [==============================] - 0s 5ms/step - loss: 0.6381 - acc: 0.6094 - val_loss: 0.6485 - val_acc: 0.5693\n",
      "40/40 [==============================] - 1s 2ms/step - loss: 0.6441 - acc: 0.5953\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.6441465616226196, 0.5953124761581421]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras.layers import Input, Dense\n",
    "from keras.models import Model\n",
    "lines_t = lines5[:2560]\n",
    "lines_ut = lines6[:2560]\n",
    "test_t = test5[:640]\n",
    "test_ut = test6[:640]\n",
    "\n",
    "\n",
    "lines_ = []\n",
    "test_lines_ = []\n",
    "\n",
    "lines1_ = []\n",
    "lines2_ = []\n",
    "lines3_ = []\n",
    "lines4_ = []\n",
    "feature1 = []\n",
    "feature2 = []\n",
    "rating = []\n",
    "sentiment = []\n",
    "correlation = []\n",
    "\n",
    "for line in lines_t:\n",
    "    a = line.split(\",\")[:3]\n",
    "    a = list(map(float, a))\n",
    "    feature1.append(a)\n",
    "    \n",
    "    \n",
    "\n",
    "for line in lines_ut:\n",
    "    a = line.split(\",\")[:3]\n",
    "    a = list(map(float, a))\n",
    "    feature1.append(a)\n",
    "\n",
    "for line in test_t:\n",
    "    a = line.split(\",\")[:3]\n",
    "    a = list(map(float, a))\n",
    "    feature2.append(a)\n",
    "    \n",
    "for line in test_ut:\n",
    "    a = line.split(\",\")[:3]\n",
    "    a = list(map(float, a))\n",
    "    feature2.append(a)\n",
    "    \n",
    "    \n",
    "train_labels = [] # train 데이터 label\n",
    "test_labels = [] # test 데이터 label\n",
    "for i in range(len(lines_t)):\n",
    "    train_labels.append(1)\n",
    "for j in range(len(lines_ut)):\n",
    "    train_labels.append(0)\n",
    "for i in range(len(test_t)):\n",
    "    test_labels.append(1)\n",
    "for j in range(len(test_ut)):\n",
    "    test_labels.append(0)\n",
    "\n",
    "train_labels = np.asarray(train_labels)\n",
    "test_labels = np.asarray(test_labels)\n",
    "input_train = np.asarray(feature1)\n",
    "input_test = np.asarray(feature2)\n",
    "\n",
    "input_train = input_train.reshape(-1,1,3)\n",
    "input_test = input_test.reshape(-1,1,3)\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "x_train, x_valid, y_train, y_valid = train_test_split(input_train, train_labels, test_size=0.2, shuffle=True, stratify=train_labels, random_state=34)\n",
    "# LSTM\n",
    "from keras.layers import LSTM\n",
    "from tensorflow.python.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Embedding, SimpleRNN\n",
    "\n",
    "from keras.layers import Dense\n",
    "\n",
    "from keras.preprocessing import sequence\n",
    "\n",
    "model = Sequential()\n",
    "model.add(LSTM(32, return_sequences=True))\n",
    "model.add(LSTM(32))\n",
    "# 'binary_crossentropy\n",
    "model.add(Dense(5))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "model.compile(optimizer='rmsprop',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['acc'])\n",
    "\n",
    "from keras.callbacks import EarlyStopping\n",
    "early_stopping = EarlyStopping(monitor='val_acc', patience=10, mode='auto')\n",
    "\n",
    "history = model.fit(x_train, y_train,validation_data=(x_valid, y_valid),\n",
    "                    epochs=100,\n",
    "                    batch_size=100,callbacks=[early_stopping]\n",
    "                    )\n",
    "\n",
    "\n",
    "\n",
    "model.evaluate(input_test, test_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a91538ac",
   "metadata": {},
   "source": [
    "## 1987"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4d46026f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "41/41 [==============================] - 8s 35ms/step - loss: 0.6903 - acc: 0.5498 - val_loss: 0.6873 - val_acc: 0.5713\n",
      "Epoch 2/100\n",
      "41/41 [==============================] - 0s 5ms/step - loss: 0.6867 - acc: 0.5586 - val_loss: 0.6832 - val_acc: 0.5752\n",
      "Epoch 3/100\n",
      "41/41 [==============================] - 0s 5ms/step - loss: 0.6817 - acc: 0.5635 - val_loss: 0.6769 - val_acc: 0.5557\n",
      "Epoch 4/100\n",
      "41/41 [==============================] - 0s 5ms/step - loss: 0.6765 - acc: 0.5520 - val_loss: 0.6687 - val_acc: 0.5713\n",
      "Epoch 5/100\n",
      "41/41 [==============================] - 0s 5ms/step - loss: 0.6708 - acc: 0.5562 - val_loss: 0.6633 - val_acc: 0.5586\n",
      "Epoch 6/100\n",
      "41/41 [==============================] - 0s 5ms/step - loss: 0.6669 - acc: 0.5625 - val_loss: 0.6591 - val_acc: 0.5566\n",
      "Epoch 7/100\n",
      "41/41 [==============================] - 0s 5ms/step - loss: 0.6650 - acc: 0.5632 - val_loss: 0.6581 - val_acc: 0.5576\n",
      "Epoch 8/100\n",
      "41/41 [==============================] - 0s 6ms/step - loss: 0.6641 - acc: 0.5618 - val_loss: 0.6558 - val_acc: 0.5625\n",
      "Epoch 9/100\n",
      "41/41 [==============================] - 0s 6ms/step - loss: 0.6629 - acc: 0.5591 - val_loss: 0.6564 - val_acc: 0.5596\n",
      "Epoch 10/100\n",
      "41/41 [==============================] - 0s 6ms/step - loss: 0.6622 - acc: 0.5627 - val_loss: 0.6541 - val_acc: 0.5635\n",
      "Epoch 11/100\n",
      "41/41 [==============================] - 0s 5ms/step - loss: 0.6618 - acc: 0.5637 - val_loss: 0.6544 - val_acc: 0.5586\n",
      "Epoch 12/100\n",
      "41/41 [==============================] - 0s 7ms/step - loss: 0.6616 - acc: 0.5632 - val_loss: 0.6567 - val_acc: 0.5586\n",
      "40/40 [==============================] - 2s 3ms/step - loss: 0.6562 - acc: 0.5703\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.6561650037765503, 0.5703125]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras.layers import Input, Dense\n",
    "from keras.models import Model\n",
    "lines_t = lines7[:2560]\n",
    "lines_ut = lines8[:2560]\n",
    "test_t = test7[:640]\n",
    "test_ut = test8[:640]\n",
    "\n",
    "\n",
    "lines_ = []\n",
    "test_lines_ = []\n",
    "\n",
    "lines1_ = []\n",
    "lines2_ = []\n",
    "lines3_ = []\n",
    "lines4_ = []\n",
    "feature1 = []\n",
    "feature2 = []\n",
    "rating = []\n",
    "sentiment = []\n",
    "correlation = []\n",
    "\n",
    "for line in lines_t:\n",
    "    a = line.split(\",\")[:3]\n",
    "    a = list(map(float, a))\n",
    "    feature1.append(a)\n",
    "    \n",
    "    \n",
    "\n",
    "for line in lines_ut:\n",
    "    a = line.split(\",\")[:3]\n",
    "    a = list(map(float, a))\n",
    "    feature1.append(a)\n",
    "\n",
    "for line in test_t:\n",
    "    a = line.split(\",\")[:3]\n",
    "    a = list(map(float, a))\n",
    "    feature2.append(a)\n",
    "    \n",
    "for line in test_ut:\n",
    "    a = line.split(\",\")[:3]\n",
    "    a = list(map(float, a))\n",
    "    feature2.append(a)\n",
    "    \n",
    "    \n",
    "train_labels = [] # train 데이터 label\n",
    "test_labels = [] # test 데이터 label\n",
    "for i in range(len(lines_t)):\n",
    "    train_labels.append(1)\n",
    "for j in range(len(lines_ut)):\n",
    "    train_labels.append(0)\n",
    "for i in range(len(test_t)):\n",
    "    test_labels.append(1)\n",
    "for j in range(len(test_ut)):\n",
    "    test_labels.append(0)\n",
    "\n",
    "train_labels = np.asarray(train_labels)\n",
    "test_labels = np.asarray(test_labels)\n",
    "input_train = np.asarray(feature1)\n",
    "input_test = np.asarray(feature2)\n",
    "\n",
    "input_train = input_train.reshape(-1,1,3)\n",
    "input_test = input_test.reshape(-1,1,3)\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "x_train, x_valid, y_train, y_valid = train_test_split(input_train, train_labels, test_size=0.2, shuffle=True, stratify=train_labels, random_state=34)\n",
    "# LSTM\n",
    "from keras.layers import LSTM\n",
    "from tensorflow.python.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Embedding, SimpleRNN\n",
    "\n",
    "from keras.layers import Dense\n",
    "\n",
    "from keras.preprocessing import sequence\n",
    "\n",
    "model = Sequential()\n",
    "model.add(LSTM(32, return_sequences=True))\n",
    "model.add(LSTM(32))\n",
    "# 'binary_crossentropy\n",
    "model.add(Dense(5))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "model.compile(optimizer='rmsprop',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['acc'])\n",
    "\n",
    "from keras.callbacks import EarlyStopping\n",
    "early_stopping = EarlyStopping(monitor='val_acc', patience=10, mode='auto')\n",
    "\n",
    "history = model.fit(x_train, y_train,validation_data=(x_valid, y_valid),\n",
    "                    epochs=100,\n",
    "                    batch_size=100,callbacks=[early_stopping]\n",
    "                    )\n",
    "\n",
    "\n",
    "\n",
    "model.evaluate(input_test, test_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ddd14bb",
   "metadata": {},
   "source": [
    "## 택시운전사"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d61d0f39",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "41/41 [==============================] - 6s 36ms/step - loss: 0.6904 - acc: 0.5615 - val_loss: 0.6856 - val_acc: 0.5820\n",
      "Epoch 2/100\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 0.6836 - acc: 0.5928 - val_loss: 0.6761 - val_acc: 0.6074\n",
      "Epoch 3/100\n",
      "41/41 [==============================] - 0s 7ms/step - loss: 0.6748 - acc: 0.5991 - val_loss: 0.6641 - val_acc: 0.6016\n",
      "Epoch 4/100\n",
      "41/41 [==============================] - 0s 5ms/step - loss: 0.6636 - acc: 0.5825 - val_loss: 0.6510 - val_acc: 0.6025\n",
      "Epoch 5/100\n",
      "41/41 [==============================] - 0s 6ms/step - loss: 0.6543 - acc: 0.5815 - val_loss: 0.6416 - val_acc: 0.5850\n",
      "Epoch 6/100\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 0.6484 - acc: 0.5774 - val_loss: 0.6365 - val_acc: 0.5859\n",
      "Epoch 7/100\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 0.6460 - acc: 0.5747 - val_loss: 0.6352 - val_acc: 0.5996\n",
      "Epoch 8/100\n",
      "41/41 [==============================] - 0s 5ms/step - loss: 0.6447 - acc: 0.5818 - val_loss: 0.6358 - val_acc: 0.5967\n",
      "Epoch 9/100\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 0.6433 - acc: 0.5842 - val_loss: 0.6318 - val_acc: 0.5938\n",
      "Epoch 10/100\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 0.6420 - acc: 0.5859 - val_loss: 0.6354 - val_acc: 0.5986\n",
      "Epoch 11/100\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 0.6427 - acc: 0.5911 - val_loss: 0.6308 - val_acc: 0.5938\n",
      "Epoch 12/100\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 0.6420 - acc: 0.5835 - val_loss: 0.6300 - val_acc: 0.6035\n",
      "40/40 [==============================] - 1s 2ms/step - loss: 0.6397 - acc: 0.5938\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.6396857500076294, 0.59375]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras.layers import Input, Dense\n",
    "from keras.models import Model\n",
    "lines_t = lines9[:2560]\n",
    "lines_ut = lines10[:2560]\n",
    "test_t = test9[:640]\n",
    "test_ut = test10[:640]\n",
    "\n",
    "\n",
    "lines_ = []\n",
    "test_lines_ = []\n",
    "\n",
    "lines1_ = []\n",
    "lines2_ = []\n",
    "lines3_ = []\n",
    "lines4_ = []\n",
    "feature1 = []\n",
    "feature2 = []\n",
    "rating = []\n",
    "sentiment = []\n",
    "correlation = []\n",
    "\n",
    "for line in lines_t:\n",
    "    a = line.split(\",\")[:3]\n",
    "    a = list(map(float, a))\n",
    "    feature1.append(a)\n",
    "    \n",
    "    \n",
    "\n",
    "for line in lines_ut:\n",
    "    a = line.split(\",\")[:3]\n",
    "    a = list(map(float, a))\n",
    "    feature1.append(a)\n",
    "\n",
    "for line in test_t:\n",
    "    a = line.split(\",\")[:3]\n",
    "    a = list(map(float, a))\n",
    "    feature2.append(a)\n",
    "    \n",
    "for line in test_ut:\n",
    "    a = line.split(\",\")[:3]\n",
    "    a = list(map(float, a))\n",
    "    feature2.append(a)\n",
    "    \n",
    "    \n",
    "train_labels = [] # train 데이터 label\n",
    "test_labels = [] # test 데이터 label\n",
    "for i in range(len(lines_t)):\n",
    "    train_labels.append(1)\n",
    "for j in range(len(lines_ut)):\n",
    "    train_labels.append(0)\n",
    "for i in range(len(test_t)):\n",
    "    test_labels.append(1)\n",
    "for j in range(len(test_ut)):\n",
    "    test_labels.append(0)\n",
    "\n",
    "train_labels = np.asarray(train_labels)\n",
    "test_labels = np.asarray(test_labels)\n",
    "input_train = np.asarray(feature1)\n",
    "input_test = np.asarray(feature2)\n",
    "\n",
    "input_train = input_train.reshape(-1,1,3)\n",
    "input_test = input_test.reshape(-1,1,3)\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "x_train, x_valid, y_train, y_valid = train_test_split(input_train, train_labels, test_size=0.2, shuffle=True, stratify=train_labels, random_state=34)\n",
    "# LSTM\n",
    "from keras.layers import LSTM\n",
    "from tensorflow.python.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Embedding, SimpleRNN\n",
    "\n",
    "from keras.layers import Dense\n",
    "\n",
    "from keras.preprocessing import sequence\n",
    "\n",
    "model = Sequential()\n",
    "model.add(LSTM(32, return_sequences=True))\n",
    "model.add(LSTM(32))\n",
    "# 'binary_crossentropy\n",
    "model.add(Dense(5))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "model.compile(optimizer='rmsprop',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['acc'])\n",
    "\n",
    "from keras.callbacks import EarlyStopping\n",
    "early_stopping = EarlyStopping(monitor='val_acc', patience=10, mode='auto')\n",
    "\n",
    "history = model.fit(x_train, y_train,validation_data=(x_valid, y_valid),\n",
    "                    epochs=100,\n",
    "                    batch_size=100,callbacks=[early_stopping]\n",
    "                    )\n",
    "\n",
    "\n",
    "\n",
    "model.evaluate(input_test, test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a715bd2c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "383.991px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
